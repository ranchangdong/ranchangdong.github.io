<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2019%2F10%2F22%2FRedis%2F</url>
    <content type="text"><![CDATA[Redis 有哪些类型在 Redis 中有五种数据类型 String：字符串Hash：字典List：列表Set：集合Sorted Set：有序集合 Redis 内部结构Redis 内部使用一个 redisObject 对象来表示所有的 key 和 value。 type ：代表一个 value 对象具体是何种数据类型。encoding ：是不同数据类型在 redis 内部的存储方式，比如：type=string 代表 value 存储的是一个普通字符串，那么对应的 encoding 可以是 raw 或者是 int，如果是 int 则代表实际 redis 内部是按数值型类存储和表示这个字符串的，当然前提是这个字符串本身可以用数值表示，比如：”123” “456”这样的字符串。vm 字段：只有打开了 Redis 的虚拟内存功能，此字段才会真正的分配内存，该功能默认是关闭状态的。 Redis 使用 redisObject 来表示所有的 key/value 数据是比较浪费内存的，当然这些内存管理成本的付出主要也是为了给 Redis 不同数据类型提供一个统一的管理接口，实际作者也提供了多种方法帮助我们尽量节省内存使用。 Redis 内存淘汰机制内存的淘汰机制的初衷是为了更好地使用内存，用一定的缓存 miss 来换取内存的使用效率。 作为 Redis 用户，我们如何使用 Redis 提供的这个特性呢？ maxmemory 我们可以通过配置 redis.conf 中的 maxmemory 这个值来开启内存淘汰功能，至于这个值有什么意义，我们可以通过了解内存淘汰的过程来理解它的意义： 客户端发起了需要申请更多内存的命令（如set）Redis 检查内存使用情况，如果已使用的内存大于 maxmemory 则开始根据用户配置的不同淘汰策略来淘汰内存（key），从而换取一定的内存如果上面都没问题，则这个命令执行成功maxmemory 为 0 的时候表示我们对 Redis 的内存使用没有限制 内存淘汰策略内存淘汰只是 Redis 提供的一个功能，为了更好地实现这个功能，必须为不同的应用场景提供不同的策略，内存淘汰策略讲的是为实现内存淘汰我们具体怎么做，要解决的问题包括淘汰键空间如何选择？在键空间中淘汰键如何选择？ Redis 提供了下面几种淘汰策略供用户选择，其中默认的策略为 noeviction 策略： noeviction：当内存使用达到阈值的时候，所有引起申请内存的命令会报错allkeys-lru：在主键空间中，优先移除最近未使用的keyvolatile-lru：在设置了过期时间的键空间中，优先移除最近未使用的 keyallkeys-random：在主键空间中，随机移除某个 keyvolatile-random：在设置了过期时间的键空间中，随机移除某个 keyvolatile-ttl：在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除这里补充一下主键空间和设置了过期时间的键空间，举个例子，假设我们有一批键存储在Redis中，则有那么一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间。设置了过期时间的键空间为主键空间的子集。 如何选择淘汰策略我们了解了 Redis 大概提供了这么几种淘汰策略，那么如何选择呢？淘汰策略的选择可以通过下面的配置指定： maxmemory-policy noeviction 但是这个值填什么呢？为解决这个问题，我们需要了解我们的应用请求对于 Redis 中存储的数据集的访问方式以及我们的诉求是什么。同时 Redis 也支持 Runtime 修改淘汰策略，这使得我们不需要重启 Redis 实例而实时的调整内存淘汰策略。 下面看看几种策略的适用场景： allkeys-lru：如果我们的应用对缓存的访问符合幂律分布（也就是存在相对热点数据），或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择 allkeys-lru 策略allkeys-random：如果我们的应用对于缓存 key 的访问概率相等，则可以使用这个策略volatile-ttl：这种策略使得我们可以向 Redis 提示哪些 key 更适合被 eviction另外，volatile-lru 策略和 volatile-random 策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个 Redis 实例来达到相同的效果，值得一提的是将key设置过期时间实际上会消耗更多的内存，因此我们建议使用 allkeys-lru 策略从而更有效率的使用内存。 非精准的 LRU上面提到的 LRU（Least Recently Used）策略，实际上 Redis 实现的 LRU 并不是可靠的 LRU，也就是名义上我们使用 LRU 算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的，这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis 是单线程的，也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎。为了在一定成本内实现相对的 LRU，早期的 Redis 版本是基于采样的 LRU，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从 Redis3.0 版本之后，Redis 作者对于基于采样的 LRU 进行了一些优化，目的是在一定的成本内让结果更靠近真实的 LRU。 聊聊 Redis 使用场景缓存会话缓存时效性访问频率计数器社交列表记录用户判定信息交集、并集和差集热门列表与排行榜最新动态消息队列 Redis 持久化机制Redis 有两种持久化机制:RDB:RDB 持久化方式会在一个特定的间隔保存那个时间点的一个数据快照 AOF:AOF 持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟 Redis 协议一致，以追加的方式进行保存,Redis 的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。两种方式的持久化是可以同时存在的，但是当 Redis 重启时，AOF 文件会被优先用于重建数据。 Redis 为什么是单线程的因为 CPU 不是 Redis 的瓶颈。Redis 的瓶颈最有可能是机器内存或者网络带宽。（以上主要来自官方 FAQ）既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。 缓存崩溃碰到这种情况，一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间 key 是锁着的，这时过来 1000 个请求 999 个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法。 缓存降级页面降级:在大促或者某些特殊情况下，某些页面占用了一些稀缺服务资源，在紧急情况下可以对其整个降级，以达到丢卒保帅 页面片段降级:比如商品详情页中的商家部分因为数据错误了，此时需要对其进行降级 页面异步请求降级:比如商品详情页上有推荐信息/配送至等异步加载的请求，如果这些信息响应慢或者后端服务有问题，可以进行降级； 服务功能降级:比如渲染商品详情页时需要调用一些不太重要的服务：相关分类、热销榜等，而这些服务在异常情况下直接不获取，即降级即可； 读降级:比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景； 写降级:比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。 爬虫降级:在大促活动时，可以将爬虫流量导向静态页或者返回空数据，从而保护后端稀缺资源。 自动开关降级:自动降级是根据系统负载、资源使用情况、SLA等指标进行降级。 超时降级:当访问的数据库/http服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话可以在超时后自动降级；比如商品详情页上有推荐内容/评价，但是推荐内容/评价暂时不展示对用户购物流程不会产生很大的影响；对于这种服务是可以超时降级的。如果是调用别人的远程服务，和对方定义一个服务响应最大时间，如果超时了则自动降级。 使用缓存的合理性问题热点数据，缓存才有价值频繁修改的数据，看情况考虑使用缓存数据不一致性缓存更新机制缓存可用性缓存服务降级缓存预热缓存穿透]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志规范]]></title>
    <url>%2F2019%2F10%2F22%2F%E6%97%A5%E5%BF%97%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[概述系统上线之后，一旦发生异常，第一件事就是要弄清楚当时发生了什么，用户当时做了什么操作，环境有无影响，数据有什么变化，是不是反复发生等，然后再进一步的确定大致是哪个方面的问题。这时，日志就给我们提供了第一手的资料。 基本原则● 不影响系统正常运行； ● 不允许产生安全问题； ● 不允许输出机密信息； ● 日志可供开发人员定位问题的真正原因； ● 日志可供监控系统自动监控与分析 日志级别ERROR：系统发生了错误事件，但仍然不影响系统的继续运行。系统需要将错误或异常细节记录ERROR日志中，方便后续人工回溯解决。WARN：系统在业务处理时触发了异常流程，但系统可恢复到正常态，下一次业务可以正常执行。如程序调用了一个旧版本的接口，可选参数不合法，非业务预期的状态但仍可继续处理等INFO：记录系统关键信息，旨在保留系统正常工作期间关键运行指标，开发人员可以将初始化系统配置、业务状态变化信息，或者用户业务流程中的核心处理记录到INFO日志中，方便日常运维工作以及错误回溯时上下文场景复现DEBUG：可以将各类详细信息记录到DEBUG里，起到调试的作用，包括参数信息，调试细节信息，返回值信息等等。TRACE：更详细的跟踪信息上述日志级别从高到低排列，是开发中最常用的五种。生产系统一般只打印INFO 级别以上的日志，对于 DEBUG 级别的日志，只在测试环境中打印。打印错误日志时，需要区分是业务异常(如:用户名不能为空)还是系统异常(如:调用 会员核心异常)，业务异常使用 warn 级别记录，系统异常使用 error 记录。 日志打点系统初始化：系统初始化时会依赖一些关键配置，根据参数不同会提供不一样的服务。将系统的启动参数记录INFO日志，打印出参数以及启动完成态服务表述。业务流程与预期不符：项目代码中结果与期望不符时也是日志场景之一，简单来说所有流程分支都可以加入考虑。取决于开发人员判断能否容忍情形发生。常见的合适场景包括外部参数不正确，数据处理问题导致返回码不在合理范围内等等。系统核心的关键动作：系统中核心角色触发的业务动作是需要多加关注的，是衡量系统正常运行的重要指标，建议记录INFO级别日志，比如电商系统用户从登录到下单的整个流程；微服务各服务节点交互；核心数据表增删改等等。系统异常：这类捕获的异常是系统告知开发人员需要加以关注的，是质量非常高的报错。应当适当记录日志，根据实际结合业务的情况使用warn或者error级别。 日志格式[线程 ID:]业务描述:方法描述:[业务流水号:]参数内容 日志规则对象声明:建议使用private static final。声明为private可防止logger对象被其他类非法使用。声明为static可防止重复new出logger对象，造成还可以防止logger被序列化，造成安全风险。声明为final是因为在类的生命周期内无需变更logger。 使用API:统一使用 slf4j，它本质是Facade, 便于我们后期随时切换日志实现。避免在代码中直接使用log4j或java logging 等实现类。 语言：最好在打印日志时输出英文，防止中文不支持而打印出乱码的情况。 禁用System输出：不要直接使用System.out或System.err 输出日志，也不允许使用 STDOUT、STDERR 作为Logger名字。 if..else判断：对于else 是非正常的情况，需要根据情况选择打印warn 或 error 日志。对于只有 if 没有 else 的地方，如果 else 的路径是不可能的，应当加上 else 语句，并打印 error 日志。 不打印无意义日志：不记录对于排查故障毫无意义的日志信息，日志信息一定要带有业务信息 不推荐字符串拼接：如果信息本身需要计算或合并的，打印前要对isxxxEnable()方法进行判断。这是因为在WARN级别时，即使INFO信息不打印，也会执行字符串拼接，造成资源浪费。实际上，不推荐使用字符串拼接的方式打印日志，可读性和可维护性都比较差。建议使用占位符 循环体内不要打印 INFO 级别日志 打印日志的代码任何情况下都不允许失败：一定要确保不会因为Log语句的问题而抛出异常造成中断。如下，如果request为null，就会抛空指针异常 重要方法入口：建议记录方法调用、入参、返回值，对于排查问题会有很大帮助。 异常：catch中的异常记录必须打印堆栈信息，不要用e.printStackTrace()。 不要记录日志后又抛出异常。抛出去的异常，一般外层会处理。如果不处理，那为什么还要抛出去？另外一个原则是，无论是否发生异常，都不要在不同地方重复记录针对同一事件的日志消息。 输出Exceptions的全部Throwable信息。否则会丢失最重要的堆栈信息。]]></content>
      <categories>
        <category>logs</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务]]></title>
    <url>%2F2019%2F10%2F22%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[前后端分离是如何做的在前后端分离架构中，后端只需要负责按照约定的数据格式向前端提供可调用的 API 服务即可。前后端之间通过 HTTP 请求进行交互，前端获取到数据后，进行页面的组装和渲染，最终返回给浏览器。 微服务哪些框架Dubbo是阿里巴巴服务化治理的核心框架，并被广泛应用于阿里巴巴集团的各成员站点。阿里巴巴近几年对开源社区的贡献不论在国内还是国外都是引人注目的，比如：JStorm 捐赠给 Apache 并加入 Apache 基金会等，为中国互联网人争足了面子，使得阿里巴巴在国人眼里已经从电商升级为一家科技公司了。 Spring Cloud从命名我们就可以知道，它是 Spring Source 的产物，Spring 社区的强大背书可以说是 Java 企业界最有影响力的组织了，除了 Spring Source 之外，还有 Pivotal 和 Netflix 是其强大的后盾与技术输出。其中 Netflix 开源的整套微服务架构套件是 Spring Cloud 的核心。 ServiceComb这个框架是由华为公司开源的，在公司内部叫cse。功能大而全，包括一站式的服务注册、服务治理、动态配置功能，具备服务化契约增强、多语言SDK支持、多通信协议支持等优势特性,使用Saga——分布式事务最终一致性解决方案。虽然这块还没有深入的使用，但是从实现的原理来看，简化了配置和性能上面有了一定的优化。 你怎么理解 RPC 框架什么是 RPC？RPC 是指远程过程调用，也就是说两台服务器 A，B 一个应用部署在 A 服务器上，想要调用 B 服务器上应用提供的函数或方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。 RPC 是如何通讯的？1、要解决通讯的问题，主要是通过在客户端和服务器之间建立 TCP 连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。2、要解决寻址的问题，也就是说，A 服务器上的应用怎么告诉底层的 RPC 框架，如何连接到 B 服务器（如主机或 IP 地址）以及特定的端口，方法的名称是什么，这样才能完成调用。比如基于 Web 服务协议栈的 RPC，就要提供一个 endpoint URI，或者是从 UDDI 服务上查找。如果是 RMI 调用的话，还需要一个 RMI Registry 来注册服务的地址。3、当 A 服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如 TCP 传递到 B 服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给 B 服务器。4、B 服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。5、返回值还要发送回服务器 A 上的应用，也要经过序列化的方式发送，服务器 A 接到后，再反序列化，恢复为内存中的表达方式，交给 A 服务器上的应用。 为什么要用 RPC？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用。 说说 RPC 的实现原理首先需要有处理网络连接通讯的模块，负责连接建立、管理和消息的传输。其次需要有编解码的模块，因为网络通讯都是传输的字节码，需要将我们使用的对象序列化和反序列化。剩下的就是客户端和服务器端的部分，服务器端暴露要开放的服务接口，客户调用服务接口的一个代理实现，这个代理实现负责收集数据、编码并传输给服务器然后等待结果返回。 说说 Dubbo 的实现原理Dubbo 作为 RPC 框架，实现的效果就是调用远程的方法就像在本地调用一样。如何做到呢？1、本地有对远程方法的描述，包括方法名、参数、返回值，在 Dubbo 中是远程和本地使用同样的接口2、要有对网络通信的封装，要对调用方来说通信细节是完全不可见的，网络通信要做的就是将调用方法的属性通过一定的协议（简单来说就是消息格式）传递到服务端3、服务端按照协议解析出调用的信息；执行相应的方法；在将方法的返回值通过协议传递给客户端；客户端再解析；在调用方式上又可以分为同步调用和异步调用。 你怎么理解 RESTful借助于超媒体这种特殊的资源呈现方式，应用状态的转换体现为浏览器中呈现资源的转换。如果将超媒体进一步抽象成一般意义上的资源呈现（Representation ）方式，那么应用状态变成了可被呈现的状态（REpresentational State）。应用状态之间的转换就成了可被呈现的状态装换（REpresentational State Transfer），这就是 REST。 总之 REST 是一种很笼统的概念，它代表一种架构风格。 说说 CAP 定理、 BASE 理论CAP 定理2000 年 7 月，加州大学伯克利分校的 Eric Brewer 教授在 ACM PODC 会议上提出 CAP 猜想。2年后，麻省理工学院的 Seth Gilbert 和 Nancy Lynch 从理论上证明了 CAP。之后，CAP 理论正式成为分布式计算领域的公认定理。 CAP 理论为：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 一致性（Consistency）一致性指 “all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。 可用性（Availability）可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。 分区容错性（Partition tolerance）分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 CAP 权衡通过 CAP 理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到 N 个 9，即保证 P 和 A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 对于涉及到钱财这样不能有一丝让步的场景，C 必须保证。网络发生故障宁可停止服务，这是保证 CA，舍弃 P。貌似这几年国内银行业发生了不下 10 起事故，但影响面不大，报到也不多，广大群众知道的少。还有一种是保证 CP，舍弃 A。例如网络故障是只读不写。 孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。 BASE 理论eBay 的架构师 Dan Pritchett 源于对大规模分布式系统的实践总结，在 ACM 上发表文章提出 BASE 理论，BASE 理论是对 CAP 理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。 基本可用（Basically Available）基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。 软状态（Soft State）软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication 的异步复制也是一种体现。 最终一致性（Eventual Consistency）最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 ACID 和 BASE 的区别与联系ACID 是传统数据库常用的设计理念，追求强一致性模型。BASE 支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。 ACID 和 BASE 代表了两种截然相反的设计哲学，在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此 ACID 和 BASE 又会结合使用。 说说最终一致性的实现方案问题的起源在电商等业务中，系统一般由多个独立的服务组成，如何解决分布式调用时候数据的一致性？ 具体业务场景如下，比如一个业务操作，如果同时调用服务 A、B、C，需要满足要么同时成功；要么同时失败。A、B、C 可能是多个不同部门开发、部署在不同服务器上的远程服务。 在分布式系统来说，如果不想牺牲一致性，CAP 理论告诉我们只能放弃可用性，这显然不能接受。为了便于讨论问题，先简单介绍下数据一致性的基础理论。 强一致 ，弱一致性，最终一致性：在工程实践上，为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性。但在电商等场景中，对于数据一致性的解决方法和常见的互联网系统（如 MySQL 主从同步）又有一定区别。有六种解决方案： 规避分布式事务——业务整合 经典方案 - eBay 模式 去哪儿网分布式事务方案 蘑菇街交易创建过程中的分布式一致性方案 支付宝及蚂蚁金融云的分布式服务 DTS 方案 农信网数据一致性方案 总之分布式服务对衍生的配套系统要求比较多，特别是我们基于消息、日志的最终一致性方案，需要考虑消息的积压、消费情况、监控、报警等。 微服务如何进行数据库管理数据库管理主要是为了数据一致性，数据一致性是微服务架构设计中唯恐避之不及却又不得不考虑的话题。通过保证事件驱动实现最终数据的一致性，此方案的优劣，也不能简单的一言而概之，而是应该根据场景定夺，适合的才是最好的。另外，我们在对微服务进行业务划分的时候就尽可能的避免“可能会产生一致性问题”的设计。如果这种设计过多，也许是时候考虑改改设计了。 如何应对微服务的链式调用异常一般情况下，每个微服务之间是独立的，如果某个服务宕机，只会影响到当前服务，而不会对整个业务系统产生影响。但是，服务端可能会在多个微服务之间产生一条链式调用，并把整合后的信息返回给客户端。在调用过程中，如果某个服务宕机或者网络不稳定可能造成整个请求失败。因此，为了应对微服务的链式调用异常，我们需要在设计微服务调用链时不宜过长，以免客户端长时间等待，以及中间环节出现错误造成整个请求失败。此外，可以考虑使用消息队列进行业务解耦，并且使用缓存避免微服务的链式调用从而提高该接口的可用性。 对于快速追踪与定位问题在微服务复杂的链式调用中，我们会比单体架构更难以追踪与定位问题。因此，在设计的时候，需要特别注意。一种比较好的方案是，当 RESTful API 接口出现非 2xx 的 HTTP 错误码响应时，采用全局的异常结构响应信息。其中，code 字段用来表示某类错误的错误码，在微服务中应该加上“{biz_name}/”前缀以便于定位错误发生在哪个业务系统上。我们来看一个案例，假设“用户中心”某个接口没有权限获取资源而出现错误，我们的业务系统可以响应“UC/AUTH_DENIED”，并且通过自动生成的 UUID 值的 request_id 字段，在日志系统中获得错误的详细信息。此外，我们需要在记录日志时，标记出错误来源以及错误详情便于更好地分析与定位问题。 微服务的安全OAuth 是一个关于授权的开放网络标准，它允许第三方网站在用户授权的前提下访问用户在服务商那里存储的各种信息。实际上，OAuth 2.0 允许用户提供一个令牌给第三方网站，一个令牌对应一个特定的第三方网站，同时该令牌只能在特定的时间内访问特定的资源。用户在客户端使用用户名和密码在用户中心获得授权，然后客户端在访问应用是附上 Token 令牌。此时，应用接收到客户端的 Token 令牌到用户中心进行认证。一般情况下，access token 会添加到 HTTP Header 的 Authorization 参数中使用，其中经常使用到的是 Bearer Token 与 Mac Token。其中，Bearer Token 适用于安全的网络下 API 授权。MAC Token 适用于不安全的网络下 API 授权。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式]]></title>
    <url>%2F2019%2F10%2F22%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[谈谈业务中使用分布式的场景首先，需要了解系统为什么使用分布式。 随着互联网的发展，传统单工程项目的很多性能瓶颈越发凸显，性能瓶颈可以有几个方面： 应用服务层：随着用户量的增加，并发量增加，单项目难以承受如此大的并发请求导致的性能瓶颈。底层数据库层：随着业务的发展，数据库压力越来越大，导致的性能瓶颈 场景1：应用系统集群的 Session 共享:应用系统集群最简单的就是服务器集群，比如：Tomcat 集群。应用系统集群的时候，比较凸显的问题是 Session 共享，Session 共享我们一是可以通过服务器插件来解决。另外一种也可以通过 Redis 等中间件实现. 场景2：应用系统的服务化拆分:服务化拆分，是目前非常火热的一种方式。现在都在提微服务。通过对传统项目进行服务化拆分，达到服务独立解耦，单服务又可以横向扩容。服务化拆分遇到的经典问题就是分布式事务问题。目前，比较常用的分布式事务解决方案有几种：消息最终一致性、TCC 补偿型事务等。 场景3：底层数据库的压力分摊如果系统的性能压力出现在数据库，那我们就可以读写分离、分库分表等方案进行解决。 Session 分布式方案基于 nfs(net filesystem) 的 Session 共享将共享服务器目录 mount 各服务器的本地 session 目录，session 读写受共享服务器 io 限制，不能满足高并发 基于关系数据库的 Session 共享这种方案普遍使用。使用关系数据库存储 session 数据，对于 mysql 数据库，建议使用 heap 引擎。这种方案性能取决于数据库的性能，在高并发下容易造成表锁（虽然可以采用行锁的存储引擎，性能会下降），并且需要自己实现 session 过期淘汰机制 基于 Cookie 的 Session 共享这种方案也在大型互联网中普遍使用，将用户的 session 加密序列化后以 cookie 的方式保存在网站根域名下（比如 taobao.com），当用户访问所有二级域名站点式，浏览器会传递所有匹配的根域名的 cookie 信息，这样实现了用户 cookie 化 session 的多服务共享。此方案能够节省大量服务器资源，缺点是存储的信息长度受到 http 协议限制；cookie 的信息还需要做加密解密；请求任何资源时都会将 cookie 附加到 http 头上传到服务器，占用了一定带宽。 基于 Web 容器的 Session 机制利用容器机制，通过配置即可实现 基于 Zookeeper 的分布式 Session 存储 基于 Redis/Memcached 的 Session 共享存储这些 key/value 非关系存储有较高的性能，轻松达到 2000 左右的 qps，内置的过期机制正好满足 session 的自动实效特性。 分布式锁的场景与实现分布式锁一般有三种实现方式1、数据库锁2、基于Redis的分布式锁3、基于Zookeeper的分布式锁 数据库锁：基于数据库表 要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。 当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。 基于redis的分布式锁：相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。而且很多缓存是可以集群部署的，可以解决单点问题。 可以使用缓存来代替数据库来实现分布式锁，这个可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。 基于Zookeeper实现分布式锁：基于zookeeper临时有序节点可以实现的分布式锁。大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 三种方案的比较：从理解的难易程度角度（从低到高）: 数据库 &gt; 缓存 &gt; Zookeeper 从实现的复杂性角度（从低到高）: Zookeeper &gt;= 缓存 &gt; 数据库 从性能角度（从高到低）: 缓存 &gt; Zookeeper &gt;= 数据库 从可靠性角度（从高到低）: Zookeeper &gt; 缓存 &gt; 数据库 还有可以利用Tair实现分布式并发锁，通过 Tair 来实现分布式锁和 Redis 的实现核心差不多，不过 Tair 有个很方便的 api，感觉是实现分布式锁的最佳配置，就是 Put api 调用的时候需要传入一个 version，就和数据库的乐观锁一样，修改数据之后，版本会自动累加，如果传入的版本和当前数据版本不一致，就不允许修改。 分布式事务分布式一致性在分布式系统中，为了保证数据的高可用，通常，我们会将数据保留多个副本(replica)，这些副本会放置在不同的物理的机器上。为了对用户提供正确的 CRUD 等语义，我们需要保证这些放置在不同物理机器上的副本是一致的。 为了解决这种分布式一致性问题，前人在性能和数据一致性的反反复复权衡过程中总结了许多典型的协议和算法。其中比较著名的有二阶提交协议（Two Phase Commitment Protocol）、三阶提交协议（Three Phase Commitment Protocol） 和 Paxos 算法 在分布式系统中，各个节点之间在物理上相互独立，通过网络进行沟通和协调。由于存在事务机制，可以保证每个独立节点上的数据操作可以满足 ACID。但是，相互独立的节点之间无法准确的知道其他节点中的事务执行情况。所以从理论上讲，两台机器理论上无法达到一致的状态。如果想让分布式部署的多台机器中的数据保持一致性，那么就要保证在所有节点的数据写操作，要不全部都执行，要么全部的都不执行。但是，一台机器在执行本地事务的时候无法知道其他机器中的本地事务的执行结果。所以他也就不知道本次事务到底应该 commit 还是 rollback。所以，常规的解决办法就是引入一个“协调者”的组件来统一调度所有分布式节点的执行。 XA 规范X/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。 通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。 所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。 一般情况下，某一数据库无法知道其它数据库在做什么，因此，在一个 DTP 环境中，交易中间件是必需的，由它通知和协调相关数据库的提交或回滚。而一个数据库只将其自己所做的操作（可恢复）影射到全局事务中。 二阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说二阶段提交其实就是实现 XA 分布式事务的关键(确切地说：两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做) 2PC所谓的两个阶段是指：第一阶段：准备阶段(投票阶段) 和第二阶段：提交阶段（执行阶段）。 准备阶段事务协调者(事务管理器)给每个参与者(资源管理器)发送 Prepare 消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的 redo 和 undo 日志，但不提交，到达一种“万事俱备，只欠东风”的状态。可以进一步将准备阶段分为以下三个步骤：协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 事务的ACID特性：原子性、一致性、隔离性、持久性]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring理解]]></title>
    <url>%2F2019%2F09%2F18%2FSpring%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[BeanFactory和ApplicationContext有什么区别BeanFactory可以理解成含有bean集合的工厂类。BeanFactory包含了多种bean的定义,以便在接收客户端请求时将对应的bean实例化。BeanFactory还能在实例化对象时生成协作类之间的关系，此举将bean自身与bean客户端的配置中解放出来。BeanFactory还包含了bean生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）从表面看，ApplicationContext如同BeanFactory一样具有bean定义 、bean关联关系的设置，根据请求分发bean的功能，但ApplicationContext在此基础上还提供了其他的功能：1、提供了指出国际化的文本消息2、同意的资源文件读取方式3、以再监听器中注册的bean事件 Spring Bean 的声明周期Spring Bean 的生命周期简单易懂，在一个bean实例被初始化时，需要执行一系列的初始化操作以达到可用的状态，同样的当一个人bean不再被调用时需要进行相关的分析结构操作，并从bean容器中移除Spring bean factory 负责管理在Spring 容器中被创建bean的生命周期。Bean 的生命周期由两组回调（call back）方法组成。1、初始化后调用的回调方法2、销毁之前调用的回调方法Spring 框架提供了以下四种方式来管理bean的生命周期事件：1、InitializingBean和DisposableBean回调接口2、针对特殊行为的其他Aware接口3、Bean配置文件中的Custom init()方法和destory()方法4、@PostConstruct和@PreDestroy注解方式 Spring IOC 如何实现Spring 中的 org.springframework.beans 包和 org.springframework.context 包构成了 Spring 框架 IoC 容器的基础。BeanFactory 接口提供了一个先进的配置机制，使得任何类型的对象的配置成为可能。ApplicationContext 接口对 BeanFactory（是一个子接口）进行了扩展，在 BeanFactory 的基础上添加了其他功能，比如与 Spring 的 AOP 更容易集成，也提供了处理 message resource 的机制（用于国际化）、事件传播以及应用层的特别配置，比如针对 Web 应用的 WebApplicationContext。org.springframework.beans.factory.BeanFactory 是 Spring IoC 容器的具体实现，用来包装和管理前面提到的各种 bean。BeanFactory 接口是 Spring IoC 容器的核心接口。 说说Spring AOP面向切面编程，在我们的应用中，经常需要做一些事情，但是这些事情与核心业务无关，比如，要记录所有 update 方法的执行时间时间，操作人等等信息，记录到日志， 通过 Spring 的 AOP 技术，就可以在不修改 update 的代码的情况下完成该需求。 Spring AOP 实现原理Spring AOP 中的动态代理只要有两种方式，JDK 动态代理 和CGLIB动态代理。JDK动态代理通过放射来接收被代理的类，并且要求被代理的类必须事先一个接口。JDK 动态代理的核心是 InvocationHandler 接口和 Proxy 类。 如果目标类没有实现接口，那么Spring AOP 会选择使用CGLIB 来动态代理目标类。CGLIB(Code Generation Library)，是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意 CGLIB 是通过继承的方式做的动态代理，因此如果某个类被标记为final 那么他无法使用 CGLIB 做动态代理的。 动态代理（CGLIB 与 JDK）JDK动态代理类和委托类需要都实现同一个接口，也就是说只有实现了某个接口的类可以使用Java动态代理机制，但是，事实上使用中并不是遇到的所有类都会给你实现一个接口，因此，对于没有实现接口的类，就不能使用该机制，而 CGLIB 则可以实现对类的动态代理。 Spring 事务实现方式编码方式：所谓编程式事务指的是通过编码方式实现事务，即类似于 JDBC 编程实现事务管理。 声明式事务管理方式：声明式事务管理又有两种实现方式： 基于 xml 配置文件的方式；另一个实在业务方法上进行 @Transaction 注解，将事务规则应用到业务逻辑中； Spring 事务底层原理划分处理单元 IOC：由于 Spring 解决的问题是对单个数据库进行局部事务处理的，具体的实现首相用 Spring 中的 IOC 划分了事务处理单元。并且将对事务的各种配置放到了 IOC 容器中（设置事务管理器，设置事务的传播特性及隔离机制）。 AOP 拦截需要进行事务处理的类Spring 事务处理模块是通过 AOP 功能来实现声明式事务处理的，具体操作（比如事务实行的配置和读取，事务对象的抽象），用 TransactionProxyFactoryBean 接口来使用 AOP 功能，生成 proxy 代理对象，通过 TransactionInterceptor 完成对代理方法的拦截，将事务处理的功能编织到拦截的方法中。读取 IOC 容器事务配置属性，转化为 Spring 事务处理需要的内部数据结构（TransactionAttributeSourceAdvisor），转化为 TransactionAttribute 表示的数据对象 对事物处理实现（事务的生成、提交、回滚、挂起）：Spring 委托给具体的事务处理器实现。实现了一个抽象和适配。适配的具体事务处理器：DataSource 数据源支持、Hibernate 数据源事务处理支持、JDO 数据源事务处理支持，JPA、JTA 数据源事务处理支持。这些支持都是通过设计 PlatformTransactionManager、AbstractPlatforTransaction 一系列事务处理的支持。 为常用数据源支持提供了一系列的 TransactionManager。 结合PlatformTransactionManager 实现了 TransactionInterception 接口，让其与 TransactionProxyFactoryBean 结合起来，形成一个 Spring 声明式事务处理的设计体系。 如何自定义注解实现功能1、创建自定义注解和创建一个接口相似，但是注解的 interface 关键字需要以 @ 符号开头。2、注解方法不能带有参数；3、注解方法返回值类型限定为：基本类型、String、Enums、Annotation 或者是这些类型的数组；4、注解方法可以有默认值；5、注解本身能够包含元注解，元注解被用来注解其它注解。 Spring MVC 运行流程1、Spring MVC 将所有的请求都提交给 DispatcherServlet，它会委托应用系统的其他模块负责对请求进行真正的处理工作。2、DispatcherServlet 查询一个或多个 HandlerMapping，找到处理请求的 Controller.3、DispatcherServlet 请求提交到目标 Controller4、Controller 进行业务逻辑处理后，会返回一个 ModelAndView5、Dispatcher 查询一个或多个 ViewResolver 视图解析器,找到 ModelAndView 对象指定的视图对象6、视图对象负责渲染返回给客户端。 Spring MVC 启动流程在 web.xml 文件中给 Spring MVC 的 Servlet 配置了 load-on-startup，所以程序启动的时候会初始化 Spring MVC，在 HttpServletBean 中将配置的 contextConfigLocation 属性设置到 Servlet 中，然后在 FrameworkServlet 中创建了 WebApplicationContext，DispatcherServlet 根据 contextConfigLocation 配置的 classpath 下的 xml 文件初始化了 Spring MVC 总的组件。 Spring 的单例实现原理Spring 对 Bean 实例的创建是采用单例注册表的方式进行实现的，而这个注册表的缓存是 ConcurrentHashMap 对象。 Spring 框架中用到了哪些设计模式1、代理模式：在 AOP 和 Remoting 中被用的比较多。2、单例模式：在 Spring 配置文件中定义的 Bean 默认为单例模式。3、模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。4、前端控制器：Spring 提供了 DispatcherServlet 来对请求进行分发。5、视图帮助(View Helper )：Spring 提供了一系列的 JSP 标签，高效宏来辅助将分散的代码整合在视图里。6、依赖注入：贯穿于 BeanFactory / ApplicationContext 接口的核心理念。7、工厂模式：BeanFactory 用来创建对象的实例。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java锁机制]]></title>
    <url>%2F2019%2F09%2F17%2FJava%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[说说线程安全问题线程安全是多线程领域的问题，线程安全可以简单理解为一个方法或者一个实例可以在多线程环境中使用而不会出现问题。在 Java 多线程编程当中，提供了多种实现 Java 线程安全的方式：1、最简单的方式，使用 Synchronization 关键字2、使用 java.util.concurrent.atomic 包中的原子类，例如 AtomicInteger3、使用 java.util.concurrent.locks 包中的锁4、使用线程安全的集合 ConcurrentHashMap5、使用 volatile 关键字，保证变量可见性（直接从内存读，而不是从线程 cache 读） volatile 实现原理在JVM底层volatile是采用的’内存屏障’来实现的缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量的副本是一致的。核心思想如下：当某个CPU在写数据的时候，如果发现操作变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取数据该变量时，发现其无效会重新从主存中加载数据 Synchroniz 实现原理同步代码块是使用monitorenter和monitorxit指令实现的，同步方法（在这看不出来 需要看JVM底层实现）依靠的时方法修饰符上的ACC_SYNCHRONIZED实现。 Synchronizd与Lock的区别Synchronizd与Lock的用法区别：synchronized(隐式锁)：在需要同步的对象中加入此控制，synchronized 可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。lock（显示锁）：需要显示指定起始位置和终止位置。一般使用 ReentrantLock 类做为锁，多个线程中必须要使用一个 ReentrantLock 类做为对象才能保证锁的生效。且在加锁和解锁处需要通过 lock() 和 unlock() 显示指出。所以一般会在 finally 块中写 unlock() 以防死锁。synchronized 和 lock 性能区别 synchronized 是托管给 JVM 执行的，而 lock 是 Java 写的控制锁的代码。在 JDK 1.5 中，synchronize 是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用 Java 提供的 Lock 对象，性能更高一些。但是到了 JDK 1.6，发生了变化。synchronize 在语义上很清晰，可以进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在 JDK 1.6 上 synchronize 的性能并不比 Lock 差。 synchronized 和 lock 机制区别synchronized 原始采用的是 CPU 悲观锁机制，即线程获得的是独占锁。独占锁意味着其 他线程只能依靠阻塞来等待线程释放锁。Lock 用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是 CAS 操作（Compare and Swap）。 CAS 乐观锁CAS 是项乐观锁技术，当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”这其实和乐观锁的冲突检查 + 数据更新的原理是一样的。 ABA问题CAS 会导致“ABA问题”CAS 算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但是不代表这个过程就是没有问题的。部分乐观锁的实现是通过版本号（version）的方式来解决 ABA 问题，乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行 +1 操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现 ABA 问题，因为版本号只会增加不会减少。 乐观锁的业务场景及实现方式乐观锁（Optimistic Lock）：每次获取数据的时候，都不会担心数据被修改，所以每次获取数据的时候都不会进行加锁，但是在更新数据的时候需要判断该数据是否被别人修改过。如果数据被其他线程修改，则不进行数据更新，如果数据没有被其他线程修改，则进行数据更新。由于数据没有进行加锁，期间该数据可以被其他线程进行读写操作。比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程]]></title>
    <url>%2F2019%2F09%2F16%2FJava%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[创建线程的方式与实现继承 Thread 类创建线程类定义 Thread 类的子类，并重写该类的 run 方法，该 run 方法的方法体就代表了线程要完成的任务。因此把 run() 方法称为执行体。创建 Thread 子类的实例，即创建了线程对象。调用线程对象的 start() 方法来启动该线程。 通过 Runnable 接口创建线程类定义 Runnable 接口的实现类，并重写该接口的 run() 方法，该 run() 方法的方法体同样是该线程的线程执行体。创建 Runnable 实现类的实例，并依此实例作为 Thread 的 target 来创建 Thread 对象，该 Thread 对象才是真正的线程对象。调用线程对象的 start() 方法来启动该线程。 通过 Callable 和 Future 创建线程创建 Callable 接口的实现类，并实现 call() 方法，该 call() 方法将作为线程执行体，并且有返回值。创建 Callable 实现类的实例，使用 FutureTask 类来包装 Callable 对象，该 FutureTask 对象封装了该 Callable 对象的 call() 方法的返回值。使用 FutureTask 对象作为 Thread 对象的 target 创建并启动新线程。调用 FutureTask 对象的 get() 方法来获得子线程执行结束后的返回值 采用实现 Runnable、Callable 接口的方式创见多线程时优势是：线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。在这种方式下，多个线程可以共享同一个 target 对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将 CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。劣势是：编程稍微复杂，如果要访问当前线程，则必须使用 Thread.currentThread() 方法 使用继承 Thread 类的方式创建多线程时优势是：编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。劣势是：线程类已经继承了 Thread 类，所以不能再继承其他父类。 sleep()、join（）、yield（）有什么区别sleep()sleep() 方法需要指定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。但是 sleep() 方法不会释放“锁标志”，也就是说如果有 synchronized 同步块，其他线程仍然不能访问共享数据。 wait()wait() 方法需要和 notify() 及 notifyAll() 两个方法一起介绍，这三个方法用于协调多个线程对共享数据的存取，所以必须在 synchronized 语句块内使用，也就是说，调用 wait()，notify() 和 notifyAll() 的任务在调用这些方法前必须拥有对象的锁。注意，它们都是 Object 类的方法，而不是 Thread 类的方法。 wait() 方法与 sleep() 方法的不同之处在于，wait() 方法会释放对象的“锁标志”。当调用某一对象的 wait() 方法后，会使当前线程暂停执行，并将当前线程放入对象等待池中，直到调用了 notify() 方法后，将从对象等待池中移出任意一个线程并放入锁标志等待池中，只有锁标志等待池中的线程可以获取锁标志，它们随时准备争夺锁的拥有权。当调用了某个对象的 notifyAll() 方法，会将对象等待池中的所有线程都移动到该对象的锁标志等待池。 除了使用 notify() 和 notifyAll() 方法，还可以使用带毫秒参数的 wait(long timeout) 方法，效果是在延迟 timeout 毫秒后，被暂停的线程将被恢复到锁标志等待池。 此外，wait()，notify() 及 notifyAll() 只能在 synchronized 语句中使用，但是如果使用的是 ReenTrantLock 实现同步，该如何达到这三个方法的效果呢？解决方法是使用 ReenTrantLock.newCondition() 获取一个 Condition 类对象，然后 Condition 的 await()，signal() 以及 signalAll() 分别对应上面的三个方法 yield()yield() 方法和 sleep() 方法类似，也不会释放“锁标志”，区别在于，它没有参数，即 yield() 方法只是使当前线程重新回到可执行状态，所以执行 yield() 的线程有可能在进入到可执行状态后马上又被执行，另外 yield() 方法只能使同优先级或者高优先级的线程得到执行机会，这也和 sleep() 方法不同。 join()join() 方法会使当前线程等待调用 join() 方法的线程结束后才能继续执行 说说 CountDownLatch 原理CountDownLatch 内部维护了一个整数 n，n（要大于等于0）在 当前线程 初始化 CountDownLatch 方法指定。当前线程调用 CountDownLatch 的 await() 方法阻塞当前线程，等待其他调用 CountDownLatch 对象的 CountDown() 方法的线程执行完毕。 其他线程调用该 CountDownLatch 的 CountDown() 方法，该方法会把 n-1，直到所有线程执行完成，n 等于 0，当前线程 就恢复执行。 说说 CyclicBarrier 原理CyclicBarrier 是一个同步辅助类,允许一组线程互相等待,直到到达某个公共屏障点(CommonBarrierPoint)。因为该 barrier 在释放等待线程后可以重用,所以称它为循环的 barrier。 说说 Semaphore 原理Semaphore 直译为信号。实际上 Semaphore 可以看做是一个信号的集合。不同的线程能够从 Semaphore 中获取若干个信号量。当 Semaphore 对象持有的信号量不足时，尝试从 Semaphore 中获取信号的线程将会阻塞。直到其他线程将信号量释放以后，阻塞的线程会被唤醒，重新尝试获取信号量。 说说 Exchanger 原理当一个线程到达 exchange 调用点时，如果它的伙伴线程此前已经调用了此方法，那么它的伙伴会被调度唤醒并与之进行对象交换，然后各自返回。如果它的伙伴还没到达交换点，那么当前线程将会被挂起，直至伙伴线程到达——完成交换正常返回；或者当前线程被中断——抛出中断异常；又或者是等候超时——抛出超时异常。 说说 CountDownLatch 与 CyclicBarrier 区别1、CountDownLatch 的作用是允许 1 或 N 个线程等待其他线程完成执行;而 CyclicBarrier 则是允许 N 个线程相互等待。2、CountDownLatch 的计数器无法被重置; CyclicBarrier 的计数器可以被重置后使用,因此它被称为是循环的 barrier。 ThreadLocal 原理分析ThreadLocal 提供了线程本地变量，它可以保证访问到的变量属于当前线程，每个线程都保存有一个变量副本，每个线程的变量都不同。ThreadLocal 相当于提供了一种线程隔离，将变量与线程相绑定。 讲讲线程池的实现原理当提交一个新任务到线程池时，线程池的处理流程如下：1、线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。2、线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。3、线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 线程池的几种方式与使用场景在 Executors 类里面提供了一些静态工厂，生成一些常用的线程池。1、newFixedThreadPool：创建固定大小的线程池。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。2、newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。3、newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。4、newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。5、newSingleThreadScheduledExecutor：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。 线程的生命周期新建(New)、就绪(Runnable)、运行(Running)、阻塞(Blocked)和死亡(Dead)5种状态]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合]]></title>
    <url>%2F2019%2F09%2F11%2FJava%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[List和Set区别1、List,Set都是继承Connection接口2、List特点：元素昂儒顺序，元素可重复；Set特点：元素无放入顺序，元素不可重复（注意：元素虽无放入顺序，但是元素在Set中的位置是有该元素的 Hash Code决定的，其实位置是固定的）3、List接口拥有三个实现类：LikedList、ArrayList、Vector. Set接口有两个实现类：HashSet（底层是由HashMap实现），LinkedHashSet List和Map区别1、List特点：元素有放入顺序，元素可重复2、Map特点：元素按键值对存储，无放入顺序3、List有三个实现类：ArrayList、LinkedList、Vector4、LinkedList底层是基于链表实现，链表内存散乱的，每一个元素存储本身内存地址的同时嗨存储下一个元素的地址，链表增删快查找慢5、Map接口有三个实现类：HashMap、HashTable、LinkedHashMap6、Map相当于和Collection一个级别的；Map集合存储键值对，且要求保持键的唯一性 ArrayList 与 LinkedList 区别因为 Array 是基于索引(index)的数据结构，它使用索引在数组中搜索和读取数据是很快的。Array 获取数据的时间复杂度是 O(1),但是要删除数据却是开销很大的，因为这需要重排数组中的所有数据。相对于 ArrayList，LinkedList 插入是更快的。因为 LinkedList 不像 ArrayList 一样，不需要改变数组的大小，也不需要在数组装满的时候要将所有的数据重新装入一个新的数组，这是 ArrayList 最坏的一种情况，时间复杂度是 O(n)，而 LinkedList 中插入或删除的时间复杂度仅为 O(1)。ArrayList 在插入数据时还需要更新索引（除了插入数组的尾部）。类似于插入数据，删除数据时，LinkedList 也优于 ArrayList。LinkedList 需要更多的内存，因为 ArrayList 的每个索引的位置是实际的数据，而 LinkedList 中的每个节点中存储的是实际的数据和前后节点的位置。你的应用不会随机访问数据。因为如果你需要 LinkedList 中的第 n 个元素的时候，你需要从第一个元素顺序数到第 n 个数据，然后读取数据。你的应用更多的插入和删除元素，更少的读取数据。因为插入和删除元素不涉及重排数据，所以它要比 ArrayList 要快。 ArrayList 与 Vector 区别同步性：Vector 是线程安全的，也就是说是同步的 ，而 ArrayList 是线程不安全的，不是同步的。数据增长：当需要增长时，Vector 默认增长为原来一倍 ，而 ArrayList 却是原来的 50% ，这样 ArrayList 就有利于节约内存空间。说明：如果涉及到堆栈，队列等操作，应该考虑用 Vector，如果需要快速随机访问元素，应该使用 ArrayList HashMap 和 HashTable 的区别HashMap 几乎可以等价于 HashTable，除了 HashMap 是非 synchronized 的，并可以接受 null(HashMap 可以接受为 null 的键值 (key) 和值 (value)，而 HashTable 则不行)。HashMap 是非 synchronized，而 HashTable 是 synchronized，这意味着 HashTable 是线程安全的，多个线程可以共享一个 HashTable；而如果没有正确的同步的话，多个线程是不能共享 HashMap 的。Java 5 提供了 ConcurrentHashMap，它是 HashTable 的替代，比 HashTable 的扩展性更好。另一个区别是 HashMap 的迭代器 (Iterator) 是 fail-fast 迭代器，而 HashTable 的 enumerator 迭代器不是 fail-fast 的。所以当有其它线程改变了 HashMap 的结构（增加或者移除元素），将会抛出 ConcurrentModificationException，但迭代器本身的 remove() 方法移除元素则不会抛出 ConcurrentModificationException 异常。但这并不是一个一定发生的行为，要看 JVM。这条同样也是 Enumeration 和 Iterator 的区别。由于 HashTable 是线程安全的也是 synchronized，所以在单线程环境下它比 HashMap 要慢。如果你不需要同步，只需要单一线程，那么使用 HashMap 性能要好过 HashTable。HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 HashSet 和 HashMap 区别HashMap：1、HashMap 实现了 Map 接口2、HashMap 储存键值对3、使用 put() 方法将元素放入 map 中4、HashMap 中使用键对象来计算 hashcode 值5、HashMap 比较快，因为是使用唯一的键来获取对象 HashSet：1、HashSet 实现了 Set 接口2、HashSet 仅仅存储对象3、使用 add() 方法将元素放入 set 中4、HashSet 使用成员对象来计算 hashcode 值，对于两个对象来说 hashcode 可能相同，所以 equals() 方法用来判断对象的相等性，如果两个对象不同的话，那么返回 false5、HashSet 较 HashMap 来说比较慢 补充 HashMap 和 ConcurrentHashMap 的区别放入 HashMap 的元素是 key-value 对。底层说白了就是散列结构。要将元素放入到 HashMap 中，那么 key 的类型必须要实现 hashcode 方法，默认这个方法是根据对象的地址来计算的，接着还必须覆盖对象的 equals() 方法。ConcurrentHashMap 对整个桶数组进行了分段，而 HashMap 则没有ConcurrentHashMap 在每一个分段上都用锁进行保护，从而让锁的粒度更精细一些，并发性能更好，而 HashMap 没有锁机制，不是线程安全的 HashMap 的工作原理及代码实现HashMap 基于 hashing 原理，我们通过 put() 和 get() 方法储存和获取对象。当我们将键值对传递给 put() 方法时，它调用键对象的 hashCode() 方法来计算 hashcode，让后找到 bucket 位置来储存值对象。当获取对象时，通过键对象的 equals() 方法找到正确的键值对，然后返回值对象。HashMap 使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap 在每个链表节点中储存键值对对象。 ConcurrentHashMap 的工作原理及代码实现ConcurrentHashMap 采用了非常精妙的”分段锁”策略，ConcurrentHashMap 的主干是个 Segment 数组。Segment 继承了 ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在 ConcurrentHashMap，一个 Segment 就是一个子哈希表，Segment 里维护了一个 HashEntry 数组，并发环境下，对于不同 Segment 的数据进行操作是不用考虑锁竞争的。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础2]]></title>
    <url>%2F2019%2F09%2F10%2FJava%E5%9F%BA%E7%A1%802%2F</url>
    <content type="text"><![CDATA[session 与 cookie 区别1、cookie 数据存放在客户的浏览器上，session 数据放在服务器上。2、cookie 不是很安全，别人可以分析存放在本地的 cookie 并进行 cookie 欺骗，考虑到安全应当使用 session。3、session 会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用 cookie。4、单个 cookie 保存的数据不能超过 4K，很多浏览器都限制一个站点最多保存 20 个 cookie。 session 分布式处理Session 复制：在支持 Session 复制的 Web 服务器上，通过修改 Web 服务器的配置，可以实现将 Session 同步到其它 Web 服务器上，达到每个 Web 服务器上都保存一致的 Session。优点：代码上不需要做支持和修改。缺点：需要依赖支持的 Web 服务器，一旦更换成不支持的 Web 服务器就不能使用了，在数据量很大的情况下不仅占用网络资源，而且会导致延迟。适用场景：只适用于Web服务器比较少且 Session 数据量少的情况。可用方案：开源方案 tomcat-redis-session-manager，暂不支持 Tomcat8。 Session 粘滞：将用户的每次请求都通过某种方法强制分发到某一个 Web 服务器上，只要这个 Web 服务器上存储了对应 Session 数据，就可以实现会话跟踪。优点：使用简单，没有额外开销。缺点：一旦某个 Web 服务器重启或宕机，相对应的 Session 数据将会丢失，而且需要依赖负载均衡机制。适用场景：对稳定性要求不是很高的业务情景 Session 集中管理：在单独的服务器或服务器集群上使用缓存技术，如 Redis 存储 Session 数据，集中管理所有的 Session，所有的Web服务器都从这个存储介质中存取对应的 Session，实现 Session 共享。优点：可靠性高，减少 Web 服务器的资源开销。缺点：实现上有些复杂，配置较多。适用场景：Web服务器较多、要求高可用性的情况。可用方案：开源方案 Spring Session，也可以自己实现，主要是重写 HttpServletRequestWrapper 中的 getSession 方法。 基于 Cookie 管理：这种方式每次发起请求的时候都需要将 Session 数据放到 Cookie 中传递给服务端。优点：不需要依赖额外外部存储，不需要额外配置。缺点：不安全，易被盗取或篡改；Cookie 数量和长度有限制，需要消耗更多网络带宽。适用场景：数据不重要、不敏感且数据量小的情况。 以上对session管理的四种方式，相对来说，Session集中管理，更加可靠，使用也是最多的 JDBC 流程1、向 DriverManager 类注册驱动数据库驱动程序2、调用 DriverManager.getConnection 方法， 通过 JDBC URL，用户名，密码取得数据库连接的 Connection 对象。3、获取 Connection 后， 便可以通过 createStatement 创建 Statement 用以执行 SQL 语句。4、有时候会得到查询结果，比如 select，得到查询结果，查询（SELECT）的结果存放于结果集（ResultSet）中。5、关闭数据库语句，关闭数据库连接。 MVC 设计思想MVC 是三个单词的首字母缩写，它们是 Model（模型）、View（视图）和 Controller（控制）。 这个模式认为，程序不论简单或复杂，从结构上看，都可以分成三层：1、最上面的一层，是直接面向最终用户的”视图层”（View）。它是提供给用户的操作界面，是程序的外壳。2、最底下的一层，是核心的”数据层”（Model），也就是程序需要操作的数据或信息。3、中间的一层，就是”控制层”（Controller），它负责根据用户从”视图层”输入的指令，选取”数据层”中的数据，然后对其进行相应的操作，产生最终结果。 equals 与 == 的区别1、== 与equals 的主要区别是：== 常用于比较原生类型，而 equals() 方法用于检查对象的相等性。2、另一个不同的点是：如果 == 和 equals() 用于比较对象，当两个引用地址相同，== 返回 true。而 equals() 可以返回 true 或者 false 主要取决于重写实现。最常见的一个例子，字符串的比较，不同情况 == 和 equals() 返回不同的结果。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA基础]]></title>
    <url>%2F2019%2F09%2F09%2FJAVA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Java是一门面向对象编程语言，不仅吸收了C++语言的各种优点，还摒弃了C++里难以理解的多继承、指针等概念，因此Java语言具有功能强大和简单易用两个特征。Java语言作为静态面向对象编程语言的代表，极好地实现了面向对象理论，允许程序员以优雅的思维方式进行复杂的编程 Java具有简单性、面对对象、分布式、健壮性、安全性、平台独立与可移植性、多线程、动态性等桌面应用程序、Web应用程序、分布式系统和嵌入系统应用程序等。 面向对象的特征：封装、继承、多态 final,finally,finalize的区别final：用于声明属性，方法和类。分别表示属性不可变，方法不可覆盖，类不可继承finally：是异常处理语句结构的一部分，表示总是执行finalize：是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等. JVM不保证此方法总被调用. int 和 Integer 有什么区别int 是 Java 提供的 8 种原始数据类型之一。Java 为每个原始类型提供了封装类，Integer 是 Java 为 int 提供的封装类。 int 的默认值为 0，而 Integer 的默认值为 null，是引用类型，即 Integer 可以区分出未赋值和值为 0 的区别，int 则无法表达出未赋值的情况， Java 中 int 和 Integer 关系是比较微妙的。关系如下：int 是基本的数据类型；Integer 是 int 的封装类；int 和 Integer 都可以表示某一个数值；int 和 Integer 不能够互用，因为他们两种不同的数据类型； 重载和重写的区别重载 Overload：表示同一个类中可以有多个名称相同的方法，但这些方法的参数列表各不相同（即参数个数或类型不同）重写 Override：表示子类中的方法可以与父类中的某个方法的名称和参数完全相同，通过子类创建的实例对象调用这个方法时，将调用子类中的定义方法，这相当于把父类中定义的那个完全相同的方法给覆盖了，这也是面向对象编程的多态性的一种表现。子类覆盖父类的方法时，只能比父类抛出更少的异常，或者是抛出父类抛出的异常的子异常，因为子类可以解决父类的一些问题，不能比父类有更多的问题。子类方法的访问权限只能比父类的更大，不能更小。如果父类的方法是private类型，那么，子类则不存在覆盖的限制，相当于子类中增加了一个全新的方法。 反射的用途及实现反射的用途：Java 反射机制是一个非常强大的功能，在很多的项目比如 Spring，MyBatis 都都可以看到反射的身影。通过反射机制，我们可以在运行期间获取对象的类型信息。利用这一点我们可以实现工厂模式和代理模式等设计模式，同时也可以解决 Java 泛型擦除等令人苦恼的问题 反射的实现：获取一个对象对应的反射类，在 Java 中有下列方法可以获取一个对象的反射类1、通过 getClass() 方法2、通过 Class.forName() 方法3、使用 类.class4、通过类加载器实现，getClassLoader() 自定义注解的场景及实现登陆、权限拦截、日志处理，以及各种 Java 框架，如 Spring，Hibernate，JUnit 提到注解就不能不说反射，Java 自定义注解是通过运行时靠反射获取注解。实际开发中，例如我们要获取某个方法的调用日志，可以通过 AOP（动态代理机制）给方法添加切面，通过反射来获取方法包含的注解，如果包含日志注解，就进行日志记录。反射的实现在 Java 应用层面上讲，是通过对 Class 对象的操作实现的，Class 对象为我们提供了一系列方法对类进行操作。在 JVM 这个角度来说，Class 文件是一组以 8 位字节为基础单位的二进制流，各个数据项目按严格的顺序紧凑的排列在 Class 文件中，里面包含了类、方法、字段等等相关数据。通过对 Class 数据流的处理我们即可得到字段、方法等数据。 HTTP 请求的 GET 与 POST 方式的区别根据 HTTP 规范，GET 用于信息获取，而且应该是安全的和幂等的。根据 HTTP 规范，POST 表示可能修改变服务器上的资源的请求。首先是 “GET 方式提交的数据最多只能是 1024 字节”，因为 GET 是通过 URL 提交数据，那么 GET 可提交的数据量就跟 URL 的长度有直接关系了。而实际上，URL 不存在参数上限的问题，HTTP 协议规范没有对 URL 长度进行限制。这个限制是特定的浏览器及服务器对它的限制。IE 对 URL 长度的限制是 2083 字节(2K+35)。对于其他浏览器，如 Netscape、FireFox 等，理论上没有长度限制，其限制取决于操作系统的支持。注意这是限制是整个 URL 长度，而不仅仅是你的参数值数据长度。POST 是没有大小限制的，HTTP 协议规范也没有进行大小限制。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nuxt.js入门]]></title>
    <url>%2F2019%2F05%2F31%2FNuxt-js%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[在说Nuxt.js之前呢 先了解一下 SEO 什么是SEO？ 简单 来说就是 搜索引擎优化 SEO是网站为了提高自已的网站排名，获得更多的流量，对网站的结构及内容进行调整优化，以便搜索引擎（百度，google等）更好抓取到更优质的网站的内容 对url链接的规范化，多用restful风格的url，多用静态资源url；注意title、keywords的设置由于spider对javascript支持不好，对于网页跳转用href标签 服务端渲染和客户端渲染采用什么技术有利于SEO？要解答这个问题需要理解服务端渲染和客户端渲染。 什么是服务端渲染? 我们用传统的servlet开发来举例：浏览器请求servlet，servlet在服务端生成html响应给浏览器，浏览器展示html的内容，这个过程就是服务端渲染，如下图：服务端渲染的特点 在服务端生成html网页的dom元素。客户端（浏览器）只负责显示dom元素内容。 客户端渲染的特点： 在服务端只是给客户端响应的了数据，而不是html网页客户端（浏览器）负责获取服务端的数据生成Dom元素 两种方式各有什么优缺点？ 客户端渲染： 缺点:不利于网站进行SEO，因为网站大量使用javascript技术，不利于spider抓取网页 优点:客户端负责渲染，用户体验性好，服务端只提供数据不用关心用户界面的内容，有利于提高服务端的开发效率 适用场景: 对SEO没有要求的系统，比如后台管理类的系统，如电商后台管理，用户管理等 服务端渲染： 优点:有利于SEO，网站通过href的url将spider直接引到服务端，服务端提供优质的网页内容给spider。 缺点:服务端完成一部分客户端的工作，通常完成一个需求需要修改客户端和服务端的代码，开发效率低，不利于系统的稳定性。 适用场景:对SEO有要求的系统，比如：门户首页、商品详情页面等。 Nuxt.js介绍移动互联网的兴起促进了web前后端分离开发模式的发展，服务端只专注业务，前端只专注用户体验，前端大量运用的前端渲染技术，比如流行的vue.js、react框架都实现了功能强大的前端渲染。 但是，对于有SEO需求的网页如果使用前端渲染技术去开发就不利于SEO了，有没有一种即使用vue.js、react的前端技术也实现服务端渲染的技术呢？其实，对于服务端渲染的需求，vue.js、react这样流行的前端框架提供了服务端渲染的解决方案。 react框架提供next.js实现服务端渲染。 vue.js框架提供Nuxt.js实现服务端渲染。 Nuxt.js工作原理 1、用户打开浏览器，输入网址请求到Node.js 2、部署在Node.js的应用Nuxt.js接收浏览器请求，并请求服务端获取数据 3、Nuxt.js获取到数据后进行服务端渲染 4、Nuxt.js将html网页响应给浏览器 Nuxt.js基本使用nuxt.js有标准的目录结构，官方提供了模板工程，可以模板工程快速创建nuxt项目 模板工程地址：https://github.com/nuxt-community/starter-template/archive/master.zip 路由基础路由Nuxt.js 依据 pages 目录结构自动生成 vue-router 模块的路由配置。 Nuxt.js根据pages的目录结构及页面名称定义规范来生成路由，下边是一个基础路由的例子： 假设 pages 的目录结构如下：1234pages/‐‐| user/‐‐‐‐‐| index.vue‐‐‐‐‐| one.vue 那么，Nuxt.js 自动生成的路由配置如下：1234567891011121314outer: &#123; routes: [ &#123; name: &apos;user&apos;, path: &apos;/user&apos;, component: &apos;pages/user/index.vue&apos; &#125;, &#123; name: &apos;user‐one&apos;, path: &apos;/user/one&apos;, component: &apos;pages/user/one.vue&apos; &#125; ]&#125; index.vue代码如下123456789101112&lt;template&gt; &lt;div&gt; 用户管理首页 &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default&#123; layout:&quot;test&quot; &#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; one.vue代码如下： 123456789101112&lt;template&gt; &lt;div&gt; one页面 &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default&#123; layout:&quot;test&quot; &#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 分别访问如下链接进行测试：http://localhost:10000/user http://localhost:10000/user/one 嵌套路由你可以通过 vue-router 的子路由创建 Nuxt.js 应用的嵌套路由。 创建内嵌子路由，你需要添加一个 Vue 文件，同时添加一个与该文件同名的目录用来存放子视图组件。 别忘了在父级 Vue 文件内增加 用于显示子视图内容。 假设文件结构如：12345pages/‐‐| user/‐‐‐‐‐| _id.vue‐‐‐‐‐| index.vue‐‐| user.vue Nuxt.js 自动生成的路由配置如下：1234567891011121314151617181920router: &#123; routes: [ &#123; path: &apos;/user&apos;, component: &apos;pages/user.vue&apos;, children: [ &#123; path: &apos;&apos;, component: &apos;pages/user/index.vue&apos;, name: &apos;user&apos; &#125;, &#123; path: &apos;:id&apos;, component: &apos;pages/user/_id.vue&apos;, name: &apos;user‐id&apos; &#125; ] &#125; ]&#125; 将user.vue文件创建到与user目录的父目录下，即和user目录保持平级12345678910111213&lt;template&gt; &lt;div&gt; 用户管理导航，&lt;nuxt‐link :to=&quot;&apos;/user/101&apos;&quot;&gt;修改&lt;/nuxt‐link&gt; &lt;nuxt‐child/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default&#123; layout:&quot;test&quot; &#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; _id.vue页面实现了向页面传入id参数，页面内容如下：123456789101112131415161718192021&lt;template&gt; &lt;div&gt; 修改用户信息&#123;&#123;id&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default&#123; layout:&quot;test&quot;, data()&#123; return &#123; id:&apos;&apos; &#125; &#125;, mounted()&#123; this.id = this.$route.params.id; console.log(this.id) &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 测试：http://localhost:10000/use 获取数据asyncData 方法Nuxt.js 扩展了 Vue.js，增加了一个叫 asyncData 的方法， asyncData 方法会在组件（限于页面组件）每次加载之前被调用。它可以在服务端或路由更新之前被调用。 在这个方法被调用的时候，第一个参数被设定为当前页面的上下文对象，你可以利用 asyncData 方法来获取数据，Nuxt.js 会将 asyncData 返回的数据融合组件 data 方法返回的数据一并返回给当前组件 注意：由于 asyncData 方法是在组件 初始化 前被调用的，所以在方法内是没有办法通过 this 来引用组件的实例对象。 在上边例子中的user/_id.vue中添加，页面代码如下：123456789101112131415161718192021222324252627&lt;template&gt; &lt;div&gt; 修改用户信息&#123;&#123;id&#125;&#125;,名称：&#123;&#123;name&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default&#123; layout:&apos;test&apos;, //根据id查询用户信息 asyncData()&#123; console.log(&quot;async方法&quot;) return &#123; name:&apos;程序员&apos; &#125; &#125;, data()&#123; return &#123; id:&apos;&apos; &#125; &#125;, mounted()&#123; this.id = this.$route.params.id; &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 此方法在服务端被执行，观察服务端控制台打印输出“async方法”。此方法返回data模型数据，在服务端被渲染，最后响应给前端，刷新此页面查看页面源代码可以看到name模型数据已在页面源代码中显示 async /await方法 使用async 和 await配合promise也可以实现同步调用，nuxt.js中使用async/await实现同步调用效果。 先测试异步调用，增加a、b两个方法，并在mounted中调用1234567891011121314151617181920212223242526methods:&#123; a()&#123; return new Promise(function(resolve,reject)&#123; setTimeout(function () &#123; resolve(1) &#125;,2000) &#125;) &#125;, b()&#123; return new Promise(function(resolve,reject)&#123; setTimeout(function () &#123; resolve(2) &#125;,1000) &#125;) &#125; &#125;, mounted()&#123; this.a().then(res=&gt;&#123; alert(res) console.log(res) &#125;) this.b().then(res=&gt;&#123; alert(res) console.log(res) &#125;)&#125; 观察客户端，并没有按照方法执行的顺序输出，使用Promise实现了异步调用。 使用async/await完成同步调用123456789101112131415161718async asyncData(&#123; store, route &#125;) &#123; console.log(&quot;async方法&quot;) var a = await new Promise(function (resolve, reject) &#123; setTimeout(function () &#123; console.log(&quot;1&quot;) resolve(1) &#125;,2000) &#125;); var a = await new Promise(function (resolve, reject) &#123; setTimeout(function () &#123; console.log(&quot;2&quot;) resolve(2) &#125;,1000) &#125;); return &#123; name:&apos;程序员&apos; &#125;&#125;, 观察服务端控制台发现是按照a、b方法的调用顺序输出1、2，实现了使用async/await完成同步调用。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES客户端-DSL搜索]]></title>
    <url>%2F2019%2F05%2F31%2FES%E5%AE%A2%E6%88%B7%E7%AB%AF-DSL%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[简单搜索简单搜索就是通过url进行查询，以get方式请求ES。 格式：get ../_search?q=….. q：搜索字符串 例子：?q=name:spring 搜索name中包括spring的文档。 DSL搜索DSL(Domain Specific Language)是ES提出的基于json的搜索方式，在搜索时传入特定的json格式的数据来完成不同的搜索需求 DSL比URI搜索方式功能强大，在项目中建议使用DSL方式来完成搜索 准备环境 创建索引库 创建映射12345678910111213141516171819202122232425262728&#123; &quot;properties&quot;: &#123; &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;pic&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;index&quot;:false &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;float&quot; &#125;, &quot;studymodel&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis&quot; &#125; &#125;&#125; 插入原始数据12345678910111213141516171819202122232425262728&#123;&quot;name&quot;: &quot;Bootstrap开发&quot;,&quot;description&quot;: &quot;Bootstrap是由Twitter推出的一个前台页面开发框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。&quot;,&quot;studymodel&quot;: &quot;201002&quot;,&quot;price&quot;:38.6,&quot;timestamp&quot;:&quot;2018‐04‐25 19:11:35&quot;,&quot;pic&quot;:&quot;group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg&quot;&#125;&#123;&quot;name&quot;: &quot;java编程基础&quot;,&quot;description&quot;: &quot;java语言是世界第一编程语言，在软件开发领域使用人数最多。&quot;,&quot;studymodel&quot;: &quot;201001&quot;,&quot;price&quot;:68.6,&quot;timestamp&quot;:&quot;2018‐03‐25 19:11:35&quot;,&quot;pic&quot;:&quot;group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg&quot;&#125;&#123;&quot;name&quot;: &quot;spring开发基础&quot;,&quot;description&quot;: &quot;spring 在java领域非常流行，java程序员都在用。&quot;,&quot;studymodel&quot;: &quot;201001&quot;,&quot;price&quot;:88.6,&quot;timestamp&quot;:&quot;2018‐02‐24 19:11:35&quot;,&quot;pic&quot;:&quot;group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg&quot;&#125; 查询所有文档 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.query(QueryBuilders.matchAllQuery()); 分页查询 12345SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();//从第1条开始searchSourceBuilder.from(0);//每次一共返回两条数据searchSourceBuilder.size(2); 精确查询Term Query为精确查询，在搜索时会整体匹配关键字，不再将关键字分词。 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.query(QueryBuilders.termsQuery(&quot;name&quot;,&quot;spring&quot;)); 全文检索match Querymatch Query即全文检索，它的搜索方式是先将搜索字符串分词，再使用各各词条从索引中搜索match query与Term query区别是match query在搜索前先将搜索关键字分词，再拿各各词语去索引中搜索 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.query(QueryBuilders.matchQuery(&quot;description&quot;,&quot;spring开发&quot;).operator(Operator.OR)); 按占比查询minimum_should_match minimum_should_match”: “80% 表示，三个词在文档的匹配占比为80%，即3*0.8=2.4，向上取整得2，表示至少有两个词在文档中要匹配成功。 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();&gt; searchSourceBuilder.query(QueryBuilders.multiMatchQuery(&quot;spring框架&quot;, &quot;name&quot;,&quot;description&quot;).minimumShouldMatch(&quot;50%&quot;).field(&quot;name&quot;,10)); 布尔查询布尔查询对应于Lucene的BooleanQuery查询，实现将多个查询组合起来三个参数：must：文档必须匹配must所包括的查询条件，相当于 “AND”should：文档应该匹配should所包括的查询条件其中的一个或多个，相当于 “OR”must_not：文档不能匹配must_not所包括的该查询条件，相当于“NOT”分别使用must、should、must_not测试下边的查询 123BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();boolQueryBuilder.must(multiMatchQueryBuilder);boolQueryBuilder.must(termsQueryBuilder); 过滤器过虑是针对搜索的结果进行过虑，过虑器主要判断的是文档是否匹配，不去计算和判断文档的匹配度得分，所以过虑器性能比查询要高，且方便缓存，推荐尽量使用过虑器去实现查询或者过虑器和查询共同使用。 123BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();boolQueryBuilder.filter(QueryBuilders.termQuery(&quot;studymodel&quot;, &quot;201001&quot;));boolQueryBuilder.filter(QueryBuilders.rangeQuery(&quot;pricec&quot;).gte(0).lte(100)); 排序可以在字段上添加一个或多个排序，支持在keyword、date、float等类型上添加，text类型的字段上不允许添加排序。 12SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();searchSourceBuilder.sort(new FieldSortBuilder(&quot;studymodel&quot;).order(SortOrder.DESC)); 高亮显示高亮显示可以将搜索结果一个或多个字突出显示，以便向用户展示匹配关键字的位置 123456789SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();HighlightBuilder highlightBuilder = new HighlightBuilder();highlightBuilder.preTags(&quot;&lt;font style=&apos;color:red;&apos;&gt;&quot;); //前缀highlightBuilder.postTags(&quot;&lt;/font&gt;&quot;); //后缀//设置高亮显示的字段highlightBuilder.fields().add(new HighlightBuilder.Field(&quot;name&quot;));highlightBuilder.fields().add(new HighlightBuilder.Field(&quot;description&quot;));searchSourceBuilder.highlighter(highlightBuilder); 这是DSL搜索 RestClient 的一些操作 如果有需要可以从github上下载https://github.com/ranchangdong/restclient-elasticsearch.git]]></content>
      <categories>
        <category>全文检索</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES客户端-RestClient]]></title>
    <url>%2F2019%2F05%2F30%2FES%E5%AE%A2%E6%88%B7%E7%AB%AF-RestClient%2F</url>
    <content type="text"><![CDATA[ES客户端ES提供多种不同的客户端：1、TransportClientES提供的传统客户端，官方计划8.0版本删除此客户端。 2、RestClientRestClient是官方推荐使用的，它包括两种：Java Low Level REST Client和 Java High Level REST Client。 ES在6.0之后提供 Java High Level REST Client， 两种客户端官方更推荐使用 Java High Level REST Client，不过当前它还处于完善中，有些功能还没有 添加依赖12345678910&lt;dependency&gt;&lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;&lt;artifactId&gt;elasticsearch‐rest‐high‐level‐client&lt;/artifactId&gt;&lt;version&gt;6.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;&lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;&lt;version&gt;6.2.1&lt;/version&gt;&lt;/dependency&gt; 配置文件123lianxi: elasticsearch: hostlist: $&#123;eshostlist:127.0.0.1:9200&#125; 配置类12345678910111213141516171819202122232425262728293031@Configurationpublic class ElasticsearchConfig &#123; @Value(&quot;$&#123;lianxi.elasticsearch.hostlist&#125;&quot;) private String hostlist; @Bean public RestHighLevelClient restHighLevelClient()&#123; //解析hostlist配置信息 String[] split = hostlist.split(&quot;,&quot;); //创建HttpHost数组，其中存放es主机和端口的配置信息 HttpHost[] httpHostArray = new HttpHost[split.length]; for(int i=0;i&lt;split.length;i++)&#123; String item = split[i]; httpHostArray[i] = new HttpHost(item.split(&quot;:&quot;)[0],Integer.parseInt(item.split(&quot;:&quot;)[1]), &quot;http&quot;); &#125; //创建RestHighLevelClient客户端 return new RestHighLevelClient(RestClient.builder(httpHostArray)); &#125; //项目主要使用RestHighLevelClient，对于低级的客户端暂时不用 @Bean public RestClient restClient()&#123; //解析hostlist配置信息 String[] split = hostlist.split(&quot;,&quot;); //创建HttpHost数组，其中存放es主机和端口的配置信息 HttpHost[] httpHostArray = new HttpHost[split.length]; for(int i=0;i&lt;split.length;i++)&#123; String item = split[i]; httpHostArray[i] = new HttpHost(item.split(&quot;:&quot;)[0], Integer.parseInt(item.split(&quot;:&quot;)[1]), &quot;http&quot;); &#125; return RestClient.builder(httpHostArray).build(); &#125; &#125; 测试类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146@SpringBootTest@RunWith(SpringRunner.class)public class TestIndex &#123; @Autowired private RestHighLevelClient client; /** * @Description 创建索引库 * @Date 2019/5/30 16:09 **/ @Test public void testCreateIndex() throws IOException &#123; //创建索引请求对象，并设置索引名称 CreateIndexRequest createIndexRequest = new CreateIndexRequest(&quot;my_course&quot;); //设置索引参数 createIndexRequest.settings( Settings.builder().put(&quot;number_of_shards&quot;,1) .put(&quot;number_of_replicas&quot;,0)); //设置映射 createIndexRequest.mapping(&quot;doc&quot;,&quot;&#123;\n&quot; + &quot;\&quot;properties\&quot;: &#123;\n&quot; + &quot;\&quot;name\&quot;: &#123;\n&quot; + &quot;\&quot;type\&quot;: \&quot;text\&quot;,\n&quot; + &quot;\&quot;analyzer\&quot;:\&quot;ik_max_word\&quot;,\n&quot; + &quot;\&quot;search_analyzer\&quot;:\&quot;ik_smart\&quot;\n&quot; + &quot;&#125;,\n&quot; + &quot;\&quot;description\&quot;: &#123;\n&quot; + &quot;\&quot;type\&quot;: \&quot;text\&quot;,\n&quot; + &quot;\&quot;analyzer\&quot;:\&quot;ik_max_word\&quot;,\n&quot; + &quot;\&quot;search_analyzer\&quot;:\&quot;ik_smart\&quot;\n&quot; + &quot;&#125;,\n&quot; + &quot;\&quot;studymodel\&quot;: &#123;\n&quot; + &quot;\&quot;type\&quot;: \&quot;keyword\&quot;\n&quot; + &quot;&#125;,\n&quot; + &quot;\&quot;price\&quot;: &#123;\n&quot; + &quot;\&quot;type\&quot;: \&quot;float\&quot;\n&quot; + &quot;&#125;,\n&quot; + &quot;\&quot;timestamp\&quot;: &#123;\n&quot; + &quot;\&quot;type\&quot;: \&quot;date\&quot;,\n&quot; + &quot;\&quot;format\&quot;: \&quot;yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis\&quot;\n&quot; + &quot;&#125;\n&quot; + &quot;&#125;\n&quot; + &quot;&#125;&quot;, XContentType.JSON); //创建索引操作客户端 IndicesClient indices = client.indices(); //创建响应对象 CreateIndexResponse createIndexResponse = indices.create(createIndexRequest, RequestOptions.DEFAULT); //得到响应结果 boolean acknowledged = createIndexResponse.isAcknowledged(); System.out.println(acknowledged); &#125; /** * @Description 删除索引 * @Date 2019/5/30 16:26 **/ public void testDeleteIndex() throws IOException &#123; //删除索引请求对象 DeleteIndexRequest indexRequest = new DeleteIndexRequest(&quot;my_course&quot;); //删除索引 AcknowledgedResponse delete = client.indices().delete(indexRequest); //删除索引响应结果 boolean acknowledged = delete.isAcknowledged(); System.out.println(acknowledged); &#125; /** * @Description 添加文档 * @Date 2019/5/30 16:30 **/ @Test public void testAddDoc() throws IOException &#123; //准备JSON数据 Map&lt;String, Object&gt; jsonMap = new HashMap&lt;&gt;(); jsonMap.put(&quot;name&quot;, &quot;spring cloud实战&quot;); jsonMap.put(&quot;description&quot;, &quot;本课程主要从四个章节进行讲解： 1.微服务架构入门 2.spring cloud 基础入门 3.实战Spring Boot 4.注册中心eureka。&quot;); jsonMap.put(&quot;studymodel&quot;, &quot;201001&quot;); SimpleDateFormat dateFormat =new SimpleDateFormat(&quot;yyyy‐MM‐dd HH:mm:ss&quot;); jsonMap.put(&quot;timestamp&quot;, dateFormat.format(new Date())); jsonMap.put(&quot;price&quot;, 5.6f); //索引请求对象 IndexRequest indexRequest = new IndexRequest(&quot;my_course&quot;,&quot;doc&quot;); //指定索引文档内容 indexRequest.source(jsonMap); //索引响应对象 IndexResponse index = client.index(indexRequest,RequestOptions.DEFAULT); //获取响应结果 DocWriteResponse.Result result = index.getResult(); System.out.println(result); &#125; /** * @Description 查询文档 * @Date 2019/5/30 16:39 **/ @Test public void getDoc() throws IOException &#123; //GET /&#123;index&#125;/&#123;type&#125;/&#123;id&#125; GetRequest getRequest = new GetRequest(&quot;my_course&quot;,&quot;doc&quot;,&quot;XUMICGsBxM8fz5F0rbOS&quot;); GetResponse documentFields = client.get(getRequest,RequestOptions.DEFAULT); Map&lt;String, Object&gt; source = documentFields.getSourceAsMap(); System.out.println(source); &#125; /** * @Description 更新文档 * @Date 2019/5/30 17:00 **/ @Test public void updateDoc() throws IOException &#123; UpdateRequest updateRequest = new UpdateRequest(&quot;my_course&quot;,&quot;doc&quot;,&quot;XEPjB2sBxM8fz5F0J7O3&quot;); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;name&quot;, &quot;spring cloud实战&quot;); updateRequest.doc(map); UpdateResponse update = client.update(updateRequest,RequestOptions.DEFAULT); RestStatus status = update.status(); System.out.println(status); &#125; /** * @Description 删除文档 * @Date 2019/5/30 17:09 **/ @Test public void testDelDoc() throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(&quot;my_course&quot;,&quot;doc&quot;,&quot;XEPjB2sBxM8fz5F0J7O3&quot;); DeleteResponse delete = client.delete(deleteRequest,RequestOptions.DEFAULT); DocWriteResponse.Result result = delete.getResult(); System.out.println(result); &#125;&#125; 这是ES客户端 RestClient 的一些基本操作 如果有需要可以从github上下载https://github.com/ranchangdong/restclient-elasticsearch.git]]></content>
      <categories>
        <category>全文检索</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch入门]]></title>
    <url>%2F2019%2F05%2F30%2Felasticsearch%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[ES快速入门&nbsp; &nbsp; &nbsp; &nbsp; ES作为一个索引及搜索服务，对外提供丰富的REST接口，快速入门部分的实例使用head插件来测试，目的是对ES的使用方法及流程有个初步的认识。 创建索引库ES的索引库是一个逻辑概念，它包括了分词列表及文档列表，同一个索引库中存储了相同类型的文档。它就相当于MySQL中的表，或相当于Mongodb中的集合。 关于索引这个语: 索引（名词）：ES是基于Lucene构建的一个搜索服务，它要从索引库搜索符合条件索引数据。 索引（动词）：索引库刚创建起来是空的，将数据添加到索引库的过程称为索引。 下边介绍两种创建索引库的方法，它们的工作原理是相同的，都是客户端向ES服务发送命令 使用postman或curl这样的工具创建 put http://localhost:9200/索引库名称 12345678&#123; &quot;settings&quot;:&#123; &quot;index&quot;:&#123; &quot;number_of_shards&quot;:1, &quot;number_of_replicas&quot;:0 &#125; &#125;&#125; number_of_shards：设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为1 number_of_replicas：设置副本的数量，设置副本是为了提高ES的高可靠性，单机环境设置为0. 如下是创建的例子，创建xc_course索引库，共1个分片，0个副本 创建映射概念说明在索引中每个文档都包括了一个或多个field，创建映射就是向索引库中创建field的过程，下边是document和field与关系数据库的概念的类比： 文档（Document）—————-Row记录 字段（Field）——————-Columns 列 注意：6.0之前的版本有type（类型）概念，type相当于关系数据库的表，ES官方将在ES9.0版本中彻底删除type。上边讲的创建索引库相当于关系数据库中的数据库还是表？ 1、如果相当于数据库就表示一个索引库可以创建很多不同类型的文档，这在ES中也是允许的。 2、如果相当于表就表示一个索引库只能存储相同类型的文档，ES官方建议 在一个索引库中只存储相同类型的文档 创建映射我们要把课程信息存储到ES中，这里我们创建课程信息的映射，先来一个简单的映射，如下： 发送：post http://localhost:9200/索引库名称/类型名称/_mapping 创建类型为xc_course的映射，共包括三个字段：name、description、studymondel 由于ES6.0版本还没有将type彻底删除，所以暂时把type起一个没有特殊意义的名字 post 请求：http://localhost:9200/xc_course/doc/_mapping12345678910111213&#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;studymodel&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125;&#125; 表示：在xc_course索引库下的doc类型下创建映射。doc是类型名，可以自定义，在ES6.0中要弱化类型的概念，给它起一个没有具体业务意义的名称。 创建文档 ES中的文档相当于MySQL数据库表中的记录发送：put 或Post http://localhost:9200/xc_course/doc/id值（如果不指定id值ES会自动生成ID） http://localhost:9200/xc_course/doc/4028e58161bcf7f40161bcf8b77c0000123456&#123;&quot;name&quot;:&quot;Bootstrap开发框架&quot;,&quot;description&quot;:&quot;Bootstrap是由Twitter推出的一个前台页面开发框架，在行业之中使用较为广泛。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。&quot;,&quot;studymodel&quot;:&quot;201001&quot;&#125;` 使用postman测试： 搜索文档根据id查询文档 发送：get http://localhost:9200/xc_course/doc/4028e58161bcf7f40161bcf8b77c0000 使用postman测试： 查询所有记录发送 get http://localhost:9200/xc_course/doc/_search 查询名称中包括spring 关键字的的记录发送：get http://localhost:9200/xc_course/doc/_search?q=name:bootstrap 查询学习模式为201001的记录发送 get http://localhost:9200/xc_course/doc/_search?q=studymodel:201001 查询结果解析 took：本次操作花费的时间，单位为毫秒。 timed_out：请求是否超时 _shards：说明本次操作共搜索了哪些分片 hits：搜索命中的记录 hits.total ： 符合条件的文档总数 hits.hits ：匹配度较高的前N个文档 hits.max_score：文档匹配得分，这里为最高分 _score：每个文档都有一个匹配度得分，按照降序排列。 _source：显示了文档的原始内容。 ik分词器发送 POST请求 http://localhost:9200/_analyze {“text”:”测试分词器，后边是测试内容：spring cloud实战”,”analyzer”:”ik_max_word” } 自定义词库如果要让分词器支持一些专有词语，可以自定义词库。iK分词器自带一个main.dic的文件，此文件为词库文件 在上边的目录中新建一个my.dic文件（注意文件格式为utf-8（不要选择utf-8 BOM））可以在其中自定义词汇：比如定义：配置文件中配置my.dic重启ES 映射维护方法 查询所有索引的映射：GET： http://localhost:9200/_mapping 创建映射:post 请求：http://localhost:9200/xc_course/doc/_mapping 一个例子：12345678910111213&#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;studymodel&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125;&#125; 更新映射:映射创建成功可以添加新字段，已有字段不允许更新。 删除映射:通过删除索引来删除映射。 常用映射类型 字符串包括text和keyword两种类型：textanalyzer 通过analyzer属性指定分词器下边指定name的字段类型为text，使用ik分词器的ik_max_word分词模式1234&quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot; &#125; 上边指定了analyzer是指在索引和搜索都使用ik_max_word，如果单独想定义搜索时使用的分词器则可以通过search_analyzer属性 对于ik分词器建议是索引时使用ik_max_word将搜索内容进行细粒度分词，搜索时使用ik_smart提高搜索精确性。 12345&quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot;&#125; index 通过index属性指定是否索引。 默认为index=true，即要进行索引，只有进行索引才可以从索引库搜索到。 但是也有一些内容不需要索引，比如：商品图片地址只被用来展示图片，不进行搜索图片，此时可以将index设置为false。 删除索引，重新创建映射，将pic的index设置为false，尝试根据pic去搜索，结果搜索不到数据1234&quot;pic&quot;: &#123;&quot;type&quot;: &quot;text&quot;,&quot;index&quot;:false&#125; store 是否在source之外存储，每个文档索引后会在 ES中保存一份原始文档，存放在”_source”中，一般情况下不需要设置store为true，因为在_source中已经有一份原始文档了 测试 删除xc_course/doc下的映射创建新映射：Post http://localhost:9200/xc_course/doc/_mapping 123456789101112131415161718192021&#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot; &#125;, &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;search_analyzer&quot;:&quot;ik_smart&quot; &#125;, &quot;pic&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;index&quot;:false &#125;, &quot;studymodel&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125; &#125;&#125; 插入文档： http://localhost:9200/xc_course/doc/4028e58161bcf7f40161bcf8b77c0000 12345678&#123;&quot;name&quot;:&quot;Bootstrap开发框架&quot;,&quot;description&quot;:&quot;Bootstrap是由Twitter推出的一个前台页面开发框架，在行业之中使用较为广泛。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。&quot;,&quot;pic&quot;:&quot;group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg&quot;,&quot;studymodel&quot;:&quot;201002&quot;&#125; 查询测试：Get http://localhost:9200/xc_course/_search?q=name:开发Get http://localhost:9200/xc_course/_search?q=description:开发Get http://localhost:9200/xc_course/_search?q=pic:group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpgGet http://localhost:9200/xc_course/_search?q=studymodel:201002通过测试发现：name和description都支持全文检索，pic不可作为查询条件。 keyword关键字字段 上边介绍的text文本字段在映射时要设置分词器，keyword字段为关键字字段，通常搜索keyword是按照整体搜索，所以创建keyword字段的索引时是不进行分词的，比如：邮政编码、手机号码、身份证等。keyword字段通常用于过虑、排序、聚合等。 更改映射：12345678910&#123; &quot;properties&quot;: &#123; &quot;studymodel&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125;, &quot;name&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125; &#125;&#125; 插入文档： 123456&#123; &quot;name&quot;: &quot;java编程基础&quot;, &quot;description&quot;: &quot;java语言是世界第一编程语言，在软件开发领域使用人数最多。&quot;, &quot;pic&quot;:&quot;group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg&quot;, &quot;studymodel&quot;: &quot;201001&quot;&#125; 根据studymodel查询文档搜索：http://localhost:9200/xc_course/_search?q=name:javaname是keyword类型，所以查询方式是精确查询。 date日期类型 日期类型不用设置分词器。通常日期类型的字段用于排序。 format通过format设置日期格式 下边的设置允许date字段存储年月日时分秒、年月日及毫秒三种格式12345678&#123; &quot;properties&quot;: &#123; &quot;timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd&quot; &#125; &#125;&#125; 插入文档：Post :http://localhost:9200/xc_course/doc/31234567&#123; &quot;name&quot;: &quot;spring开发基础&quot;, &quot;description&quot;: &quot;spring 在java领域非常流行，java程序员都在用。&quot;, &quot;studymodel&quot;: &quot;201001&quot;, &quot;pic&quot;:&quot;group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg&quot;, &quot;timestamp&quot;:&quot;2018‐07‐04 18:28:58&quot;&#125; 数值类型 尽量选择范围小的类型，提高搜索效率 对于浮点数尽量用比例因子，比如一个价格字段，单位为元，我们将比例因子设置为100这在ES中会按 分 存储，映射如下： 1234&quot;price&quot;: &#123; &quot;type&quot;: &quot;scaled_float&quot;, &quot;scaling_factor&quot;: 100&#125;, 由于比例因子为100，如果我们输入的价格是23.45则ES中会将23.45乘以100存储在ES中。 如果输入的价格是23.456，ES会将23.456乘以100再取一个接近原始值的数，得出2346。 使用比例因子的好处是整型比浮点型更易压缩，节省磁盘空间。 如果比例因子不适合，则从下表选择范围小的去用： 更新已有映射，并插入文档：http://localhost:9200/xc_course/doc/3 12345678&#123; &quot;name&quot;: &quot;spring开发基础&quot;, &quot;description&quot;: &quot;spring 在java领域非常流行，java程序员都在用。&quot;, &quot;studymodel&quot;: &quot;201001&quot;, &quot;pic&quot;:&quot;group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg&quot;, &quot;timestamp&quot;:&quot;2018‐07‐04 18:28:58&quot;, &quot;price&quot;:38.6&#125; 综合例子 创建如下映射post：http://localhost:9200/xc_course/doc/_mapping12345678910111213141516171819202122232425262728&#123; &quot;properties&quot;: &#123; &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; &#125;, &quot;pic&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;index&quot;:false &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;float&quot; &#125;, &quot;studymodel&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;timestamp&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis&quot; &#125; &#125;&#125; 插入文档: Post: http://localhost:9200/xc_course/doc/112345678&#123; &quot;name&quot;: &quot;Bootstrap开发&quot;, &quot;description&quot;: &quot;Bootstrap是由Twitter推出的一个前台页面开发框架， 是一个非常流行的开发框架， 此框架集成了多种页面效果。 此开发框架包含了大量的CSS、 JS程序代码， 可以帮助开发者（ 尤其是不擅长页面开发的程序人员） 轻松的实现一个不受浏览器限制的精美界面效果。 &quot;, &quot;studymodel &quot;: &quot;201002 &quot;, &quot;price &quot;: 38.6, &quot;timestamp &quot;: &quot;2018 - 04 - 25 19: 11: 35 &quot;, &quot;pic&quot;: &quot;group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg&quot;&#125;]]></content>
      <categories>
        <category>全文检索</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch安装]]></title>
    <url>%2F2019%2F05%2F30%2Felasticsearch%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[使用docker创建elasticsearch镜像拉取 docker pull elasticsearch:6.5.0 运行 docker run -it -e “discovery.type=single-node” –name=”es” -p 9200:9200 -p 9300:9300 elasticsearch:6.5.0 注意：这里的 6.5.0 是版本号 必须添加 修改配置，跨域访问问题 进入容器 docker exec -it b8c7c128df2f /bin/bashroot@b8c7c128df2f:/usr/share/elasticsearch# lsNOTICE.txt README.textile bin config data lib logs modules pluginsroot@b8c7c128df2f:/usr/share/elasticsearch# cd config/root@b8c7c128df2f:/usr/share/elasticsearch/config# lselasticsearch.yml log4j2.properties scripts 2.编辑 elasticsearch.ymlroot@b8c7c128df2f:/usr/share/elasticsearch/config# vim elasticsearch.yml3.如果容器中没有vim命令安装 vim首先apt-get update然后apt-get install vim安装完，再编辑elasticsearch.yml在文件末尾加上http.cors.enabled: truehttp.cors.allow-origin: “*”配置修改完成，重启容器。 浏览地址栏输入 服务器公网ip:9200 访问 安装Elasticsearch可视化管理工具 ElasticHDElasticHD 支持 ES监控、实时搜索，Index template快捷替换修改，索引列表信息查看， SQL converts to DSL工具等，体验下来感觉还是比较强大的！ 镜像拉取 docker pull containerize/elastichd 运行 docker run -p 9800:9800 -d –link es containerize/elastichd IK分词器安装elasticsearch分词器，对中文分词并不是太友好。这里我们可以下载开源的IK分词器，来解决这一问题 1.进入elasticsearch容器-&gt;plugins 目录下 docker exec -it b8c7c128df2f /bin/bash root@b8c7c128df2f:/usr/share/elasticsearch# cd plugins/ 2.现在可以通过下载资源方式安装 wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.5.0/elasticsearch-analysis-ik-6.5.0.zip下载完成 elasticsearch-analysis-ik-6.5.0.zip root@b8c7c128df2f:/usr/share/elasticsearch/plugins# ls elasticsearch-analysis-ik-6.5.0.zip 这里需要注意的是ik 分词器的版本。需要与elasticsearch版本相对应，否者后面会启动失败。 4.解压 创建ik文件夹 unzip elasticsearch-analysis-ik-6.5.0.zip 5.重启 elasticsearch]]></content>
      <categories>
        <category>全文检索</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastDFS研究]]></title>
    <url>%2F2019%2F05%2F29%2FfastDFS%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[分布式文件系统什么是分布式文件系统文件系统：文件系统是负责管理和存储文件的系统软件，它是操作系统和硬件驱动之间的桥梁，操作系统通过文件系统提供的接口去存取文件，用户通过操作系统访问磁盘上的文件。文件系统存储流程 常见的文件系统：FAT16/FAT32、NTFS、HFS、UFS、APFS、XFS、Ext4等 。 什么是分布式文件系统&nbsp; &nbsp; &nbsp; &nbsp;分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点相连。分布式文件系统的设计基于客户机/服务器模式。一个典型的网络可能包括多个供多用户访问的服务器。另外，对等特性允许一些系统扮演客户机和服务器的双重角色。例如，用户可以“发表”一个允许其他客户机访问的目录，一旦被访问，这个目录对客户机来说就像使用本地驱动器一样 &nbsp; &nbsp; &nbsp; &nbsp;分布式文件系统是面对互联网的需求而产生，互联网时代对海量数据如何存储？靠简单的增加硬盘的个数已经满足不了我们的要求，因为硬盘传输速度有限但是数据在急剧增长，另外我们还要要做好数据备份、数据安全等。 &nbsp; &nbsp; &nbsp; &nbsp;采用分布式文件系统可以将多个地点的文件系统通过网络连接起来，组成一个文件系统网络，结点之间通过网络进行通信，一台文件系统的存储和传输能力有限，我们让文件在多台计算机上存储，通过多台计算共同传输。 好处：1、一台计算机的文件系统处理能力扩充到多台计算机同时处理。2、一台计算机挂了还有另外副本计算机提供数据。3、每台计算机可以放在不同的地域，这样用户就可以就近访问，提高访问速度。 主流的分布式文件系统：NFS：网络文件系统GFS：googleFSHDFS: Hadoop分布式文件系统 什么是fastDFS&nbsp; &nbsp; &nbsp; &nbsp;FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务 &nbsp; &nbsp; &nbsp; &nbsp;上边介绍的NFS、GFS都是通用的分布式文件系统，通用的分布式文件系统的优点的是开发体验好，但是系统复杂性高、性能一般，而专用的分布式文件系统虽然开发体验性差，但是系统复杂性低并且性能高。fastDFS非常适合存储图片等那些小文件，fastDFS不对文件进行分块，所以它就没有分块合并的开销，fastDFS网络通信采用socket，通信速度很快。 fastDSF工作原理fastDSF架构&nbsp; &nbsp; &nbsp; &nbsp;FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Trackerserver调度最终由Storage server完成文件上传和下载。 Tracker： Tracker Server作用是负载均衡和调度，通过Tracker server在文件上传时可以根据一些策略找到Storage server提供文件上传服务。可以将tracker称为追踪服务器或调度服务器。 FastDFS集群中的Tracker server可以有多台，Tracker server之间是相互平等关系同时提供服务，Tracker server不存在单点故障。客户端请求Tracker server采用轮询方式，如果请求的tracker无法提供服务则换另一个tracker。 Storage： Storage Server作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storage server没有实现自己的文件系统而是使用操作系统的文件系统来管理文件。可以将storage称为存储服务器。Storage集群采用了分组存储方式。storage集群由一个或多个组构成，集群存储总容量为集群中所有组的存储容量之和。一个组由一台或多台存储服务器组成，组内的Storage server之间是平等关系，不同组的Storage server之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步，从而保证同组内每个storage上的文件完全一致的。一个组的存储容量为该组内的存储服务器容量最小的那个，由此可见组内存储服务器的软硬件配置最好是一致的。 采用分组存储方式的好处是灵活、可控性较强。比如上传文件时，可以由客户端直接指定上传到的组也可以由tracker进行调度选择。一个分组的存储服务器访问压力较大时，可以在该组增加存储服务器来扩充服务能力（纵向扩容）。当系统容量不足时，可以增加组来扩充存储容量（横向扩容） Storage状态收集Storage server会连接集群中所有的Tracker server，定时向他们报告自己的状态，包括磁盘剩余空间、文件同步状况、文件上传下载次数等统计信息。 文件上传流程客户端上传文件后存储服务器将文件ID返回给客户端，此文件ID用于以后访问该文件的索引信息。文件索引信息包括：组名，虚拟磁盘路径，数据两级目录，文件名。组名：文件上传后所在的storage组名称，在文件上传成功后有storage服务器返回，需要客户端自行保存。 虚拟磁盘路径：storage配置的虚拟路径，与磁盘选项store_path*对应。如果配置了store_path0则是M00，如果配置了store_path1则是M01，以此类推。 数据两级目录：storage服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件 文件名：与文件上传时不同。是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创建时间戳、文件大小、随机数和文件拓展名等信息 文件下载流程tracker根据请求的文件路径即文件ID 来快速定义文件。 比如请求下边的文件：1.通过组名tracker能够很快的定位到客户端需要访问的存储服务器组是group1，并选择合适的存储服务器提供客户端访问。2.存储服务器根据“文件存储虚拟磁盘路径”和“数据文件两级目录”可以很快定位到文件所在目录，并根据文件名找到客户端需要访问的文件。 Docker安装FastDFS拉取镜像并启动 docker run -d –restart=always –privileged=true –net=host –name=fastdfs -e IP=47.95.234.255 -e WEB_PORT=90 -v ${HOME}/fastdfs:/var/local/fdfs registry.cn-beijing.aliyuncs.com/tianzuo/fastdfs 其中-v ${HOME}/fastdfs:/var/local/fdfs是指：将${HOME}/fastdfs这个目录挂载到容器里的/var/local/fdfs这个目录里。所以上传的文件将被持久化到${HOME}/fastdfs/storage/data里，IP 后面是自己的服务器公网ip或者虚拟机ip，-e WEB_PORT=80 指定nginx端口 测试12345docker exec -it fastdfs /bin/bashecho &quot;Hello FastDFS!&quot;&gt;index.htmlfdfs_test /etc/fdfs/client.conf upload index.html 在浏览器地址栏访问测试 http://47.95.234.255/group1/M00/00/02/rBEhP1zuotCAIX6OAAAADwL5vO430_big.html 使用Spring Boot集成FastDFS 新建一个springboot项目，在pom文件加入fastdfs-client-java包，用来调用FastDFS相关的API1234&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置yml文件1234567891011121314151617181920212223242526# 分布式文件系统fastdfs配置fdfs: # socket连接超时时长 soTimeout: 1500 # 连接tracker服务器超时时长 connectTimeout: 600 pool: # 从池中借出的对象的最大数目 max-total: 153 # 获取连接时的最大等待毫秒数100 max-wait-millis: 102 # 缩略图生成参数，可选 thumbImage: width: 150 height: 150 # 跟踪服务器tracker_server请求地址,支持多个，这里只有一个，如果有多个在下方加- x.x.x.x:port trackerList: - 47.95.234.255:22122 # # 存储服务器storage_server访问地址 web-server-url: http://47.95.234.255/ spring: http: multipart: max-file-size: 100MB # 最大支持文件大小 max-request-size: 100MB # 最大支持请求大小 配置文件设置了连接的超时时间，编码格式以及tracker_server地址等信息 测试类12345678910111213141516171819202122232425262728293031323334353637@RunWith(SpringRunner.class)@SpringBootTest(classes = Application.class)public class FdfsTest &#123; @Autowired private FastFileStorageClient storageClient; @Autowired private ThumbImageConfig thumbImageConfig; @Test public void testUpload() throws FileNotFoundException &#123; File file = new File(&quot;C:\\Users\\Super\\Desktop\\Snipaste_2019-05-28_09-40-56.png&quot;); // 上传并且生成缩略图 StorePath storePath = this.storageClient.uploadFile( new FileInputStream(file), file.length(), &quot;png&quot;, null); // 带分组的路径 System.out.println(storePath.getFullPath()); // 不带分组的路径 System.out.println(storePath.getPath()); &#125; @Test public void testUploadAndCreateThumb() throws FileNotFoundException &#123; File file = new File(&quot;C:\\Users\\Super\\Desktop\\Snipaste_2019-05-28_09-40-56.png&quot;); // 上传并且生成缩略图 StorePath storePath = this.storageClient.uploadImageAndCrtThumbImage( new FileInputStream(file), file.length(), &quot;png&quot;, null); // 带分组的路径 System.out.println(storePath.getFullPath()); // 不带分组的路径 System.out.println(storePath.getPath()); // 获取缩略图路径 String path = thumbImageConfig.getThumbImagePath(storePath.getFullPath()); System.out.println(path); &#125;&#125; 访问FastDFS图片服务器，看看图片是否已经上传上去]]></content>
      <categories>
        <category>文件存储</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket]]></title>
    <url>%2F2019%2F05%2F28%2FWebSocket%2F</url>
    <content type="text"><![CDATA[WebSocket&nbsp; &nbsp; &nbsp; &nbsp; WebSocket是一种在单个TCP连接上进行全双工通信的协议。WebSocket通信协议于2011年被IETF定为标准RFC 6455，并由RFC7936补充规范。WebSocket API也被W3C定为标准。 &nbsp; &nbsp; &nbsp; &nbsp; WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 概述&nbsp; &nbsp; &nbsp; &nbsp; WebSocket是一种在单个TCP连接上进行全双工通信的协议。WebSocket通信协议于2011年被IETF定为标准RFC 6455，并由RFC7936补充规范。WebSocketAPI也被W3C定为标准。 &nbsp; &nbsp; &nbsp; &nbsp; WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输 背景 &nbsp; &nbsp; &nbsp; &nbsp; WebSocket 现在，很多网站为了实现推送技术，所用的技术都是轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。 &nbsp; &nbsp; &nbsp; &nbsp; WebSocket 而比较新的技术去做轮询的效果是Comet。这种技术虽然可以双向通信，但依然需要反复发出请求。而且在Comet中，普遍采用的长链接，也会消耗服务器资源。 &nbsp; &nbsp; &nbsp; &nbsp; WebSocket 在这种情况下，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。 优点&nbsp; &nbsp; &nbsp; &nbsp;较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。 &nbsp; &nbsp; &nbsp; &nbsp;更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。 &nbsp; &nbsp; &nbsp; &nbsp;保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。 &nbsp; &nbsp; &nbsp; &nbsp;更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。 &nbsp; &nbsp; &nbsp; &nbsp;可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。 &nbsp; &nbsp; &nbsp; &nbsp;更好的压缩效果。相对于HTTP压缩，Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率。 握手协议&nbsp; &nbsp; &nbsp; &nbsp; WebSocket 是独立的、创建在 TCP 上的协议。 &nbsp; &nbsp; &nbsp; &nbsp;Websocket 通过HTTP/1.1 协议的101状态码进行握手。 &nbsp; &nbsp; &nbsp; &nbsp; 为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为“握手”（handshaking）。 HTML5 WebSocket&nbsp; &nbsp; &nbsp; &nbsp; HTML5 定义的 WebSocket 协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。 WebSocket运行流程图 浏览器通过 JavaScript 向服务器发出建立 WebSocket 连接的请求，连接建立以后，客户端和服务器端就可以通过 TCP 连接直接交换数据。 当你获取 Web Socket 连接后，你可以通过 send() 方法来向服务器发送数据，并通过 onmessage 事件来接收服务器返回的数据。 以下 API 用于创建 WebSocket 对象。 var Socket = new WebSocket(url, [protocol] ); 以上代码中的第一个参数 url, 指定连接的 URL。第二个参数 protocol 是可选的，指定了可接受的子协议。 WebSocket 属性以下是 WebSocket 对象的属性。假定我们使用了以上代码创建了 Socket 对象 WebSocket 事件以下是 WebSocket 对象的相关事件。假定我们使用了以上代码创建了 Socket 对象： WebSocket 方法以下是 WebSocket 对象的相关方法。假定我们使用了以上代码创建了 Socket 对象： WebSocket 实例WebSocket 协议本质上是一个基于 TCP 的协议。 为了建立一个 WebSocket 连接，客户端浏览器首先要向服务器发起一个 HTTP 请求，这个请求和通常的 HTTP 请求不同，包含了一些附加头信息，其中附加头信息”Upgrade: WebSocket”表明这是一个申请协议升级的 HTTP 请求，服务器端解析这些附加的头信息然后产生应答信息返回给客户端，客户端和服务器端的 WebSocket 连接就建立起来了，双方就可以通过这个连接通道自由的传递信息，并且这个连接会持续存在直到客户端或者服务器端的某一方主动的关闭连接。 客户端的 HTML 和 JavaScript目前大部分浏览器支持 WebSocket() 接口，你可以在以下浏览器中尝试实例： Chrome, Mozilla, Opera 和 Safari。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!DOCTYPE HTML&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; function WebSocketTest() &#123; if (&quot;WebSocket&quot; in window) &#123; alert(&quot;您的浏览器支持 WebSocket!&quot;); // 打开一个 web socket var ws = new WebSocket(&quot;ws://localhost:9998/echo&quot;); ws.onopen = function() &#123; // Web Socket 已连接上，使用 send() 方法发送数据 ws.send(&quot;发送数据&quot;); alert(&quot;数据发送中...&quot;); &#125;; ws.onmessage = function (evt) &#123; var received_msg = evt.data; alert(&quot;数据已接收...&quot;); &#125;; ws.onclose = function() &#123; // 关闭 websocket alert(&quot;连接已关闭...&quot;); &#125;; &#125; else &#123; // 浏览器不支持 WebSocket alert(&quot;您的浏览器不支持 WebSocket!&quot;); &#125; &#125; &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;sse&quot;&gt; &lt;a href=&quot;javascript:WebSocketTest()&quot;&gt;运行 WebSocket&lt;/a&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 服务端的WebSocket的实现方式有两种，这里就不一一说明了，我已经将实现方式的代码上传到github中，需要的话可以下载下来,仔细阅读代码会发现 实现方式其实并不难 使用WebSocket 由服务器主动推送消息到前台https://github.com/ranchangdong/service-websocket.git 使用WebSocket 网页模拟聊天室 （需要在开发者工具查看接收的消息）https://github.com/ranchangdong/text-websocket.git]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServiceComb服务治理]]></title>
    <url>%2F2019%2F05%2F15%2FServiceComb%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%2F</url>
    <content type="text"><![CDATA[ServiceComb服务治理本指南将以一个简单的 体质指数(BMI) 应用开展微服务之旅。体质指数主要用于衡量人体胖瘦程度。该应用主要包含两个微服务： 体质指数计算器：负责处理运算事务。 体质指数界面：提供用户界面及网关服务 网关及路由规则网关服务主要用到了业界有名的Netflix Zuul来实现 引入依赖 ServiceComb从0.4.0-SNAPSHOT版本之后新增了spring-cloud-zuul模块使能提供对zuul的兼容 在 application.yaml 文件中配置路由规则及服务端口信息： 在 microservice.yaml 文件中配置网关服务的信息和服务注册中心的地址 此处将服务注册中心和Zuul相结合使其能发现服务。 负载均衡策略当对体质指数计算器进行水平扩展时，需要将请求均衡地分发到多个体质指数计算器上。本指南将展示如何在 体质指数 应用中使用 ServiceComb 提供的负载均衡能力 其运行流程为： 其中，虚线表示服务注册及服务发现的过程 开启默认情况下会使用内置的一个简单的负载均衡的实现，不需要额外的配置。 可以使用IDEA 新增一个运行实例 就可以实现负载均衡效果 限流策略流量控制机制通过控制数据传输速率来避免微服务过载运行。本指南将展示如何在 体质指数 应用中使用 ServiceComb 提供的流量控制能力。 开启pom.xml 文件中添加依赖项： microservice.yaml 文件中指明使用流量控制的处理链及指定流控策略： 验证在地址栏输入链接 快速进行多次访问 就会出现由于流控受限而请求被拒的信息 熔断机制服务治理主要用于解决或缓解服务雪崩的情况，即个别微服务表现异常时，系统能对其进行容错处理，从而避免资源的耗尽。本指南将会展示如何在 体质指数 应用中使用 ServiceComb 提供的服务治理能力。 pom.xml 文件中添加依赖项： microservice.yaml 文件中指明使用服务治理的处理链及指定熔断和容错策略： 分布式调用链追踪分布式调用链追踪用于有效地监控微服务的网络延时并可视化微服务中的数据流转。本指南将展示如何在 体质指数 应用中使用 ServiceComb 提供的分布式调用链追踪能力。 启用pom.xml 文件中添加依赖项：简称：日志追踪 microservice.yaml 文件中添加分布式追踪的处理链： 测试案例在浏览器访问 http://start.servicecomb.io/ 会出现以下界面 注意：黄色矩形中的选项一定要勾选 否则就没有限流、熔断、日志的依赖 然后点击确认即可 下载好的文件 解压后 使用IDEA打开运行即可]]></content>
      <categories>
        <category>ServiceComb</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServiceComb-RPC编程开发]]></title>
    <url>%2F2019%2F05%2F14%2FServiceComb-RPC%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[在讲ServiceComb-RPC编程开发之前呢 先要扩展一点东西 就是ServiceComb的线程通信模块 还记得在ServiceComb基本了解中讲的 线程通信模型 RPC编程开发 目录结构 父工程 pom文件配置12345678910111213141516171819202122232425262728293031323334&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.12.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;!--实现POM文件的导入--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.servicecomb&lt;/groupId&gt; &lt;artifactId&gt;java-chassis-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 服务提供者服务方pom文件 提供方配置文件 服务提供者实现类 在实现类中与Rest服务提供者不同 服务消费者 消费者pom文件中比提供者多一个web模块 1234dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 消费方配置文件 也与提供方基本相同 只需要修改应用程序名称 和端口 RPC服务消费者 这里的消费者不是用的@Service注解 而是使用@Component注入 对外发布的控制类 启动类参考前面Rest编程开发就行 在消费者服务中添加一个application.properties文件1server.port=8088 然后启动注册中心 再启动服务 在浏览器地址栏 输入 http://localhost:8088/rpc 运行结果 将会在控制台打印 RPC开发方式ServiceComb总结 如果这里的讲解不够清晰 我已经将源码上传到geihubhttps://github.com/ranchangdong/RPC-ServiceComb.git]]></content>
      <categories>
        <category>ServiceComb</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServiceComb-Rest编程开发]]></title>
    <url>%2F2019%2F05%2F14%2FServiceComb-Rest%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[在讲解 Rest编程开发ServiceComb之前 先讲解接一下ServiceComb的配置文件在resources目录下创建 microservice.yaml 文件 （必须这样命名） 配置如下 使用Rest Template方式开发概念阐述 Rest Template是Spring提供的RESTful访问接口，ServiceComb提供该接口的实现类用于服务的调用。 场景描述 用户使用ServiceComb提供的Rest Template实例，可以使用自定义的URL进行服务调用，而不用关心服务的具体地址。 Rest Template实例通过调用RestTemplateBuilder.create()方法获取，再使用该实例通过自定义的URL进行服务调用 ServiceCombRest编程开发目录结构 pom文件配置父工程配置 服务方配置 服务提供者服务者提供方只需要将接口服务实现 注意： @RestSchema(schemaId = “hello”) 这个注解代表将你注册到注册中心给其他的消费者调用 schemaId不能重复 服务消费者 消费者服务接口实现类 cse ：服务注册中心 提供的一种协议 URL : ces:// 微服务名称 + 具体某个微服务访问路径 消费者controller类 启动类不管是提供方 还是 消费方 它们启动类都是差不多 注意：@EnableServiceComb 这个注解是代表启动ServiceComb框架 Rest编程开发ServiceComb总结 如果这里的讲解不够清晰 我已经将源码上传到geihubhttps://github.com/ranchangdong/Rest-ServiceComb.git]]></content>
      <categories>
        <category>ServiceComb</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServiceComb基本了解]]></title>
    <url>%2F2019%2F05%2F14%2FServiceComb%E5%9F%BA%E6%9C%AC%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ServiceComb概述Apache ServiceComb Java Chassis 给开发者提供一个快速构建微服务的JAVA SDK。它包含如下特性： 多种开发风格，REST(JAX-RS、Spring MVC）和RPC多种通信协议, HTTP over Vert.x、Http Over Servlet、Highway等统一一致的服务提供者、服务消费者处理链，以及基于契约的开箱即用的服务治理能力 Apache ServiceComb 是业界第一个Apache微服务顶级项目， 是一个开源微服务解决方案。致力于帮助企业、用户和开发者将企业应用轻松微服务化上云，并实现对微服务应用的高效运维管理。其提供一站式开源微服务解决方案，融合SDK框架级、0侵入ServiceMesh场景并支持多语言。ServiceComb目前拥有三个主要的子项目，分别为： Java chassis https://github.com/apache/servicecomb-java-chassis 开箱即用Java语言 微服务SDK，含服务契约、编程模型、运行模型与通信模型四个部分，具备负载均衡、容错熔断、限流降级、调用链追踪等全面微服务治理能力，服务治理能力与业务逻辑隔离。 Service Center—服务注册中心 https://github.com/apache/servicecomb-service-center 基于Etcd的高性能、高可用、无状态的Golang版分布式服务注册与发现中心，可实时服务实例注册、实时服务实例推送和服务间契约测试等。 Saga—分布式事务解决方案 https://github.com/apache/servicecomb-saga ServiceComb Saga是提供了分布式事务最终一致性解决方案，用户只需要通过注解方式定义事务的执行方法以及撤销方法，Saga框架会自动保证分布式事务执行的最终一致性。 2018年10月24日， Apache软件基金会宣布Apache ServiceComb 毕业成为Apache顶级项目： Java Chassis系统架构 简单理解 Java Chassis系统架构图设计理念 编程模型 通信模型 运行模型 服务注册中心CSE : Cloud Service Engine 云服务引擎可以轻松的将为服务发布到云平台 华为云Paas平台用ServiceComb开发为服务 再借用华为云Paas平台实现为服务治理 服务提供者: 提供为服务功能 服务注册中心: 注册微服务 ，实现微服务的管理 服务消费者: 调用微服务 逻辑关系 1.服务提供者向CSE注册中心注册一个微服务 2.服务消费者就可以向CSE注册中心服务发现 3.如果CSE注册中心找到了要调用的微服务就可以发送一个微服务的实力给微服务的实例给服务消费者 4.心跳：通过心跳的消息实现微服务状态检测 主要设计意图1.编程模型和通信模型分离，不同的编程模型可以灵活组合不同的通信模型。应用开发者在开发阶段只关注接口开发，部署阶段灵活切换通信方式；支持legacy系统的切换，legacy系统只需要修改服务发布的配置文件（或者annotation），而不需要修改代码。 现阶段支持SpringMVC、JAX-RS和透明RPC三种开发方式。 2.内建API-first支持。通过契约规范化微服务开发，实现跨语言的通信，并支持配套的软件工具链（契约生成代码、代码生成契约等）开发，构建完整的开发生态。 3.定义了常用的微服务运行模型，将微服务从发现到交互过程中的各种容错手段都封装起来。该运行模型支持自定义和扩展。 ServiceComb与Spring Cloud比较 ServiceComb 快速开发脚手架 SERVICECOMB SPRING INITIALIZRhttp://start.servicecomb.io/ 点击 Genterate Project 就会创建一个ServiceComb的Demo工程的压缩包 解压 然后用IDEA打开 这是Demo工程的目录 运行工程之前 需要将 ervice Center 服务注册中心打开 这个需要在Apache ServiceComb 官网去下载 然后解压 双击启动就行 然后运行Demo工程 在浏览器地址连输入 http://localhost:9080/hello 这样基于的ServiceComb的微服务就成功运行了]]></content>
      <categories>
        <category>ServiceComb</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合RibbitMQ]]></title>
    <url>%2F2019%2F04%2F17%2FSpringBoot%E6%95%B4%E5%90%88RibbitMQ%2F</url>
    <content type="text"><![CDATA[搭建SpringBoot环境我们选择基于Spring-Rabbit去操作RabbitMQ使用spring-boot-starter-amqp会自动添加spring-rabbit依赖，如下123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐test&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐logging&lt;/artifactId&gt;&lt;/dependency&gt; 配置配置application.yml 配置连接rabbitmq的参数1234567891011server: port: 44000spring: application: name: test‐rabbitmq‐producer rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtualHost: / 定义RabbitmqConfig类，配置Exchange、Queue、及绑定交换机本例配置Topic交换机。123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configurationpublic class RabbitmqConfig &#123; public static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;; public static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;; public static final String EXCHANGE_TOPICS_INFORM=&quot;exchange_topics_inform&quot;; public static final String ROUTINGKEY_EMAIL=&quot;inform.#.email.#&quot;; public static final String ROUTINGKEY_SMS=&quot;inform.#.sms.#&quot;; //声明交换机 @Bean(EXCHANGE_TOPICS_INFORM) public Exchange EXCHANGE_TOPICS_INFORM()&#123; //durable(true) 持久化 mq重启之后还在 return ExchangeBuilder.topicExchange(EXCHANGE_TOPICS_INFORM).durable(true).build(); &#125; //声明队列 @Bean(QUEUE_INFORM_EMAIL) public Queue QUEUE_INFORM_EMAIL()&#123; return new Queue(QUEUE_INFORM_EMAIL); &#125; @Bean(QUEUE_INFORM_SMS) public Queue QUEUE_INFORM_SMS()&#123; return new Queue(QUEUE_INFORM_SMS); &#125; //邮件队列绑定交换机 指定routingKey with(ROUTINGKEY_EMAIL) @Bean public Binding BINDING_QUEUE_INFORM_EMAIL(@Qualifier(QUEUE_INFORM_EMAIL) Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_EMAIL).noargs(); &#125; //短信队列绑定交换机 指定routingKey with(ROUTINGKEY_EMAIL) @Bean public Binding BINDING_QUEUE_INFORM_SMS(@Qualifier(QUEUE_INFORM_SMS) Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_SMS).noargs(); &#125;&#125; 生产端使用RarbbitTemplate发送消息12345678910111213141516171819202122@SpringBootTest@RunWith(SpringRunner.class)public class Produer05_SpringBoot &#123; @Autowired private RabbitTemplate rabbitTemplate; //使用rabbitTemplate发送消息 @Test public void testSendEamil()&#123; String message = &quot;SpringBoot 发送消息了&quot;; /** * 参数： * 1.交换机名称 * 2.routingKey * 3.消息内容 */ rabbitTemplate.convertAndSend(RabbitmqConfig.EXCHANGE_TOPICS_INFORM,&quot;inform.email&quot;,message); &#125;&#125; 消费端 创建消费端工程，添加依赖 参照生产端依赖即可 123456789@Componentpublic class ReceiveHandler &#123; @RabbitListener(queues = &#123;RabbitmqConfig.QUEUE_INFORM_EMAIL&#125;) public void email(String mes, Message message, Channel channel)&#123; System.out.println(&quot;接收到消息：&quot;+mes); &#125;&#125; 最后先进行测试]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ]]></title>
    <url>%2F2019%2F04%2F17%2FRabbitMQ%2F</url>
    <content type="text"><![CDATA[介绍RabbitMQ: MQ全称为Message Queue，即消息队列， RabbitMQ是由erlang语言开发，基于AMQP（Advanced MessageQueue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。RabbitMQ官方地址：http://www.rabbitmq.com/ 开发中消息队列通常有如下应用场景：1、任务异步处理。将不需要同步处理的并且耗时长的操作由消息队列通知消息接收方进行异步处理。提高了应用程序的响应时间。2、应用程序解耦合MQ相当于一个中介，生产方通过MQ与消费方交互，它将应用程序进行解耦合。 市场上还有哪些消息队列？ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ、Redis 为什么使用RabbitMQ呢？1、使得简单，功能强大。2、基于AMQP协议。3、社区活跃，文档完善。4、高并发性能好，这主要得益于Erlang语言。5、Spring Boot默认已集成RabbitMQ AMQP是什么 ？AMQP是一套公开的消息队列协议，最早在2003年被提出，它旨在从协议层定义消息通信数据的标准格式，为的就是解决MQ市场上协议不统一的问题。RabbitMQ就是遵循AMQP标准协议开发的MQ服务。 JMS是什么 ？JMS是java提供的一套消息服务API标准，其目的是为所有的java应用程序提供统一的消息通信的标准，类似java的jdbc，只要遵循jms标准的应用程序之间都可以进行消息通信。它和AMQP有什么 不同，jms是java语言专属的消息服务标准，它是在api层定义标准，并且只能用于java应用；而AMQP是在协议层定义的标准，是跨语言的 RabbitMQ的工作原理组成部分说明如下： Broker：消息队列服务进程，此进程包括两个部分：Exchange和Queue。 Exchange：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过虑。 Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方。 Producer：消息生产者，即生产方客户端，生产方客户端将消息发送到MQ。 Consumer：消息消费者，即消费方客户端，接收MQ转发的消息。消息发布接收流程：—–发送消息—– 1、生产者和Broker建立TCP连接。 2、生产者和Broker建立通道。 3、生产者通过通道消息发送给Broker，由Exchange将消息进行转发。 4、Exchange将消息转发到指定的Queue（队列）—-接收消息—– 1、消费者和Broker建立TCP连接 2、消费者和Broker建立通道 3、消费者监听指定的Queue（队列） 4、当有消息到达Queue时Broker默认将消息推送给消费者。 5、消费者接收到消息。 RabbitMQ入门程序创建两个工程生产者和消费者text-rabbitmq-producer : 生产者工程text-rabbitmq-consumer ：消费者工程 12345678910&lt;dependency&gt; &lt;groupId&gt;com.com.test.rabbitmq.config.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐logging&lt;/artifactId&gt; &lt;/dependency&gt; 代码编写： 生产者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * RabbitMQ入门程序 生产者 * */public class producer01 &#123; //队列 private static final String QUEUE = &quot;HELLO&quot;; public static void main(String args[]) &#123; //通过连接工厂对象创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置RabbitMQ连接地址 connectionFactory.setHost(&quot;127.0.0.1&quot;); //设置连接的端口 connectionFactory.setPort(5672); //登陆RabbitMQ需要用到的用户名和密码 connectionFactory.setUsername(&quot;guest&quot;); connectionFactory.setPassword(&quot;guest&quot;); //设置虚拟机,一个mq服务可以设置多个虚拟机 每个虚拟机都相当于独立的mq connectionFactory.setVirtualHost(&quot;/&quot;); //建立新连接 Connection connection = null; Channel channel = null; try &#123; connection = connectionFactory.newConnection(); //创建会话通道,生产者和mq服务所有通信都在channel通道中完成 channel = connection.createChannel(); //声明队列 如果队列在mq中 没有则要创建 //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments /** * 参数的明细 * 1.queue 队列名称 * 2.durable 是否持久化，如果持久化mq重启后队列还在 * 3.exclusive 是否独占连接 队列只允许在连接中访问，如果Connection连接关闭队列则自动删除 如果将参数设置true可用于临时队列的创建 * 4.autoDelete 自动删除 队列不再使用时是否自动删除此队列 如果将此参数和exclusive参数设置微true就可以实现临时队列（队列不用了就自动删除） * 5.arguments 参数 可以设置一个队列的扩展参数 比如设置存活时间 */ channel.queueDeclare(QUEUE,true,false,false,null); //发送消息 /** * String exchange, String routingKey, BasicProperties props, byte[] body\ * 参数明细： * \1、exchange: 交换机 如果不指定将使用MQ的默认交换机(设置为”“) * 2、routingKey：路由key，交换机根据路由key来将消息转发到指定的队列 如果使用默认交换机，routingKey设置为队列名称 * \3、props：消息属性 * 4、body：消息内容 * */ String message=&quot;Hello Word 小胖&quot;; channel.basicPublish(&quot;&quot;,QUEUE,null,message.getBytes()); System.out.println(&quot;send to mq&quot;+message); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; try &#123; connection.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 消费者：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * RabbitMQ入门程序 消费者 * */public class Consumer01 &#123; //队列 private static final String QUEUE = &quot;HELLO&quot;; public static void main(String args[]) &#123; //通过连接工厂对象创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置RabbitMQ连接地址 connectionFactory.setHost(&quot;127.0.0.1&quot;); //设置连接的端口 connectionFactory.setPort(5672); //登陆RabbitMQ需要用到的用户名和密码 connectionFactory.setUsername(&quot;guest&quot;); connectionFactory.setPassword(&quot;guest&quot;); //设置虚拟机,一个mq服务可以设置多个虚拟机 每个虚拟机都相当于独立的mq connectionFactory.setVirtualHost(&quot;/&quot;); //建立新连接 Connection connection = null; try &#123; connection = connectionFactory.newConnection(); //创建会话通道,生产者和mq服务所有通信都在channel通道中完成 Channel channel = connection.createChannel(); //监听队列 //声明队列 如果队列在mq中 没有则要创建 //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments /** * 参数的明细 * 1.queue 队列名称 * 2.durable 是否持久化，如果持久化mq重启后队列还在 * 3.exclusive 是否独占连接 队列只允许在连接中访问，如果Connection连接关闭队列则自动删除 如果将参数设置true可用于临时队列的创建 * 4.autoDelete 自动删除 队列不再使用时是否自动删除此队列 如果将此参数和exclusive参数设置微true就可以实现临时队列（队列不用了就自动删除） * 5.arguments 参数 可以设置一个队列的扩展参数 比如设置存活时间 */ channel.queueDeclare(QUEUE,true,false,false,null); //实现消费方法 DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123; /** * 当接收到消息后此方法将被调用 * @param consumerTag 消费者标签 用来标识消费者的 ，在监听队列的时候设置 * @param envelope 信封 通过envelope * @param properties 消息属性 * @param body * @throws IOException */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; //交换机 String exchange = envelope.getExchange(); //消息ID mq在channel中用来表示消息的ID 可用于确认消息已接受 long deliveryTag = envelope.getDeliveryTag(); //消息内容 String message = new String(body,&quot;UTF-8&quot;); System.out.println(&quot;接收到消息 message:&quot;+message); &#125; &#125;; //监听队列 /** * 参数 ：String queue, boolean autoAck, Consumer callback * * 1、queue：队列名称 * 2、autoAck：自动回复 当前消费者接收到消息后要告诉mq消息也接收 如果将此参数设置为true表示会自动回复mq 如果设置为false要通过编程来实现回复 * 3、callback：消费方法，当消费者接受到消息要执行的方法 * */ channel.basicConsume(QUEUE,true,defaultConsumer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; &#125; &#125;&#125; 工作模式 Publish/subscribe 发布订阅模式：1、每个消费者监听自己的队列。2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class Producer02_publish &#123; //队列 private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;; private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;; private static final String EXCHANGE_FANOUT_INFORM=&quot;exchange_fanout_inform&quot;; public static void main(String args[]) &#123; //通过连接工厂对象创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置RabbitMQ连接地址 connectionFactory.setHost(&quot;127.0.0.1&quot;); //设置连接的端口 connectionFactory.setPort(5672); //登陆RabbitMQ需要用到的用户名和密码 connectionFactory.setUsername(&quot;guest&quot;); connectionFactory.setPassword(&quot;guest&quot;); //设置虚拟机,一个mq服务可以设置多个虚拟机 每个虚拟机都相当于独立的mq connectionFactory.setVirtualHost(&quot;/&quot;); //建立新连接 Connection connection = null; Channel channel = null; try &#123; connection = connectionFactory.newConnection(); //创建会话通道,生产者和mq服务所有通信都在channel通道中完成 channel = connection.createChannel(); //声明交换机 channel.exchangeDeclare(EXCHANGE_FANOUT_INFORM, BuiltinExchangeType.FANOUT); //声明队列 如果队列在mq中 没有则要创建 //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments /** * 参数的明细 * 1.queue 队列名称 * 2.durable 是否持久化，如果持久化mq重启后队列还在 * 3.exclusive 是否独占连接 队列只允许在连接中访问，如果Connection连接关闭队列则自动删除 如果将参数设置true可用于临时队列的创建 * 4.autoDelete 自动删除 队列不再使用时是否自动删除此队列 如果将此参数和exclusive参数设置微true就可以实现临时队列（队列不用了就自动删除） * 5.arguments 参数 可以设置一个队列的扩展参数 比如设置存活时间 */ channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null); channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null); channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_FANOUT_INFORM,&quot;&quot;); channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_FANOUT_INFORM,&quot;&quot;); //发送消息 /** * String exchange, String routingKey, BasicProperties props, byte[] body\ * 参数明细： * \1、exchange: 交换机 如果不指定将使用MQ的默认交换机(设置为”“) * 2、routingKey：路由key，交换机根据路由key来将消息转发到指定的队列 如果使用默认交换机，routingKey设置为队列名称 * \3、props：消息属性 * 4、body：消息内容 * */ String message1=&quot;Hello Word 小胖&quot;; channel.basicPublish(EXCHANGE_FANOUT_INFORM,&quot;&quot;,null,message1.getBytes()); System.out.println(&quot;send to mq&quot;+message1); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; try &#123; connection.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class Consumer02_subscribe_email &#123; //队列名称 private static final String QUEUE_INFORM_EMAIL = &quot;inform_queue_email&quot;; private static final String EXCHANGE_FANOUT_INFORM=&quot;exchange_fanout_inform&quot;; public static void main(String args[]) &#123; //通过连接工厂对象创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置RabbitMQ连接地址 connectionFactory.setHost(&quot;127.0.0.1&quot;); //设置连接的端口 connectionFactory.setPort(5672); //登陆RabbitMQ需要用到的用户名和密码 connectionFactory.setUsername(&quot;guest&quot;); connectionFactory.setPassword(&quot;guest&quot;); //设置虚拟机,一个mq服务可以设置多个虚拟机 每个虚拟机都相当于独立的mq connectionFactory.setVirtualHost(&quot;/&quot;); //建立新连接 Connection connection = null; try &#123; connection = connectionFactory.newConnection(); //创建会话通道,生产者和mq服务所有通信都在channel通道中完成 Channel channel = connection.createChannel(); //声明交换机 channel.exchangeDeclare(EXCHANGE_FANOUT_INFORM,BuiltinExchangeType.FANOUT); //监听队列 //声明队列 如果队列在mq中 没有则要创建 //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments /** * 参数的明细 * 1.queue 队列名称 * 2.durable 是否持久化，如果持久化mq重启后队列还在 * 3.exclusive 是否独占连接 队列只允许在连接中访问，如果Connection连接关闭队列则自动删除 如果将参数设置true可用于临时队列的创建 * 4.autoDelete 自动删除 队列不再使用时是否自动删除此队列 如果将此参数和exclusive参数设置微true就可以实现临时队列（队列不用了就自动删除） * 5.arguments 参数 可以设置一个队列的扩展参数 比如设置存活时间 */ channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null); //交换机和队列绑定 /** * 参数明细 * 1、队列名称 * 2、交换机名称 * 3、路由key */ channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_FANOUT_INFORM,&quot;&quot;); //实现消费方法 DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123; /** * 当接收到消息后此方法将被调用 * @param consumerTag 消费者标签 用来标识消费者的 ，在监听队列的时候设置 * @param envelope 信封 通过envelope * @param properties 消息属性 * @param body * @throws IOException */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; //交换机 String exchange = envelope.getExchange(); //消息ID mq在channel中用来表示消息的ID 可用于确认消息已接受 long deliveryTag = envelope.getDeliveryTag(); //消息内容 String message = new String(body,&quot;UTF-8&quot;); System.out.println(&quot;邮件接收到消息 message:&quot;+message); &#125; &#125;; //监听队列 /** * 参数 ：String queue, boolean autoAck, Consumer callback * * 1、queue：队列名称 * 2、autoAck：自动回复 当前消费者接收到消息后要告诉mq消息也接收 如果将此参数设置为true表示会自动回复mq 如果设置为false要通过编程来实现回复 * 3、callback：消费方法，当消费者接受到消息要执行的方法 * */ channel.basicConsume(QUEUE_INFORM_EMAIL,true,defaultConsumer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; &#125; &#125;&#125; Consumer02_subscribe_sms 短信消费者和邮件代码一样 publish/subscribe与work queues有什么区别。区别：1.work queues不用定义交换机，而publish/subscribe需要定义交换机。2.publish/subscribe的生产方是面向交换机发送消息，work queues的生产方是面向队列发送消息(底层使用默认交换机)。3.publish/subscribe需要设置队列和交换机的绑定，work queues不需要设置，实质上work queues会将队列绑定到默认的交换机 。相同点：所以两者实现的发布/订阅的效果是一样的，多个消费端监听同一个队列不会重复消费消息。 2、实质工作用什么 publish/subscribe还是work queues。建议使用 publish/subscribe，发布订阅模式比工作队列模式更强大，并且发布订阅模式可以指定自己专用的交换机。 Routing路由模式：1、每个消费者监听自己的队列，并且设置routingkey。2、生产者将消息发给交换机，由交换机根据routingkey来转发消息到指定的队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class Producer03_routing &#123; //队列 private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;; private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;; private static final String EXCHANGE_ROUTING_INFORM=&quot;exchange_routing_inform&quot;; public static void main(String args[]) &#123; //通过连接工厂对象创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置RabbitMQ连接地址 connectionFactory.setHost(&quot;127.0.0.1&quot;); //设置连接的端口 connectionFactory.setPort(5672); //登陆RabbitMQ需要用到的用户名和密码 connectionFactory.setUsername(&quot;guest&quot;); connectionFactory.setPassword(&quot;guest&quot;); //设置虚拟机,一个mq服务可以设置多个虚拟机 每个虚拟机都相当于独立的mq connectionFactory.setVirtualHost(&quot;/&quot;); //建立新连接 Connection connection = null; Channel channel = null; try &#123; connection = connectionFactory.newConnection(); //创建会话通道,生产者和mq服务所有通信都在channel通道中完成 channel = connection.createChannel(); //声明交换机 channel.exchangeDeclare(EXCHANGE_ROUTING_INFORM, BuiltinExchangeType.DIRECT); //声明队列 如果队列在mq中 没有则要创建 //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments /** * 参数的明细 * 1.queue 队列名称 * 2.durable 是否持久化，如果持久化mq重启后队列还在 * 3.exclusive 是否独占连接 队列只允许在连接中访问，如果Connection连接关闭队列则自动删除 如果将参数设置true可用于临时队列的创建 * 4.autoDelete 自动删除 队列不再使用时是否自动删除此队列 如果将此参数和exclusive参数设置微true就可以实现临时队列（队列不用了就自动删除） * 5.arguments 参数 可以设置一个队列的扩展参数 比如设置存活时间 */ channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null); channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null); //交换机和队列绑定String queue, String exchange, String routingKey /** * 参数明细 * 1、队列名称 * 2、交换机名称 * 3、路由key */ channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_ROUTING_INFORM,QUEUE_INFORM_EMAIL); channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_ROUTING_INFORM,QUEUE_INFORM_SMS); //发送消息 /** * String exchange, String routingKey, BasicProperties props, byte[] body\ * 参数明细： * \1、exchange: 交换机 如果不指定将使用MQ的默认交换机(设置为”“) * 2、routingKey：路由key，交换机根据路由key来将消息转发到指定的队列 如果使用默认交换机，routingKey设置为队列名称 * \3、props：消息属性 * 4、body：消息内容 * */ String message1=&quot;Hello Word 小胖&quot;; channel.basicPublish(EXCHANGE_ROUTING_INFORM,QUEUE_INFORM_EMAIL,null,message1.getBytes()); channel.basicPublish(EXCHANGE_ROUTING_INFORM,QUEUE_INFORM_SMS,null,message1.getBytes()); System.out.println(&quot;send to mq&quot;+message1); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; try &#123; connection.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class Consumer03_routing_email &#123; //队列名称 private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;; private static final String EXCHANGE_ROUTING_INFORM=&quot;exchange_routing_inform&quot;; public static void main(String args[]) &#123; //通过连接工厂对象创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); //设置RabbitMQ连接地址 connectionFactory.setHost(&quot;127.0.0.1&quot;); //设置连接的端口 connectionFactory.setPort(5672); //登陆RabbitMQ需要用到的用户名和密码 connectionFactory.setUsername(&quot;guest&quot;); connectionFactory.setPassword(&quot;guest&quot;); //设置虚拟机,一个mq服务可以设置多个虚拟机 每个虚拟机都相当于独立的mq connectionFactory.setVirtualHost(&quot;/&quot;); //建立新连接 Connection connection = null; try &#123; connection = connectionFactory.newConnection(); //创建会话通道,生产者和mq服务所有通信都在channel通道中完成 Channel channel = connection.createChannel(); //声明交换机 channel.exchangeDeclare(EXCHANGE_ROUTING_INFORM, BuiltinExchangeType.DIRECT); //监听队列 //声明队列 如果队列在mq中 没有则要创建 //String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments /** * 参数的明细 * 1.queue 队列名称 * 2.durable 是否持久化，如果持久化mq重启后队列还在 * 3.exclusive 是否独占连接 队列只允许在连接中访问，如果Connection连接关闭队列则自动删除 如果将参数设置true可用于临时队列的创建 * 4.autoDelete 自动删除 队列不再使用时是否自动删除此队列 如果将此参数和exclusive参数设置微true就可以实现临时队列（队列不用了就自动删除） * 5.arguments 参数 可以设置一个队列的扩展参数 比如设置存活时间 */ channel.queueDeclare(QUEUE_INFORM_EMAIL, true, false, false, null); //交换机和队列绑定 /** * 参数明细 * 1、队列名称 * 2、交换机名称 * 3、路由key */ channel.queueBind(QUEUE_INFORM_EMAIL, EXCHANGE_ROUTING_INFORM, QUEUE_INFORM_EMAIL); //实现消费方法 DefaultConsumer defaultConsumer = new DefaultConsumer(channel) &#123; /** * 当接收到消息后此方法将被调用 * @param consumerTag 消费者标签 用来标识消费者的 ，在监听队列的时候设置 * @param envelope 信封 通过envelope * @param properties 消息属性 * @param body * @throws IOException */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; //交换机 String exchange = envelope.getExchange(); //消息ID mq在channel中用来表示消息的ID 可用于确认消息已接受 long deliveryTag = envelope.getDeliveryTag(); //消息内容 String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot;邮件接收到消息 message:&quot; + message); &#125; &#125;; //监听队列 /** * 参数 ：String queue, boolean autoAck, Consumer callback * * 1、queue：队列名称 * 2、autoAck：自动回复 当前消费者接收到消息后要告诉mq消息也接收 如果将此参数设置为true表示会自动回复mq 如果设置为false要通过编程来实现回复 * 3、callback：消费方法，当消费者接受到消息要执行的方法 * */ channel.basicConsume(QUEUE_INFORM_EMAIL, true, defaultConsumer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; &#125; &#125;&#125; Routing模式和Publish/subscibe有啥区别？Routing模式要求队列在绑定交换机时要指定routingkey，消息会转发到符合routingkey的队列。 Topics 路由模式：1、每个消费者监听自己的队列，并且设置带统配符的routingkey。2、生产者将消息发给broker，由交换机根据routingkey来转发消息到指定的队列。 生产者声明交换机，指定topic类型： 123456789101112/*** 声明交换机* param1：交换机名称* param2:交换机类型 四种交换机类型：direct、fanout、topic、headers*/channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC);//Email通知channel.basicPublish(EXCHANGE_TOPICS_INFORM, &quot;inform.email&quot;, null, message.getBytes());//sms通知channel.basicPublish(EXCHANGE_TOPICS_INFORM, &quot;inform.sms&quot;, null, message.getBytes());//两种都通知channel.basicPublish(EXCHANGE_TOPICS_INFORM, &quot;inform.sms.email&quot;, null, message.getBytes()); 消费端队列绑定交换机指定通配符：统配符规则：中间以“.”分隔。符号#可以匹配多个词，符号*可以匹配一个词语。123456789//声明队列channel.queueDeclare(QUEUE_INFORM_EMAIL, true, false, false, null);channel.queueDeclare(QUEUE_INFORM_SMS, true, false, false, null);//声明交换机channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC);//绑定email通知队列channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_TOPICS_INFORM,&quot;inform.#.email.#&quot;);//绑定sms通知队列channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_TOPICS_INFORM,&quot;inform.#.sms.#&quot;); 使用生产者发送若干条消息，交换机根据routingkey统配符匹配并转发消息到指定的队列。 使用Routing模式也可以实现本案例，共设置三个 routingkey，分别是email、sms、all，email队列绑定email和all，sms队列绑定sms和all，这样就可以实现上边案例的功能，实现过程比topics复杂。Topic模式更多加强大，它可以实现Routing、publish/subscirbe模式的功能 Header模式header模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。 生产者队列与交换机绑定的代码与之前不同， 123456Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;();headers_email.put(&quot;inform_type&quot;, &quot;email&quot;);Map&lt;String, Object&gt; headers_sms = new Hashtable&lt;String, Object&gt;();headers_sms.put(&quot;inform_type&quot;, &quot;sms&quot;);channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,&quot;&quot;,headers_email);channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_HEADERS_INFORM,&quot;&quot;,headers_sms); 通知：12345678String message = &quot;email inform to user&quot;+i;Map&lt;String,Object&gt; headers = new Hashtable&lt;String, Object&gt;();headers.put(&quot;inform_type&quot;, &quot;email&quot;);//匹配email通知消费者绑定的header//headers.put(&quot;inform_type&quot;, &quot;sms&quot;);//匹配sms通知消费者绑定的headerAMQP.BasicProperties.Builder properties = new AMQP.BasicProperties.Builder();properties.headers(headers);//Email通知channel.basicPublish(EXCHANGE_HEADERS_INFORM, &quot;&quot;, properties.build(), message.getBytes()); 发送邮件消费者1234567channel.exchangeDeclare(EXCHANGE_HEADERS_INFORM, BuiltinExchangeType.HEADERS);Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;();headers_email.put(&quot;inform_email&quot;, &quot;email&quot;);//交换机和队列绑定channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,&quot;&quot;,headers_email);//指定消费队列channel.basicConsume(QUEUE_INFORM_EMAIL, true, consumer) RPC RPC即客户端远程调用服务端的方法 ，使用MQ可以实现RPC的异步调用，基于Direct交换机实现，流程如下：1、客户端即是生产者就是消费者，向RPC请求队列发送RPC调用消息，同时监听RPC响应队列。2、服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果3、服务端将RPC方法 的结果发送到RPC响应队列4、客户端（RPC调用方）监听RPC响应队列，接收到RPC调用结果。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GridFS研究]]></title>
    <url>%2F2019%2F04%2F15%2FGridFS%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[GridFS介绍GridFS是MongoDB提供的用于持久化存储文件的模块，CMS使用MongoDB存储数据，使用GridFS可以快速集成开发 GridFS工作原理：在GridFS存储文件是将文件分块存储，文件会按照256KB的大小分割成多个块进行存储，GridFS使用两个集合（collection）存储文件，一个集合是chunks, 用于存储文件的二进制数据；一个集合是files，用于存储文件的元数据信息（文件名称、块大小、上传时间等信息）。从GridFS中读取文件要对文件的各各块进行组装、合并。 这是MongoDB数据库中默认存储文件的两个集合 GridFS存取文件测试存文件123456789101112131415@Autowired private GridFsTemplate gridFsTemplate; @Test public void testStore() throws Exception &#123; //要存储的文件 File file = new File(&quot;d:/index_banner.ftl&quot;); //定义输入流 FileInputStream inputStram = new FileInputStream(file); //向GridFS存储文件 ObjectId objectId = gridFsTemplate.store(inputStram, &quot;index_banner.ftl&quot;); //得到文件ID String fileId = objectId.toString(); System.out.println(fileId); &#125; 存储原理说明：文件存储成功得到一个文件id此文件id是fs.files集合中的主键。可以通过文件id查询fs.chunks表中的记录，得到文件的内容 取文件在config包中定义Mongodb的配置类，如下：GridFSBucket用于打开下载流对象1234567891011121314@Configurationpublic class MongoConfig &#123; //MongoDB数据库名 @Value(&quot;$&#123;spring.data.mongodb.database&#125;&quot;) String db; @Bean public GridFSBucket getGridFSBucket(MongoClient mongoClient)&#123; MongoDatabase database = mongoClient.getDatabase(db); GridFSBucket bucket = GridFSBuckets.create(database); return bucket; &#125;&#125; 测试取文件代码：1234567891011121314151617 @Test public void queryFile() throws IOException &#123; //根据文件id查询文件 findOne表示查询单个文件 GridFSFile gridFSFile = gridFsTemplate.findOne(Query.query(Criteria.where(&quot;_id&quot;).is(&quot;5a7719d76abb5042987eec3a&quot;)));//打开一个下载流对象 GridFSDownloadStream gridFSDownloadStream = gridFSBucket.openDownloadStream(gridFSFile.getObjectId());//创建GridFsResource对象，获取流 GridFsResource gridFsResource = new GridFsResource(gridFSFile, gridFSDownloadStream);//从流中获取文件数据 String s = IOUtils.toString(gridFsResource.getInputStream(), &quot;UTF-8&quot;);//打印数据 System.out.println(s); &#125;]]></content>
      <categories>
        <category>文件存储</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC]]></title>
    <url>%2F2019%2F04%2F11%2FSpringMVC%2F</url>
    <content type="text"><![CDATA[简介SpringMVC 是类似于 Struts2 的一个 MVC 框架，在实际开发中，接收浏览器的请求响应，对数据进行处理，然后返回页面进行显示，但是上手难度却比 Struts2 简单多了。而且由于 Struts2 所暴露出来的安全问题，SpringMVC 已经成为了大多数企业优先选择的框架。 SpringMVC是一种基于Java，实现了Web MVC设计模式，请求驱动类型的轻量级Web框架，即使用了MVC架构模式的思想，将Web层进行职责解耦。基于请求驱动指的就是使用请求-响应模型，框架的目的就是帮助我们简化开发，SpringMVC也是要简化我们日常Web开发 MVC设计模式MVC设计模式的任务是将包含业务数据的模块与显示模块的视图解耦。这是怎样发生的？在模型和视图之间引入重定向层可以解决问题。此重定向层是控制器，控制器将接收请求，执行更新模型的操作，然后通知视图关于模型更改的消息。 SpringMVC工作流程SpringMVC提供了总开关DispatcherServlet；请求处理映射器(Handler Mapping)和处理适配器（Handler Adapter），视图解析器(View Resolver)进行视图管理；动作处理器Controller接口（包含ModelAndView，以及处理请求响应对象request和response），配置灵活，支持文件上传，数据简单转化等强大功能 客户端通过url发送请求 核心控制器Dispatcher Servlet接收到请求，通过系统或自定义的映射器配置找到对应的handler，并将url映射的控制器controller返回给核心控制器。 通过核心控制器找到系统或默认的适配器 由找到的适配器，调用实现对应接口的处理器，并将结果返回给适配器，结果中包含数据模型和视图对象，再由适配器返回给核心控制器 核心控制器将获取的数据和视图结合的对象传递给视图解析器，获取解析得到的结果，并由视图解析器响应给核心控制器 核心控制器将结果返回给客户端 适配器作用SpringMVC涉及的映射器，视图解析器的作用不难理解，映射器负责将前端请求的url映射到配置的处理器，视图解析器将最终的结果进行解析，但中间为什么要经过一层适配器呢，为什么不经映射器找到controller后直接执行返回呢？ 那是因为SpringMVC为业务处理器提供了多种接口实现（例如实现了Controller接口），而适配器就是用来根据处理器实现了什么接口，最终选择与已经注册好的不同类型的Handler Adapter进行匹配，并最终执行，例如，SimpleControllerHandlerAdapter是支持实现了controller接口的控制器，如果自己写的控制器实现了controller接口，那么SimpleControllerHandlerAdapter就会去执行自己写的控制器中的具体方法来完成请求。 SpringMVC配置创建工程和导入依赖12345678910111213141516171819202122232425262728293031323334353637&lt;properties&gt; &lt;spring-base-version&gt;5.1.3.RELEASE&lt;/spring-base-version&gt; &lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-base-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-base-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-base-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-base-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-base-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置web.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;!-- 在Spring框架中是如何解决从页面传来的字符串的编码问题的呢？ 下面我们来看看Spring框架给我们提供过滤器CharacterEncodingFilter 这个过滤器就是针对于每次浏览器请求进行过滤的，然后再其之上添加了父类没有的功能即处理字符编码。 其中encoding用来设置编码格式，forceEncoding用来设置是否理会 request.getCharacterEncoding()方法，设置为true则强制覆盖之前的编码格式。--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--2、部署applicationContext的xml文件--&gt; &lt;!--如果在web.xml中不写任何参数配置信息，默认的路径是&quot;/WEB-INF/applicationContext.xml， 在WEB-INF目录下创建的xml文件的名称必须是applicationContext.xml。 如果是要自定义文件名可以在web.xml里加入contextConfigLocation这个context参数： 在&lt;param-value&gt; &lt;/param-value&gt;里指定相应的xml文件名，如果有多个xml文件，可以写在一起并以“,”号分隔。 也可以这样applicationContext-*.xml采用通配符，比如这那个目录下有applicationContext-ibatis-base.xml， applicationContext-action.xml，applicationContext-ibatis-dao.xml等文件，都会一同被载入。 在ContextLoaderListener中关联了ContextLoader这个类，所以整个加载配置过程由ContextLoader来完成。--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--配置spring前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springApplication.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 在resources下新建springApplication.xml文件，文件内容如下:12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.1.xsd&quot;&gt; &lt;!-- 开启注解包扫描--&gt; &lt;context:component-scan base-package=&quot;com.heibaiying.*&quot;/&gt; &lt;!--使用默认的Servlet来响应静态文件 详见 1.2 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 开启注解驱动 详见 1.2 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; id=&quot;internalResourceViewResolver&quot;&gt; &lt;!-- 前缀 --&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;!-- 后缀 --&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 相关配置讲解mvc:default-servlet-handler/在web.xml配置中，我们将DispatcherServlet的拦截路径设置为“\”，则spring会捕获所有web请求，包括对静态资源的请求，为了正确处理对静态资源的请求，spring提供了两种解决方案： 配置mvc:default-servlet-handler/ ： 配置&lt;mvc:default-servlet-handler /&gt;后，会在Spring MVC上下文中定义一个org.springframework.web.servlet.resource.DefaultServletHttpRequestHandler，它会对进入DispatcherServlet的URL进行筛查，如果发现是静态资源的请求，就将该请求转由Web应用服务器默认的Servlet处理，如果不是静态资源的请求，才由DispatcherServlet继续处理。 配置&lt;mvc:resources /&gt; ：指定静态资源的位置和路径映射： 123&lt;mvc:resources location=&quot;/img/&quot; mapping=&quot;/img/**&quot;/&gt; &lt;mvc:resources location=&quot;/js/&quot; mapping=&quot;/js/**&quot;/&gt; &lt;mvc:resources location=&quot;/css/&quot; mapping=&quot;/css/**&quot;/&gt; mvc:annotation-driven/&lt;mvc:annotation-driven /&gt; 会自动注册DefaultAnnotationHandlerMapping与AnnotationMethodHandlerAdapter两个bean,用以支持@Controllers分发请求。并提供了数据绑定、参数转换、json转换等功能，所以必须加上这个配置。 配置自定义拦截器创建自定义拦截器，实现接口HandlerInterceptor（这里我们创建两个拦截器，用于测试拦截器方法的执行顺序） 12345678910111213141516171819202122232425262728package com.heibaiying.interceptors;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author : heibaiying * @description : spring5 中 preHandle，postHandle，afterCompletion 在接口中被声明为默认方法 */public class MyFirstInterceptor implements HandlerInterceptor &#123; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; System.out.println(&quot;进入第一个拦截器preHandle&quot;); return true; &#125; // 需要注意的是，如果对应的程序报错，不一定会进入这个方法 但一定会进入afterCompletion这个方法 public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; System.out.println(&quot;进入第一个拦截器postHandle&quot;); &#125; public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; System.out.println(&quot;进入第一个拦截器afterCompletion&quot;); &#125;&#125; 123456789101112131415161718192021222324252627package com.heibaiying.interceptors;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author : heibaiying * @description : spring5 中 preHandle，postHandle，afterCompletion 在接口中被声明为默认方法 */public class MySecondInterceptor implements HandlerInterceptor &#123; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; System.out.println(&quot;进入第二个拦截器preHandle&quot;); return true; &#125; public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; System.out.println(&quot;进入第二个拦截器postHandle&quot;); &#125; public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; System.out.println(&quot;进入第二个拦截器afterCompletion&quot;); &#125;&#125; 在springApplication.xml中注册自定义拦截器 123456789101112&lt;!--配置拦截器--&gt; &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/mvc/**&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/mvc/login&quot;/&gt; &lt;bean class=&quot;com.heibaiying.interceptors.MyFirstInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/mvc/**&quot;/&gt; &lt;bean class=&quot;com.heibaiying.interceptors.MySecondInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 关于多个拦截器方法执行顺序的说明: 拦截器的执行顺序是按声明的先后顺序执行的，先声明的拦截器中的preHandle方法会先执行，然而它的postHandle方法和afterCompletion方法却会后执行。 全局异常处理定义自定义异常12345678910111213141516171819202122232425package com.heibaiying.exception;/** * @author : heibaiying * @description : 自定义无权限异常 */public class NoAuthException extends RuntimeException &#123; public NoAuthException() &#123; super(); &#125; public NoAuthException(String message) &#123; super(message); &#125; public NoAuthException(String message, Throwable cause) &#123; super(message, cause); &#125; public NoAuthException(Throwable cause) &#123; super(cause); &#125;&#125; 实现自定义异常处理器1234567891011121314151617181920212223242526package com.heibaiying.exception;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author : heibaiying * @description : 无权限异常处理机制 */public class NoAuthExceptionResolver implements HandlerExceptionResolver &#123; public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; if (ex instanceof NoAuthException &amp;&amp; !isAjax(request)) &#123; return new ModelAndView(&quot;NoAuthPage&quot;); &#125; return new ModelAndView(); &#125; // 判断是否是Ajax请求 private boolean isAjax(HttpServletRequest request) &#123; return &quot;XMLHttpRequest&quot;.equalsIgnoreCase(request.getHeader(&quot;X-Requested-With&quot;)); &#125;&#125; 在springApplication.xml注册自定义异常处理器 定义测试controller，抛出自定义异常123456789101112131415@Controller@RequestMapping(&quot;mvc&quot;)public class HelloController &#123; @RequestMapping(&quot;hello&quot;) private String hello() &#123; return &quot;hello&quot;; &#125; @RequestMapping(&quot;auth&quot;) private void auth() &#123; throw new NoAuthException(&quot;没有对应的访问权限！&quot;); &#125;&#125; 调用这个controller时，同时也可以验证在拦截器部分提到的：如果对应的程序报错，拦截器不一定会进入postHandle这个方法 但一定会进入afterCompletion这个方法 文件上传与下载在springApplication.xml中进行配置，使之支持文件上传 12345678&lt;!--配置文件上传--&gt; &lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!--文件最大限制--&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;102400000&quot;/&gt; &lt;!--单个文件最大限制--&gt; &lt;property name=&quot;maxUploadSizePerFile&quot; value=&quot;10240000&quot;/&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;utf-8&quot;/&gt; &lt;/bean&gt; 新建测试上传的FileController.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.heibaiying.controller;import com.heibaiying.utils.FileUtil;import org.apache.commons.io.FileUtils;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.multipart.MultipartFile;import javax.servlet.http.HttpSession;import java.io.File;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.net.URLEncoder;/** * @author : heibaiying * @description : 文件上传 */@Controllerpublic class FileController &#123; @GetMapping(&quot;file&quot;) public String filePage() &#123; return &quot;file&quot;; &#125; /*** * 单文件上传 */ @PostMapping(&quot;upFile&quot;) public String upFile(MultipartFile file, HttpSession session) &#123; //保存在项目根目录下image文件夹下，如果文件夹不存在则创建 FileUtil.saveFile(file, session.getServletContext().getRealPath(&quot;/image&quot;)); // success.jsp 就是一个简单的成功页面 return &quot;success&quot;; &#125; /*** * 多文件上传 多个文件用同一个名字 */ @PostMapping(&quot;upFiles&quot;) public String upFiles(@RequestParam(name = &quot;file&quot;) MultipartFile[] files, HttpSession session) &#123; for (MultipartFile file : files) &#123; FileUtil.saveFile(file, session.getServletContext().getRealPath(&quot;images&quot;)); &#125; return &quot;success&quot;; &#125; /*** * 多文件上传方式2 分别为不同文件指定不同名字 */ @PostMapping(&quot;upFiles2&quot;) public String upFile(String extendParam, @RequestParam(name = &quot;file1&quot;) MultipartFile file1, @RequestParam(name = &quot;file2&quot;) MultipartFile file2, HttpSession session) &#123; String realPath = session.getServletContext().getRealPath(&quot;images2&quot;); FileUtil.saveFile(file1, realPath); FileUtil.saveFile(file2, realPath); System.out.println(&quot;extendParam:&quot; + extendParam); return &quot;success&quot;; &#125;&#125; 其中工具类FileUtil.java代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.heibaiying.utils;import org.springframework.web.multipart.MultipartFile;import java.io.*;/** * @author : heibaiying * @description : 文件上传工具类 */public class FileUtil &#123; public static String saveFile(MultipartFile file, String path) &#123; InputStream inputStream = null; FileOutputStream outputStream = null; String fullPath = path + File.separator + file.getOriginalFilename(); try &#123; File saveDir = new File(path); if (!saveDir.exists()) &#123; saveDir.mkdirs(); &#125; outputStream = new FileOutputStream(new File(fullPath)); inputStream = file.getInputStream(); byte[] bytes = new byte[1024 * 1024]; int read; while ((read = inputStream.read(bytes)) != -1) &#123; outputStream.write(bytes, 0, read); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (outputStream != null) &#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return fullPath; &#125;&#125; 新建用于上传的jsp页面，上传文件时表单必须声明 enctype=“multipart/form-data” 123456789101112131415161718192021222324252627&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;文件上传&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;$&#123;pageContext.request.contextPath&#125;/css/file.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath &#125;/upFile&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; 请选择上传文件：&lt;input name=&quot;file&quot; type=&quot;file&quot;&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;点击上传文件&quot;&gt; &lt;/form&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath &#125;/upFiles&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; 请选择上传文件(多选)：&lt;input name=&quot;file&quot; type=&quot;file&quot; multiple&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;点击上传文件&quot;&gt; &lt;/form&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath &#125;/upFiles2&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; 请选择上传文件1：&lt;input name=&quot;file1&quot; type=&quot;file&quot;&gt;&lt;br&gt; 请选择上传文件2：&lt;input name=&quot;file2&quot; type=&quot;file&quot;&gt;&lt;br&gt; 文件内容额外备注: &lt;input name=&quot;extendParam&quot; type=&quot;text&quot;&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;点击上传文件&quot;&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 文件下载在fileController.java中加上方法： 1234567891011121314151617181920212223242526/*** * 上传用于下载的文件 */ @PostMapping(&quot;upFileForDownload&quot;) public String upFileForDownload(MultipartFile file, HttpSession session, Model model) throws UnsupportedEncodingException &#123; String path = FileUtil.saveFile(file, session.getServletContext().getRealPath(&quot;/image&quot;)); model.addAttribute(&quot;filePath&quot;, URLEncoder.encode(path,&quot;utf-8&quot;)); model.addAttribute(&quot;fileName&quot;, file.getOriginalFilename()); return &quot;fileDownload&quot;; &#125; /*** * 下载文件 */ @GetMapping(&quot;download&quot;) public ResponseEntity&lt;byte[]&gt; downloadFile(String filePath) throws IOException &#123; HttpHeaders headers = new HttpHeaders(); File file = new File(filePath); // 解决文件名中文乱码 String fileName=new String(file.getName().getBytes(&quot;UTF-8&quot;),&quot;iso-8859-1&quot;); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); headers.setContentDispositionFormData(&quot;attachment&quot;, fileName); return new ResponseEntity&lt;byte[]&gt;(FileUtils.readFileToByteArray(file), headers, HttpStatus.CREATED); &#125; 其中fileDownload.jsp 如下： 123456789&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;文件下载&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;a href=&quot;$&#123;pageContext.request.contextPath&#125;/download?filePath=$&#123;filePath&#125;&quot;&gt;$&#123;fileName&#125;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>基本框架</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack之proxyTable设置跨域]]></title>
    <url>%2F2019%2F04%2F11%2Fwebpack%E4%B9%8BproxyTable%E8%AE%BE%E7%BD%AE%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[为什么要使用proxyTable很简单，两个字，跨域。在平时项目的开发环境中，经常会遇到跨域的问题，尤其是使用vue-cli这种脚手架工具开发时，由于项目本身启动本地服务是需要占用一个端口的，所以必然会产生跨域的问题。当然跨域有多种解决方式，这里就不一一例举，下次弄篇文章单独讲，在使用webpack做构建工具的项目中使用proxyTable代理实现跨域是一种比较方便的选择。 如何使用proxyTable拿之前使用过的vue-cli举例。我们首先要在项目目录中找到根目录下config文件夹下的index.js文件。由于我们是在开发环境下使用，自然而然是要配置在dev里面 上面这段代码的效果就是将本地11001端口的一个请求代理到了http://localhost:31001这一域名下： ‘http://localhost:11001/api/cms&#39; ===&gt; http://localhost:31001/cms 关于proxyTable的原理这个代理实际上是利用http-proxy-middleware这个插件完成的，具体到这个插件的运行机制，由于是英文再加上能力有限就没深究了。但我想探究的是这种代理方式实际上是如何做到的，实际上就是我们的本地服务器将请求转发给了目标服务器。之所以出现跨域是因为浏览器有同源策略的限制，但服务器是没有的，所以这种代理方式能够实现的机制大体就是： 本地服务器 –》 代理 –》目标服务器 –》拿到数据后通过代理伪装成本地服务请求的返回值 —》然后浏览器就顺利收到了我们想要的数据 这是我的简单理解]]></content>
      <categories>
        <category>跨域</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSI]]></title>
    <url>%2F2019%2F04%2F11%2FSSI%2F</url>
    <content type="text"><![CDATA[SSI服务端包含技术页面内容多如何管理？将页面拆分成一个一个的小页面，通过cms去管理这些小页面，当要更改部分页面内容时只需要更改具体某个小页面即可。 页面拆出来怎么样通过web服务浏览呢？使用web服务(例如nginx)的SSI技术，将多个子页面合并渲染输出 SSI是什么？ ssi包含类似于jsp页面中的incluce指令，ssi是在web服务端将include指定 的页面包含在网页中，渲染html网页响应给客户端 。nginx、apache等多数web容器都支持SSI指令。 ssi指令如下： &lt;!‐‐#include virtual=”/../….html”‐‐&gt; 将首页拆分成12345index.html：首页主体内容include/header.html：头部区域include/index_banner.html：轮播图include/index_category.html：左侧列表导航include/footer.html：页尾 在nginx虚拟主机中开通SSI 12345678910111213141516server&#123; listen 80; server_name www.xuecheng.com; # 开启ssi支持，默认为false ssi on; #设置为on表示在处理ssi文件时不输出错误信息，默认为false ssi_silent_errors on; location / &#123; alias 文件路径; index index.html; &#125; ssi的配置参数如下：ssi on： 开启ssi支持ssi_silent_errors on：默认为off，设置为on则在处理SSI文件出错时不输出错误信息ssi_types：默认为 ssi_types text/html，如果需要支持shtml（服务器执行脚本，类似于jsp）则需要设置为ssi_types text/shtml]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接口开发规范]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%8E%A5%E5%8F%A3%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[Api请求及响应规范为了严格按照接口进行开发，提高效率，对请求及响应格式进行规范化。1、get 请求时，采用key/value格式请求，SpringMVC可采用基本类型的变量接收，也可以采用对象接收。2、Post请求时，可以提交form表单数据（application/x-www-form-urlencoded）和Json数据（ContentType=application/json），文件等多部件类型（multipart/form-data）三种数据格式，SpringMVC接收Json数据使用@RequestBody注解解析请求的json数据。4、响应结果统一信息为：是否成功、操作代码、提示信息及自定义数据。5、响应结果统一格式为json。 Api定义约束Api定义使用SpringMVC来完成，由于此接口后期将作为微服务远程调用使用，在定义接口时有如下限制：1、@PathVariable 统一指定参数名称，如：@PathVariable(“id”) 2、@RequestParam统一指定参数名称，如：@RequestParam（”id”） 页面查询接口测试基于服务端编写接口，如果前端人员等待服务端人员将接口开发完毕再去开发前端内容这样做效率是非常低下的，所以当接口定义完成，可以使用工具生成接口文档，前端人员查看接口文档即可进行前端开发，这样前端和服务人员并行开发，大大提高了生产效率。 这里介绍两种接口开发工具，Swagger和Postman。 Swagger Swagger介绍 OpenAPI规范（OpenAPI Specification 简称OAS）是Linux基金会的一个项目，试图通过定义一种用来描述API格式或API定义的语言，来规范RESTful服务开发过程，目前版本是V3.0，并且已经发布并开源在github上。（https://github.com/OAI/OpenAPI-Specification）Swagger是全球最大的OpenAPI规范（OAS）API开发工具框架，支持从设计和文档到测试和部署的整个API生命周期的开发。 (https://swagger.io/)Spring Boot 可以集成Swagger，生成Swagger接口，Spring Boot是Java领域的神器，它是Spring项目下快速构建项目的框架。 Swagger常用注解 在Java类中添加Swagger的注解即可生成Swagger接口，常用Swagger注解如下： @Api：修饰整个类，描述Controller的作用@ApiOperation：描述一个类的一个方法，或者说一个接口@ApiParam：单个参数描述@ApiModel：用对象来接收参数@ApiModelProperty：用对象接收参数时，描述对象的一个字段@ApiResponse：HTTP响应其中1个描述@ApiResponses：HTTP响应整体描述@ApiIgnore：使用该注解忽略这个API@ApiError ：发生错误返回的信息@ApiImplicitParam：一个请求参数@ApiImplicitParams：多个请求参数@ApiImplicitParam属性： Swagger接口定义 修改接口工程中页面查询接口，添加Swagger注解 1234567891011@Api(value=&quot;cms页面管理接口&quot;,description = &quot;cms页面管理接口，提供页面的增、删、改、查&quot;)public interface CmsPageControllerApi &#123;@ApiOperation(&quot;分页查询页面列表&quot;)@ApiImplicitParams(&#123;@ApiImplicitParam(name=&quot;page&quot;,value = &quot;页码&quot;,required=true,paramType=&quot;path&quot;,dataType=&quot;int&quot;),@ApiImplicitParam(name=&quot;size&quot;,value = &quot;每页记录数&quot;,required=true,paramType=&quot;path&quot;,dataType=&quot;int&quot;)&#125;)public QueryResponseResult findList(int page, int size, QueryPageRequest queryPageRequest) ;&#125; 在实体类中还是 BO 或者是 VO 使用注解 ApiModelProperty 对属性注释： 123456789101112131415161718@Datapublic class QueryPageRequest extends RequestData &#123;//站点id@ApiModelProperty(&quot;站点id&quot;)private String siteId;//页面ID@ApiModelProperty(&quot;页面ID&quot;)private String pageId;//页面名称@ApiModelProperty(&quot;页面名称&quot;)private String pageName;//页面别名@ApiModelProperty(&quot;页面别名&quot;)private String pageAliase;//模版id@ApiModelProperty(&quot;模版id&quot;)private String templateId;&#125; Swagger接口测试Swagger接口生成工作原理：1、系统启动，扫描到api工程中的Swagger2Configuration类2、在此类中指定了包路径com.xuecheng，找到在此包下及子包下标记有@RestController注解的controller类3、根据controller类中的Swagger注解生成接口文档。 启动服务工程，查看接口文档，根据IP和端口查询 这里是请求：http://localhost:31001/swagger-ui.html 使用Swagger工具测试服务接口：1.在cms服务接口中打断点2.打开接口文档页面，输入请求参数，点击“Try it out”发起请求 PostmanPostman是一款功能强大的http接口测试工具，使用postman可以完成http各种请求的功能测试。官方地址：https://www.getpostman.com/1、安装Postman本教程使用，双击打开 Postman-win64-6.0.10-Setup.exe新建一个Postman窗口 使用postman测试http接口 请求参数设置 get请求参数设置 form-data：将表单的数据转为键值对，并且可以包括文件x-www-form-urlencoded: content-type为application/x-www-from-urlencoded，将表单的数据转为键值对raw：请求text、json、xml、html，比如如果请求json数据则使用此格式binary：content-type为application/octet-stream，可用于上传文件。 扩展PO：persistent object 持久对象 1 ．有时也被称为Data对象，对应数据库中的entity，可以简单认为一个PO对应数据库中的一条记录。 2 ．在hibernate持久化框架中与insert/delet操作密切相关。 3 ．PO中不应该包含任何对数据库的操作。 POJO ：plain ordinary java object 无规则简单java对象 一个中间对象，可以转化为PO、DTO、VO。 1 ．POJO持久化之后==〉PO （在运行期，由Hibernate中的cglib动态把POJO转换为PO，PO相对于POJO会增加一些用来管理数据库entity状态的属性和方法。PO对于programmer来说完全透明，由于是运行期生成PO，所以可以支持增量编译，增量调试。） 2 ．POJO传输过程中==〉DTO 3 ．POJO用作表示层==〉VO PO 和VO都应该属于它。 BO：business object 业务对象 业务对象主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。 比如一个简历，有教育经历、工作经历、社会关系等等。我们可以把教育经历对应一个PO，工作经历对应一个PO，社会关系对应一个PO。 建立一个对应简历的BO对象处理简历，每个BO包含这些PO。 这样处理业务逻辑时，我们就可以针对BO去处理。 封装业务逻辑为一个对象（可以包括多个PO，通常需要将BO转化成PO，才能进行数据的持久化，反之，从DB中得到的PO，需要转化成BO才能在业务层使用）。 关于BO主要有三种概念 1 、只包含业务对象的属性； 2 、只包含业务方法； 3 、两者都包含。 在实际使用中，认为哪一种概念正确并不重要，关键是实际应用中适合自己项目的需要。 VO：value object 值对象 / view object 表现层对象 1 ．主要对应页面显示（web页面/swt、swing界面）的数据对象。 2 ．可以和表对应，也可以不，这根据业务的需要。 DTO（TO）：Data Transfer Object 数据传输对象 1 ．用在需要跨进程或远程传输时，它不应该包含业务逻辑。 2 ．比如一张表有100个字段，那么对应的PO就有100个属性（大多数情况下，DTO内的数据来自多个表）。但view层只需显示10个字段，没有必要把整个PO对象传递到client，这时我们就可以用只有这10个属性的DTO来传输数据到client，这样也不会暴露server端表结构。到达客户端以后，如果用这个对象来对应界面显示，那此时它的身份就转为VO。 DAO：data access object数据访问对象 1 ．主要用来封装对DB的访问（CRUD操作）。 2 ．通过接收Business层的数据，把POJO持久化为PO。]]></content>
      <categories>
        <category>接口</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB]]></title>
    <url>%2F2019%2F04%2F11%2FMongoDB%2F</url>
    <content type="text"><![CDATA[NoSQL 简介NoSQL(NoSQL = Not Only SQL )，意即”不仅仅是SQL”。 在现代的计算系统上每天网络上都会产生庞大的数据量。 这些数据有很大一部分是由关系数据库管理系统（RDBMS）来处理。 1970年 E.F.Codd’s提出的关系模型的论文 “A relational model of data for large shared data banks”，这使得数据建模和应用程序编程更加简单。 通过应用实践证明，关系模型是非常适合于客户服务器编程，远远超出预期的利益，今天它是结构化数据存储在网络和商务应用的主导技术。 NoSQL 是一项全新的数据库革命性运动，早期就有人提出，发展至2009年趋势越发高涨。NoSQL的拥护者们提倡运用非关系型的数据存储，相对于铺天盖地的关系型数据库运用，这一概念无疑是一种全新的思维的注入 mongodb入门基础概念在mongodb中是通过数据库、集合、文档的方式来管理数据，下边是mongodb与关系数据库的一些概念对比： 1、一个mongodb实例可以创建多个数据库2、一个数据库可以创建多个集合3、一个集合可以包括多个文档。· 数据库1、查询数据库show dbs 查询全部数据库db 显示当前数据库2、创建数据库命令格式： use DATABASE_NAME 例子：use test02有test02数据库则切换到此数据库，没有则创建。注意：新创建的数据库不显示，需要至少包括一个集合。3、删除数据库（慎用！！！）命令格式： db.dropDatabase() 例子：删除test02数据库先切换数据库：use test02再执行删除：db.dropDatabase() 集合集合相当于关系数据库中的表，一个数据库可以创建多个集合，一个集合是将相同类型的文档管理起来。 创建集合123db.createCollection(name, options)name: 新创建的集合名称options: 创建参数 删除集合123db.collection.drop()例子：db.student.drop() 删除student集合 文档插入文档 mongodb中文档的格式是json格式，下边就是一个文档，包括两个key：_id主键和name1234&#123;&quot;_id&quot; : ObjectId(&quot;5b2cc4bfa6a44812707739b5&quot;),&quot;name&quot; : &quot;程序员&quot;&#125; 插入命令： db.COLLECTION_NAME.insert(document 每个文档默认以_id作为主键，主键默认类型为ObjectId（对象类型），mongodb会自动生成主键值。例子： db.student.insert({“name”:”程序员”,”age”:10}) 注意：同一个集合中的文档的key可以不相同！但是建议设置为相同的。 更新文档 命令格式：12345678db.collection.update(&lt;query&gt;,&lt;update&gt;,&lt;options&gt;)query:查询条件，相当于sql语句的whereupdate：更新文档内容options：选项 替换文档将符合条件 “name”:”北京黑马程序”的第一个文档替换为{“name”:”北京黑马程序员”,”age”:10}。 db.student.update({“name”:”程序员”},{“name”:”北京程序员”,”age”:10}) $set修改器使用$set修改器指定要更新的key，key不存在则创建，存在则更新。将符合条件 “name”:”北京黑马程序”的所有文档更新name和age的值。 db.student.update({“name”:”黑马程序员”},{$set:{“name”:”北京黑马程序员”,”age”:10}},{multi:true}) multi：false表示更新第一个匹配的文档，true表示更新所有匹配的文档。 删除文档命令格式：12db.student.remove(&lt;query&gt;)query：删除条件，相当于sql语句中的where 删除所有文档 db.student.remove({})删除符合条件的文档db.student.remove({“name”:”黑马程序员”}) 查询文档命令格式：123db.collection.find(query, projection)query：查询条件，可不填projection：投影查询key，可不填 查询全部 db.student.find() 查询符合条件的记录查询name等为”黑马程序员”的文档 db.student.find({“name”:”黑马程序员”}) 投影查询只显示name和age两个key，_id主键不显示。 db.student.find({“name”:”黑马程序员”},{name:1,age:1,_id:0}) 用户创建用户 语法格式：123456789mongo&gt;db.createUser(&#123; user: &quot;&lt;name&gt;&quot;,pwd: &quot;&lt;cleartext password&gt;&quot;,customData: &#123; &lt;any information&gt; &#125;,roles: [&#123; role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; &#125; | &quot;&lt;role&gt;&quot;,...]&#125;) 创建root用户，角色为root12345678use admindb.createUser(&#123;user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[&#123;role:&quot;root&quot;,db:&quot;admin&quot;&#125;]&#125;) 内置角色如下： 数据库用户角色：read、readWrite; 数据库管理角色：dbAdmin、dbOwner、userAdmin； 集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager； 备份恢复角色：backup、restore； 所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase 超级用户角色：root 查询用户查询当前库下的所有用户：show users 删除用户语法格式：db.dropUser(“用户名”)例子：删除root1用户db.dropUser(“root1”) 修改用户语法格式：1234567891011db.updateUser(&quot;&lt;username&gt;&quot;,&#123;customData : &#123; &lt;any information&gt; &#125;,roles : [&#123; role: &quot;&lt;role&gt;&quot;, db: &quot;&lt;database&gt;&quot; &#125; | &quot;&lt;role&gt;&quot;,...],pwd: &quot;&lt;cleartext password&gt;&quot;&#125;,writeConcern: &#123; &lt;write concern&gt; &#125;) 修改root用户的角色为readWriteAnyDatabase12use admindb.updateUser(&quot;root&quot;,&#123;roles:[&#123;role:&quot;readWriteAnyDatabase&quot;,db:&quot;admin&quot;&#125;]&#125;) 修改密码语法格式： db.changeUserPassword(“username”,”newPasswd”) 修改root用户的密码为123 use admindb.changeUserPassword(“root”,”123”) 启用 auth注意：如果要启用认证权限 一定要启动auth db.auth(‘admin’, ‘admin123’) 返回1表示成功]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringDataMongodb]]></title>
    <url>%2F2019%2F04%2F11%2FSpringDataMongodb%2F</url>
    <content type="text"><![CDATA[Spring Data MongoDB 项目提供与MongoDB文档数据库的集成。Spring Data MongoDB POJO的关键功能区域为中心的模型与MongoDB的DBCollection轻松地编写一个存储库交互数据访问 这里是用SpringBoot实现的 导入jar包12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 实现一个实体类12345678910111213141516171819202122232425262728293031323334353637383940414243@Data@ToString@Document(collection = &quot;cms_page&quot;)public class CmsPage &#123;/*** 页面名称、别名、访问地址、类型（静态/动态）、页面模版、状态*///站点IDprivate String siteId;//页面ID@Idprivate String pageId;//页面名称private String pageName;//别名private String pageAliase;//访问地址private String pageWebPath;//参数private String pageParameter;//物理路径private String pagePhysicalPath;//类型（静态/动态）private String pageType;//页面模版private String pageTemplate;//页面静态化内容private String pageHtml;//状态private String pageStatus;//创建时间private Date pageCreateTime;//模版idprivate String templateId;//参数列表，暂不用private List&lt;CmsPageParam&gt; pageParams;//模版文件Id// private String templateFileId;//静态文件Idprivate String htmlFileId;//数据Urlprivate String dataUrl;&#125; 属性说明：1、定义一个页面需要指定页面所属站点一个站点包括多个页面，比如：学成在线的门户站点（网站）包括了多个页面。2、定义一个页面需要指定页面使用的模板多个页面可以使用相同的模板，比如：商品信息模板，每个商品就是一个页面，所有商品使用同一个商品信息模板注解说明：@Data、@ToString、@Document注解表示什么意思？@Data、@ToString：是Lombok提供的注解，下边会介绍。@Document：是Spring Data mongodb提供的注解，最终CMS的开发会使用Mongodb数据库。 配置文件在classpath下配置application.yml 123456789server: port: 31001spring: application: name: xc‐service‐manage‐cms data: mongodb: uri: mongodb://root:123@localhost:27017 database: xc_cms Dao测试分页查询测试定义Dao接口 使用Spring Data Mongodb完成Mongodb数据库的查询，Spring Data Mongodb提供一套快捷操作mongodb的方法。创建Dao，继承MongoRepository，并指定实体类型和主键类型。 public interface CmsPageRepository extends MongoRepository&lt;CmsPage,String&gt; {} 编写测试类 123456789101112131415package com.xuecheng.manage_cms;import com.xuecheng.framework.domain.cms.CmsPage;import com.xuecheng.manage_cms.dao.CmsPageRepository;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.domain.*;import org.springframework.test.context.junit4.SpringRunner;@SpringBootTest@RunWith(SpringRunner.class)public class CmsPageRepositoryTest &#123; @Autowired CmsPageRepository cmsPageRepository;&#125; 分页查询测试 123456789//分页测试@Testpublic void testFindPage() &#123;int page = 0;//从0开始int size = 10;//每页记录数Pageable pageable = PageRequest.of(page,size);Page&lt;CmsPage&gt; all = cmsPageRepository.findAll(pageable);System.out.println(all);&#125; 基础方法测试 这里Dao接口继承了MongoRepository，在MongoRepository中定义了很多现成的方法，如save、delete等，通过下边的代码来测试这里父类方法。 添加 123456789101112131415161718//添加@Testpublic void testInsert()&#123;//定义实体类CmsPage cmsPage = new CmsPage();cmsPage.setSiteId(&quot;s01&quot;);cmsPage.setTemplateId(&quot;t01&quot;);cmsPage.setPageName(&quot;测试页面&quot;);cmsPage.setPageCreateTime(new Date());List&lt;CmsPageParam&gt; cmsPageParams = new ArrayList&lt;&gt;();CmsPageParam cmsPageParam = new CmsPageParam();cmsPageParam.setPageParamName(&quot;param1&quot;);cmsPageParam.setPageParamValue(&quot;value1&quot;);cmsPageParams.add(cmsPageParam);cmsPage.setPageParams(cmsPageParams);cmsPageRepository.save(cmsPage);System.out.println(cmsPage);&#125; 删除 12345//删除@Testpublic void testDelete() &#123;cmsPageRepository.deleteById(&quot;5b17a2c511fe5e0c409e5eb3&quot;);&#125; 修改 12345678910//修改@Testpublic void testUpdate() &#123;Optional&lt;CmsPage&gt; optional = cmsPageRepository.findOne(&quot;5b17a34211fe5e2ee8c116c9&quot;);if(optional.isPresent())&#123;CmsPage cmsPage = optional.get();cmsPage.setPageName(&quot;测试页面01&quot;);cmsPageRepository.save(cmsPage);&#125;&#125; 关于Optional：Optional是jdk1.8引入的类型，Optional是一个容器对象，它包括了我们需要的对象，使用isPresent方法判断所包含对象是否为空，isPresent方法返回false则表示Optional包含对象为空，否则可以使用get()取出对象进行操作。Optional的优点是：1、提醒你非空判断。2、将对象非空检测标准化。 自定义Dao方法 同Spring Data JPA一样Spring Data mongodb也提供自定义方法的规则，如下：按照findByXXX，findByXXXAndYYY、countByXXXAndYYY等规则定义方法，实现查询操作。 12345678910public interface CmsPageRepository extends MongoRepository&lt;CmsPage,String&gt; &#123;//根据页面名称查询CmsPage findByPageName(String pageName);//根据页面名称和类型查询CmsPage findByPageNameAndPageType(String pageName,String pageType);//根据站点和页面类型查询记录数int countBySiteIdAndPageType(String siteId,String pageType);//根据站点和页面类型分页查询Page&lt;CmsPage&gt; findBySiteIdAndPageType(String siteId,String pageType, Pageable pageable);&#125;]]></content>
      <categories>
        <category>SpringData</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebMagic]]></title>
    <url>%2F2019%2F04%2F08%2FWebMagic%2F</url>
    <content type="text"><![CDATA[爬虫分类: 通用网络爬虫:互联网上抓取所有数据 聚焦网络爬虫:互联网上只抓取某一种数据 增量式网络爬虫:互联网上只抓取刚刚更新的数据 Deep Web 爬虫:Deep Web 是那些大部分内容不能通过静态链接获取的、隐藏在搜索表单后的，只有用户提交一些关键词才能获得的 Web 页面。 WebMagic的结构分为Downloader、PageProcessor、Scheduler、Pipeline四大组件，并由Spider将它们彼此组织起来。这四大组件对应爬虫生命周期中的下载、处理、管理和持久化等功能。WebMagic的设计参考了Scapy，但是实现方式更Java化一些。 而Spider则将这几个组件组织起来，让它们可以互相交互，流程化的执行，可以认为Spider是一个大的容器，它也是WebMagic逻辑的核心。 WebMagic的四个组件DownloaderDownloader负责从互联网上下载页面，以便后续处理。WebMagic默认使用了Apache HttpClient作为下载工具。 PageProcessorPageProcessor负责解析页面，抽取有用信息，以及发现新的链接。WebMagic使用Jsoup作为HTML解析工具，并基于其开发了解析XPath的工具Xsoup。 在这四个组件中，PageProcessor对于每个站点每个页面都不一样，是需要使用者定制的部分。 SchedulerScheduler负责管理待抓取的URL，以及一些去重的工作。WebMagic默认提供了JDK的内存队列来管理URL，并用集合来进行去重。也支持使用Redis进行分布式管理。 PipelinePipeline负责抽取结果的处理，包括计算、持久化到文件、数据库等。WebMagic默认提供了“输出到控制台”和“保存到文件”两种结果处理方案。 Pipeline定义了结果保存的方式，如果你要保存到指定数据库，则需要编写对应的Pipeline。对于一类需求一般只需编写一个Pipeline。 用于数据流转的对象RequestRequest是对URL地址的一层封装，一个Request对应一个URL地址。 它是PageProcessor与Downloader交互的载体，也是PageProcessor控制Downloader唯一方式。 除了URL本身外，它还包含一个Key-Value结构的字段extra。你可以在extra中保存一些特殊的属性，然后在其他地方读取，以完成不同的功能。例如附加上一个页面的一些信息等。 PagePage代表了从Downloader下载到的一个页面——可能是HTML，也可能是JSON或者其他文本格式的内容。 Page是WebMagic抽取过程的核心对象，它提供一些方法可供抽取、结果保存等。 ResultItemsResultItems相当于一个Map，它保存PageProcessor处理的结果，供Pipeline使用。它的API与Map很类似，值得注意的是它有一个字段skip，若设置为true，则不应被Pipeline处理。 入门案例创建Maven工程，并加入以下依赖12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.itcast.crawler&lt;/groupId&gt; &lt;artifactId&gt;itcast-crawler-webmagic&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!--WebMagic--&gt; &lt;dependency&gt; &lt;groupId&gt;us.codecraft&lt;/groupId&gt; &lt;artifactId&gt;webmagic-core&lt;/artifactId&gt; &lt;version&gt;0.7.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;us.codecraft&lt;/groupId&gt; &lt;artifactId&gt;webmagic-extension&lt;/artifactId&gt; &lt;version&gt;0.7.3&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 注意：0.7.3版本对SSL的并不完全，如果是直接从Maven中央仓库下载依赖，在爬取只支持SSL v1.2的网站会有SSL的异常抛出。解决方案：1.等作者的0.7.4的版本发布2.直接从github上下载最新的代码，安装到本地仓库 也可以参考以下资料自己修复https://github.com/code4craft/webmagic/issues/701 加入配置文件WebMagic使用slf4j-log4j12作为slf4j的实现。添加log4j.properties配置文件12345log4j.rootLogger=INFO,A1 log4j.appender.A1=org.apache.log4j.ConsoleAppenderlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%t] [%c]-[%p] %m%n 案例实现123456789101112131415161718public class JobProcessor implements PageProcessor &#123; public void process(Page page) &#123; page.putField(&quot;author&quot;, page.getHtml().css(&quot;div.mt&gt;h1&quot;).all()); &#125; private Site site = Site.me(); public Site getSite() &#123; return site; &#125; public static void main(String[] args) &#123; Spider.create(new JobProcessor()) //初始访问url地址 .addUrl(&quot;https://www.jd.com/moreSubject.aspx&quot;) .run(); &#125;&#125; 实现PageProcessor抽取元素SelectableWebMagic里主要使用了三种抽取技术：XPath、正则表达式和CSS选择器。另外，对于JSON格式的内容，可使用JsonPath进行解析。 XPath以上是获取属性class=mt的div标签，里面的h1标签的内容page.getHtml().xpath(“//div[@class=mt]/h1/text()”)也可以参考课堂资料的W3School离线手册(2017.03.11版).chm CSS选择器CSS选择器是与XPath类似的语言。在上一次的课程中，我们已经学习过了Jsoup的选择器，它比XPath写起来要简单一些，但是如果写复杂一点的抽取规则，就相对要麻烦一点。div.mt&gt;h1表示class为mt的div标签下的直接子元素h1标签page.getHtml().css(“div.mt&gt;h1”).toString() 可是使用:nth-child(n)选择第几个元素，如下选择第一个元素page.getHtml().css(“div#news_div &gt; ul &gt; li:nth-child(1) a”).toString()注意：需要使用&gt;，就是直接子元素才可以选择第几个元素 正则表达式正则表达式则是一种通用的文本抽取语言。在这里一般用于获取url地址。 抽取元素APISelectable相关的抽取元素链式API是WebMagic的一个核心功能。使用Selectable接口，可以直接完成页面元素的链式抽取，也无需去关心抽取的细节。 在刚才的例子中可以看到，page.getHtml()返回的是一个Html对象，它实现了Selectable接口。这个接口包含的方法分为两类：抽取部分和获取结果部分 获取结果API当链式调用结束时，我们一般都想要拿到一个字符串类型的结果。这时候就需要用到获取结果的API了。 我们知道，一条抽取规则，无论是XPath、CSS选择器或者正则表达式，总有可能抽取到多条元素。WebMagic对这些进行了统一，可以通过不同的API获取到一个或者多个元素 当有多条数据的时候，使用get()和toString()都是获取第一个url地址1234567String str = page.getHtml() .css(&quot;div#news_div&quot;) .links().regex(&quot;.*[0-3]$&quot;).toString();String get = page.getHtml() .css(&quot;div#news_div&quot;) .links().regex(&quot;.*[0-3]$&quot;).get(); 这里selectable.toString()采用了toString()这个接口，是为了在输出以及和一些框架结合的时候，更加方便。因为一般情况下，我们都只需要选择一个元素！selectable.all()则会获取到所有元素。 获取链接有了处理页面的逻辑，我们的爬虫就接近完工了，但是现在还有一个问题：一个站点的页面是很多的，一开始我们不可能全部列举出来，于是如何发现后续的链接，是一个爬虫不可缺少的一部分。 下面的例子就是获取https://www.jd.com/moreSubject.aspx这个页面中所有符合https://www.jd.com/news.\\w+?.*正则表达式的url地址并将这些链接加入到待抓取的队列中去。1234567891011public void process(Page page) &#123; page.addTargetRequests(page.getHtml().links() .regex(&quot;(https://www.jd.com/news.\\w+?.*)&quot;).all()); System.out.println(page.getHtml().css(&quot;div.mt&gt;h1&quot;).all());&#125;public static void main(String[] args) &#123; Spider.create(new JobProcessor()) .addUrl(&quot;https://www.jd.com/moreSubject.aspx&quot;) .run();&#125; 使用Pipeline保存结果WebMagic用于保存结果的组件叫做Pipeline。我们现在通过“控制台输出结果”这件事也是通过一个内置的Pipeline完成的，它叫做ConsolePipeline。那么，我现在想要把结果用保存到文件中，怎么做呢？只将Pipeline的实现换成”FilePipeline”就可以了。 已有的PipelineWebMagic中就已经提供了控制台输出、保存到文件、保存为JSON格式的文件几种通用的Pipeline。 自定义Pipeline 123456789101112131415161718@Componentpublic class SpringDataPipeline implements Pipeline &#123; @Autowired private JobInfoService jobInfoService; @Override public void process(ResultItems resultItems, Task task) &#123; //获取需要保存到MySQL的数据 JobInfo jobInfo = resultItems.get(&quot;jobInfo&quot;); //判断获取到的数据不为空 if(jobInfo!=null) &#123; //如果有值则进行保存 this.jobInfoService.save(jobInfo); &#125; &#125;&#125; 在Processor中修改process()启动的逻辑，添加代码 123456789101112@Autowiredprivate SpringDataPipeline springDataPipeline;public void process() &#123; Spider.create(new JobProcessor()) .addUrl(url) .addPipeline(this.springDataPipeline) .setScheduler(new QueueScheduler() .setDuplicateRemover(new BloomFilterDuplicateRemover(10000000))) .thread(5) .run();&#125; 爬虫的配置、启动和终止Spider是爬虫启动的入口。在启动爬虫之前，我们需要使用一个PageProcessor创建一个Spider对象，然后使用run()进行启动。 同时Spider的其他组件（Downloader、Scheduler、Pipeline）都可以通过set方法来进行设置。 爬虫配置SiteSite.me()可以对爬虫进行一些配置配置，包括编码、抓取间隔、超时时间、重试次数等。在这里我们先简单设置一下：重试次数为3次，抓取间隔为一秒123456private Site site = Site.me() .setCharset(&quot;UTF-8&quot;)//编码 .setSleepTime(1)//抓取间隔时间 .setTimeOut(1000*10)//超时时间 .setRetrySleepTime(3000)//重试时间 .setRetryTimes(3);//重试次数 站点本身的一些配置信息，例如编码、HTTP头、超时时间、重试策略等、代理等，都可以通过设置Site对象来进行配置。 Scheduler组件Scheduler是WebMagic中进行URL管理的组件。一般来说，Scheduler包括两个作用： 对待抓取的URL队列进行管理。对已抓取的URL进行去重。WebMagic内置了几个常用的Scheduler。如果你只是在本地执行规模比较小的爬虫，那么基本无需定制Scheduler，但是了解一下已经提供的几个Scheduler还是有意义的。去重部分被单独抽象成了一个接口：DuplicateRemover，从而可以为同一个Scheduler选择不同的去重方式，以适应不同的需要，目前提供了两种去重方式。RedisScheduler是使用Redis的set进行去重，其他的Scheduler默认都使用HashSetDuplicateRemover来进行去重。如果要使用BloomFilter，必须要加入以下依赖：123456&lt;!--WebMagic对布隆过滤器的支持--&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;16.0&lt;/version&gt;&lt;/dependency&gt; 添加布隆过滤器 12345678910public static void main(String[] args) &#123; Spider.create(new JobProcessor()) //初始访问url地址 .addUrl(&quot;https://www.jd.com/moreSubject.aspx&quot;) .addPipeline(new FilePipeline(&quot;D:/webmagic/&quot;)) .setScheduler(new QueueScheduler() .setDuplicateRemover(new BloomFilterDuplicateRemover(10000000))) //参数设置需要对多少条数据去重 .thread(1)//设置线程数 .run();&#125;]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jsoup]]></title>
    <url>%2F2019%2F04%2F08%2FJsoup%2F</url>
    <content type="text"><![CDATA[我们抓取到页面之后，还需要对页面进行解析。可以使用字符串处理工具解析页面，也可以使用正则表达式，但是这些方法都会带来很大的开发成本，所以我们需要使用一款专门解析html页面的技术。 jsoup 是一款Java 的HTML解析器，可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力的API，可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。 jsoup的主要功能如下：1.从一个URL，文件或字符串中解析HTML；2.使用DOM或CSS选择器来查找、取出数据；可操作HTML元素、属性、文本 加入Jsoup依赖：1234567891011121314151617181920212223&lt;!--Jsoup--&gt;&lt;dependency&gt; &lt;groupId&gt;org.jsoup&lt;/groupId&gt; &lt;artifactId&gt;jsoup&lt;/artifactId&gt; &lt;version&gt;1.10.3&lt;/version&gt;&lt;/dependency&gt;&lt;!--测试--&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt;&lt;!--工具--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt; jsoup解析Jsoup可以直接输入url，它会发起请求并获取数据，封装为Document对象123456789@Testpublic void testJsoupUrl() throws Exception &#123; // 解析url地址 Document document = Jsoup.parse(new URL(&quot;http://www.itcast.cn/&quot;), 1000); //获取title的内容 Element title = document.getElementsByTag(&quot;title&quot;).first(); System.out.println(title.text());&#125; 虽然使用Jsoup可以替代HttpClient直接发起请求解析数据，但是往往不会这样用，因为实际的开发过程中，需要使用到多线程，连接池，代理等等方式，而jsoup对这些的支持并不是很好，所以我们一般把jsoup仅仅作为Html解析工具使用 解析字符串准备一个html文件1234567891011121314151617181920212223242526272829303132333435&lt;html&gt; &lt;head&gt; &lt;title&gt;传智播客官网-一样的教育,不一样的品质&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;city&quot;&gt; &lt;h3 id=&quot;city_bj&quot;&gt;北京中心&lt;/h3&gt; &lt;fb:img src=&quot;/2018czgw/images/slogan.jpg&quot; class=&quot;slogan&quot;/&gt; &lt;div class=&quot;city_in&quot;&gt; &lt;div class=&quot;city_con&quot; style=&quot;display: none;&quot;&gt; &lt;ul&gt; &lt;li id=&quot;test&quot; class=&quot;class_a class_b&quot;&gt; &lt;a href=&quot;http://www.itcast.cn&quot; target=&quot;_blank&quot;&gt; &lt;span class=&quot;s_name&quot;&gt;北京&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;http://sh.itcast.cn&quot; target=&quot;_blank&quot;&gt; &lt;span class=&quot;s_name&quot;&gt;上海&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;http://gz.itcast.cn&quot; target=&quot;_blank&quot;&gt; &lt;span abc=&quot;123&quot; class=&quot;s_name&quot;&gt;广州&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;ul&gt; &lt;li&gt;天津&lt;/li&gt; &lt;/ul&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; Jsoup可以直接输入字符串，并封装为Document对象12345678910111213@Testpublic void testJsoupString() throws Exception &#123; //读取文件获取 String html = FileUtils.readFileToString(new File(&quot;D:\\jsoup.html&quot;), &quot;UTF-8&quot;); // 解析字符串 Document document = Jsoup.parse(html); //获取title的内容 Element title = document.getElementsByTag(&quot;title&quot;).first(); System.out.println(title.text());&#125; 解析文件123456789@Testpublic void testJsoupHtml() throws Exception &#123; // 解析文件 Document document = Jsoup.parse(new File(&quot;D:\\jsoup.html&quot;),&quot;UTF-8&quot;); //获取title的内容 Element title = document.getElementsByTag(&quot;title&quot;).first(); System.out.println(title.text());&#125; 使用dom方式遍历文档根据id查询元素getElementById Element element = document.getElementById(“city_bj”); 根据标签获取元素getElementsByTag element = document.getElementsByTag(“title”).first(); 根据class获取元素getElementsByClass element = document.getElementsByClass(“s_name”).last(); 根据属性获取元素getElementsByAttribute element = document.getElementsByAttribute(“abc”).first();element = document.getElementsByAttributeValue(“class”, “city_con”).first(); 获取元素 Element element = document.getElementById(“test”); 从元素中获取id String str = element.id(); 从元素中获取className str = element.className(); 从元素中获取属性的值attr str = element.attr(“id”); 从元素中获取所有属性attributes str = element.attributes().toString(); 从元素中获取文本内容text str = element.text(); 使用选择器语法查找元素jsoup elements对象支持类似于CSS (或jquery)的选择器语法，来实现非常强大和灵活的查找功能。这个select 方法在Document, Element,或Elements对象中都可以使用。且是上下文相关的，因此可实现指定元素的过滤，或者链式选择访问。Select方法将返回一个Elements集合，并提供一组方法来抽取和处理结果。 Selector选择器概述 tagname: 通过标签查找元素，比如：span #id: 通过ID查找元素，比如：# city_bj.class: 通过class名称查找元素，比如：.class_aattribute: 利用属性查找元素，比如：abc: 利用属性值来查找元素，比如：[class=s_name] tagname: 通过标签查找元素，比如：span Elements span = document.select(“span”);for (Element element : span) {System.out.println(element.text());} #id: 通过ID查找元素，比如：#city_bjj String str = document.select(“#city_bj”).text(); class: 通过class名称查找元素，比如：.class_a str = document.select(“.class_a”).text(); str = document.select(“[abc]”).text(); str = document.select(“[class=s_name]”).text(); Selector选择器组合使用el#id: 元素+ID，比如： h3#city_bjel.class: 元素+class，比如： li.class_ael[attr]: 元素+属性名，比如： span[abc]任意组合: 比如：span[abc].s_nameancestor child: 查找某个元素下子元素，比如：.city_con li 查找”city_con”下的所有liparent &gt; child: 查找某个父元素下的直接子元素，比如：.city_con &gt; ul &gt; li 查找city_con第一级（直接子元素）的ul，再找所有ul下的第一级liparent &gt; *: 查找某个父元素下所有直接子元素 el#id: 元素+ID，比如： h3#city_bj String str = document.select(“h3#city_bj”).text(); el.class: 元素+class，比如： li.class_a str = document.select(“li.class_a”).text(); el[attr]: 元素+属性名，比如： span[abc] str = document.select(“span[abc]”).text(); 任意组合，比如：span[abc].s_name str = document.select(“span[abc].s_name”).text(); ancestor child: 查找某个元素下子元素，比如：.city_con li 查找”city_con”下的所有li str = document.select(“.city_con li”).text(); parent &gt; child: 查找某个父元素下的直接子元素，比如：.city_con &gt; ul &gt; li 查找city_con第一级（直接子元素）的ul，再找所有ul下的第一级li str = document.select(“.city_con &gt; ul &gt; li”).text(); parent &gt; 查找某个父元素下所有直接子元素.city_con &gt; str = document.select(“.city_con &gt; *”).text();]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebCrawler]]></title>
    <url>%2F2019%2F04%2F08%2FWebCrawler%2F</url>
    <content type="text"><![CDATA[网络爬虫网络爬虫（Web crawler），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本在大数据时代，信息的采集是一项重要的工作，而互联网中的数据是海量的，如果单纯靠人力进行信息采集，不仅低效繁琐，搜集的成本也会提高。如何自动高效地获取互联网中我们感兴趣的信息并为我们所用是一个重要的问题，而爬虫技术就是为了解决这些问题而生的。 网络爬虫（Web crawler）也叫做网络机器人，可以代替人们自动地在互联网中进行数据信息的采集与整理。它是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本，可以自动采集所有其能够访问到的页面内容，以获取相关数据。 从功能上来讲，爬虫一般分为数据采集，处理，储存三个部分。爬虫从一个或若干初始网页的URL开始，获得初始网页上的URL，在抓取网页的过程中，不断从当前页面上抽取新的URL放入队列,直到满足系统的一定停止条件 爬虫入门程序环境准备1234567891011121314151617//创建Maven工程crawler-first并给pom.xml加入依赖&lt;dependencies&gt; &lt;!-- HttpClient --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 加入log4j.properties 123456log4j.rootLogger=DEBUG,A1log4j.logger.cn.itcast = DEBUGlog4j.appender.A1=org.apache.log4j.ConsoleAppenderlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%t] [%c]-[%p] %m%n 编写最简单的爬虫，抓取百度首页：http://www.baidu.com/ 使用的是Get请求方式 与 Post请求 类似 12345678910111213141516171819202122232425262728293031public static void main(String[] args) throws IOException &#123; //创建HttpClient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建HttpGet请求 HttpGet httpGet = new HttpGet(&quot;http://www.baidu.com/&quot;); CloseableHttpResponse response = null; try &#123; //使用HttpClient发起请求 response = httpClient.execute(httpGet); //判断响应状态码是否为200 if (response.getStatusLine().getStatusCode() == 200) &#123; //如果为200表示请求成功，获取返回数据 String content = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); //打印数据 System.out.println(content); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; //释放连接 if (response == null) &#123; try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; httpClient.close(); &#125; &#125;&#125; 接下来呢 是带参数的Get和Post请求get请求： 是创建URIBuilder 来设置参数1234567891011121314151617181920212223242526272829public static void main(String[] args) throws URISyntaxException &#123; //创建HttpClient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //http://yun.itheima.com/course?keys=Java //创建URIBuilder URIBuilder uriBuilder = new URIBuilder(&quot;http://yun.itheima.com/course&quot;); //设置参数 uriBuilder.setParameter(&quot;keys&quot;,&quot;java&quot;); //创建HttpGet对象 设置url地址 HttpGet httpGet = new HttpGet(uriBuilder.build()); //使用 HttpClient发起请求 获取响应 CloseableHttpResponse response = null; try &#123; response = httpClient.execute(httpGet); //解析响应 String content = EntityUtils.toString(response.getEntity(), &quot;utf8&quot;); System.out.println(content.length()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try&#123; response.close(); httpClient.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125; post请求： 声明List集合的方式 来封装表单中的参数 创建表单中的Entity对象 设置表单的Entity对象到Post请求中12345678910111213141516171819202122232425262728293031323334public static void main(String[] args) throws Exception &#123; //创建HttpClient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建HttpGet对象 设置访问url地址 http://yun.itheima.com/course?keys=Java HttpPost httpPost = new HttpPost(&quot;http://yun.itheima.com/course&quot;); //声明List集合 封装表单中的参数 List&lt;NameValuePair&gt; params = new ArrayList&lt;NameValuePair&gt;(); params.add(new BasicNameValuePair(&quot;keys&quot;,&quot;Java&quot;)); //创建表单中的Entity对象 UrlEncodedFormEntity(封装好的数据，编码) UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(params, &quot;utf8&quot;); //设置表单的Entity对象到Post请求中 httpPost.setEntity(formEntity); //使用HttpClient发起请求 获取response CloseableHttpResponse response =null; try &#123; response = httpClient.execute(httpPost); //解析响应 if(response.getStatusLine().getStatusCode() == 200)&#123; String content = EntityUtils.toString(response.getEntity(), &quot;utf8&quot;); System.out.println(content.length()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; response.close(); httpClient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; HttpClient连接池如果每次请求都要创建HttpClient，会有频繁创建和销毁的问题，可以使用连接池来解决这个问题。12345678910111213141516171819202122232425262728293031323334353637public static void main(String[] args) &#123; //创建连接处管理器 PoolingHttpClientConnectionManager em = new PoolingHttpClientConnectionManager(); //设置连接数 em.setMaxTotal(100); //设置每个主机最大连接数 em.setDefaultMaxPerRoute(10); //使用连接池管理器发起请求 doGet(em); doGet(em); &#125; private static void doGet(PoolingHttpClientConnectionManager em) &#123; //不是每次创建新的HttpClient 而是从连接池中获取HttpClient对象 CloseableHttpClient httpClient = HttpClients.custom().setConnectionManager(em).build(); HttpGet httpGet = new HttpGet(&quot;http://www.itcast.cn&quot;); CloseableHttpResponse response =null; try &#123; response = httpClient.execute(httpGet); if(response.getStatusLine().getStatusCode() == 200) &#123; String entity = EntityUtils.toString(response.getEntity(), &quot;utf8&quot;); System.out.println(entity.length()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if (response != null)&#123; try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 请求参数注意：这个请求参数不是地址栏上的参数 是给请求方式的设置由于Get和Post请求方式设置相同这里就拿Get请求来举例1234567891011//创建HttpGet请求 HttpGet httpGet = new HttpGet(&quot;http://www.itcast.cn/&quot;); //设置请求参数 RequestConfig requestConfig = RequestConfig.custom() .setConnectTimeout(1000)//设置创建连接的最长时间 .setConnectionRequestTimeout(500)//设置获取连接的最长时间 .setSocketTimeout(10 * 1000)//设置数据传输的最长时间 .build(); httpGet.setConfig(requestConfig);]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringDataJPA2]]></title>
    <url>%2F2019%2F04%2F04%2FSpringDataJPA2%2F</url>
    <content type="text"><![CDATA[JpaSpecificationExecutor 方法列表 T findOne(Specification spec); //查询单个对象List findAll(Specification spec); //查询列表//查询全部，分页//pageable：分页参数//返回值：分页pageBean（page：是springdatajpa提供的）Page findAll(Specification spec, Pageable pageable);//查询列表//Sort：排序参数List findAll(Specification spec, Sort sort);long count(Specification spec);//统计查询Specification ：查询条件 自定义我们自己的Specification实现类实现 root：查询的根对象（查询的任何属性都可以从根对象中获取）CriteriaQuery：顶层查询对象，自定义查询方式（了解：一般不用）CriteriaBuilder：查询的构造器，封装了很多的查询条件Predicate toPredicate(Root root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb); //封装查询条件 12345678910方法对应关系方法名称 Sql对应关系equle filed = valuegt（greaterThan ） filed &gt; valuelt（lessThan ） filed &lt; valuege（greaterThanOrEqualTo ） filed &gt;= valuele（ lessThanOrEqualTo） filed &lt;= valuenotEqule filed != valuelike filed like valuenotLike filed not like value 测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121@Autowired private CustomerDao customerDao; /** * 查询单个对象 */ @Test public void testSpec()&#123; //匿名内部类 /** * 自定义查询条件 * 实现Specification接口 （提供泛型 查询对象的类型） * 实现toPredicate方法（构造查询条件） * 需要借助方法参数中的两个参数（ * root: 获取需要查询的对象属性 * CriteriaBuilber:构造查询条件 内部封装了很多查询条件（模糊匹配，精准匹配 * ） * * 案例：根据客户名称查询 查询客户名为小胖的客户 * 构成查询条件 * 查询方式 * cd对象 * 比较的属性名称 * root对象 */ Specification&lt;Customer&gt; spec = new Specification&lt;Customer&gt;() &#123; public Predicate toPredicate(Root&lt;Customer&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) &#123;// 获取比较的属性 Path&lt;Object&gt; custName = root.get(&quot;custName&quot;); Predicate predicate = cb.equal(custName, &quot;小胖&quot;);//进行精准匹配 （比较的属性 ，比较的名称） return predicate; &#125; &#125;; Customer customer = customerDao.findOne(spec); System.out.println(customer); &#125; /** * 多条件查询 * 根据客户名和客户所属行业查询 */ @Test public void testSpec1()&#123; /** * root :获取属性 * 客户名 * 所属行业 * cb:构造查询 * 构造客户名的精准匹配查询 * 构造所属行业的精准匹配查询 * 将以上两个查询联合起来查询 */ Specification&lt;Customer&gt; spec =new Specification&lt;Customer&gt;() &#123; public Predicate toPredicate(Root&lt;Customer&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) &#123; Path&lt;Object&gt; custName = root.get(&quot;custName&quot;); Path&lt;Object&gt; custIndustry = root.get(&quot;custIndustry&quot;); /** * 构造查询 */// 构造客户名的精准匹配查询 Predicate p1 = cb.equal(custName, &quot;小胖&quot;);// 构造所属行业的精准匹配查询 Predicate p2 = cb.equal(custIndustry, &quot;IT&quot;);// 将以上两个查询联合起来查询 Predicate and = cb.and(p1, p2); return and; &#125; &#125;; Customer customer = customerDao.findOne(spec); System.out.println(customer); &#125; /** * 完成根据客户名称的模糊匹配 返回客户列表 * * gt ,lt ,ge ,le ,like 得到path对象 根据path指定比较的参数类型，再去进行比较 * 指定参数类型：path.as(类型的字节码对象) * */ @Test public void testSpec2()&#123; Specification&lt;Customer&gt; spec = new Specification&lt;Customer&gt;() &#123; public Predicate toPredicate(Root&lt;Customer&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) &#123; //构建查询条件 Path&lt;Object&gt; custName = root.get(&quot;custName&quot;); //查询方式 cb.like(custName.as(String.class),&quot;小胖&quot;); return null; &#125; &#125;; /*List&lt;Customer&gt; all = customerDao.findAll(spec); System.out.println(all);*/ //创建排序对象 //创建排序对象需要调用构造方法实例化对象 //第一个参数 ：排序的顺序（正序，倒序） //倒序Sort.Direction.DESC //正序Sort.Direction.ASC Sort sort = new Sort(Sort.Direction.DESC); customerDao.findAll(spec,sort); &#125; /** * 分页查询 */ @Test public void testSpec4()&#123; Pageable page = new PageRequest(0,2); Page&lt;Customer&gt; customerPage = customerDao.findAll(null, page); System.out.println(customerPage.getTotalPages()); //得到总页数 System.out.println(customerPage.getContent()); //得到数据集合 System.out.println(customerPage.getTotalElements()); //得到总条数 &#125; 多表之间的关系和操作多表的操作步骤表关系 一对一 一对多： 一的一方：主表 多的一方：从表 外键：需要再从表上新建一列作为外键，他的取值来源于主表的主键 多对多： 中间表：中间表中最少应该由两个字段组成，这两个字段做为外键指向两张表的主键，又组成了联合主键 讲师对学员：一对多关系 实体类中的关系 包含关系：可以通过实体类中的包含关系描述表关系 继承关系 分析步骤 1.明确表关系 2.确定表关系（描述 外键|中间表） 3.编写实体类，再实体类中描述表关系（包含关系） 4.配置映射关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 /** * @Id： 声明主键的配置 * @GeneratedValue: 配置主键生成策略 * strategy * GenerationType.IDENTITY： 自增 * * 底层数据库必须支持自动增长 * GenerationType.SEQUENCE : 序列 oracle * * 底层数据库必须支持序列 * GenerationType.TABLE : jpa提供的一种机制 通过一张数据库表的形式帮助我们完成主键自增 * GenerationType.AUTO : 有程序自动的帮助我们选择主键生成策略 * @Column:配置属性和字段的映射关系 * name: 数据库表中字段的名称 * */ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;cust_id&quot;) private Long custId; //客户主键 @Column(name = &quot;cust_name&quot;) private String custName; //客户名称 @Column(name = &quot;cust_source&quot;) private String custSource; //客户来源 @Column(name = &quot;cust_industry&quot;) private String custIndustry; //客户所属行业 @Column(name = &quot;cust_level&quot;) private String custLevel; //客户级别 @Column(name = &quot;cust_address&quot;) private String custAddress; //客户地址 @Column(name = &quot;cust_phone&quot;) private String custPhone; //客户的联系方式/** * 声明关系： * @OneToMany ：配置一对多的关系 * targetEntity：对方对象的字节码对象 * 配置外键(中间表) * @JoinColumn： 作用：用于定义主键字段和外键字段的对应关系。 * name: 外键字段名称 * referencedColumnName：参照的主表的主键字段名称 * * 在客户实体类上 具备维护外键的作用 */ /*@OneToMany(targetEntity = LinkMan.class) @JoinColumn(name = &quot;lkm_cust_id&quot; ,referencedColumnName = &quot;cust_id&quot;) /** * 放弃外键维护权 * mappedBy ： 对方配置关系的属性名称 * * cascade:配置级联操作 * CascadeType.MERGE 级联更新 * CascadeType.PERSIST 级联保存： * CascadeType.REFRESH 级联刷新： * CascadeType.REMOVE 级联删除： * CascadeType.ALL 包含所有 * * @OneToMany注解中添加fetch属性 * FetchType.EAGER ：立即加载 * FetchType.LAZY ：延迟加载 * */ @OneToMany(mappedBy = &quot;customer&quot;,cascade = CascadeType.ALL,fetch = FetchType.EAGER) private Set&lt;LinkMan&gt; linkMans = new HashSet&lt;LinkMan&gt;(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;lkm_id&quot;) private Long lkmId; @Column(name = &quot;lkm_name&quot;) private String lkmName; @Column(name = &quot;lkm_gender&quot;) private String lkmGender; @Column(name = &quot;lkm_phone&quot;) private String lkmPhone; @Column(name = &quot;lkm_mobile&quot;) private String lkmMobile; @Column(name = &quot;lkm_email&quot;) private String lkmEmail; @Column(name = &quot;lkm_position&quot;) private String lkmPosition; @Column(name = &quot;lkm_memo&quot;) private String lkmMemo; @Column(name = &quot;lkm_custId&quot;) private Long lkmCustId; public Customer getCustomer() &#123; return customer; &#125; public void setCustomer(Customer customer) &#123; this.customer = customer; &#125; /** * 配置联系人到客户的多对一关系 * 使用注解的形式配置多对一 * * @return */ @ManyToOne(targetEntity = Customer.class) @JoinColumn(name = &quot;lkm_cust_id&quot;,referencedColumnName = &quot;cust_id&quot;) private Customer customer; 级联：操作一个对象的同时操作他的关联对象级联操作：1.需要区分操作主体2.需要在操作主体的实体类上，添加级联属性（需要添加到多表映射关系的注解上）3.cascade（配置级联）级联添加，案例：当我保存一个客户的同时保存联系人级联删除案例：当我删除一个客户的同时删除此客户的所有联系人 123456789101112级联操作：指操作一个对象同时操作它的关联对象使用方法：只需要在操作主体的注解上配置cascade /** * cascade:配置级联操作 * CascadeType.MERGE 级联更新 * CascadeType.PERSIST 级联保存： * CascadeType.REFRESH 级联刷新： * CascadeType.REMOVE 级联删除： * CascadeType.ALL 包含所有 */ @OneToMany(mappedBy=&quot;customer&quot;,cascade=CascadeType.ALL)``` 测试代码：1234567891011121314151617181920212223242526272829303132 /** * 级联添加 */ @Test @Transactional @Rollback(value = false) public void testCascadeAdd()&#123; Customer customer = new Customer(); customer.setCustName(&quot;百度&quot;); LinkMan linkMan = new LinkMan(); linkMan.setLkmName(&quot;小李&quot;); linkMan.setCustomer(customer); customer.getLinkMans().add(linkMan); customerDao.save(customer); linkManDao.save(linkMan); &#125; /** * 级联删除 */ @Test @Transactional @Rollback(value = false) public void testRemoveAdd()&#123; Customer customer = customerDao.findOne(1L); customerDao.delete(customer);&#125; 多对多操作 案例：用户和角色（多对多关系） 用户： 角色： 分析步骤 1.明确表关系 多对多关系 2.确定表关系（描述 外键|中间表） 中间间表 3.编写实体类，再实体类中描述表关系（包含关系） 用户：包含角色的集合 角色：包含用户的集合 4.配置映射关系多对多实体类编写：12345678910111213141516171819202122232425262728293031323334353637//用户实体类 @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;user_id&quot;) private Long userId; @Column(name = &quot;user_name&quot;) private String userName; @Column(name = &quot;age&quot;) private Integer age; /** * 配置用户到角色的多对多关系 * @retur */ @ManyToMany(targetEntity = Role.class,cascade = CascadeType.ALL) //配置多对多 @JoinTable(name = &quot;sys_user_role&quot;, //joinColumns,当前对象在中间表中的外键 joinColumns = &#123;@JoinColumn(name = &quot;sys_user_id&quot;,referencedColumnName = &quot;user_id&quot;)&#125;, inverseJoinColumns = &#123;@JoinColumn(name=&quot;sys_role_id&quot;,referencedColumnName = &quot;role_id&quot;)&#125; ) private Set&lt;Role&gt; roles = new HashSet&lt;Role&gt;(); ````````` //角色实体类 @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;role_id&quot;) private Long roleId; @Column(name = &quot;role_name&quot;) private String roleName; @ManyToMany(mappedBy = &quot;roles&quot;) //配置多对多 private Set&lt;User&gt; users = new HashSet&lt;User&gt;(); 注解说明：@OneToMany 作用：建立一对多的关系映射 属性： targetEntityClass：指定多的多方的类的字节码 mappedBy：指定从表实体类中引用主表对象的名称。 cascade：指定要使用的级联操作 CascadeType.MERGE 级联更新CascadeType.PERSIST 级联保存CascadeType.REFRESH 级联刷新CascadeType.REMOVE 级联删除CascadeType.ALL 包含所有 fetch：指定是否采用延迟加载orphanRemoval：是否使用孤儿删除 @ManyToOne 作用：建立多对一的关系 属性： targetEntity：指定一的一方实体类字节码 cascade：指定要使用的级联操作 fetch：指定是否采用延迟加载 optional：关联是否可选。如果设置为false，则必须始终存在非空关系。 @ManyToMany 作用：用于映射多对多关系 属性： cascade：配置级联操作。 fetch：配置是否采用延迟加载。 targetEntity：配置目标的实体类。映射多对多的时候不用写。 @JoinTable 作用：针对中间表的配置 属性： nam：配置中间表的名称 joinColumns：中间表的外键字段关联当前实体类所对应表的主键字段 inverseJoinColumn：中间表的外键字段关联对方表的主键字段 @JoinColumn 作用：用于定义主键字段和外键字段的对应关系。 属性： name：指定外键字段的名称 referencedColumnName：指定引用主表的主键字段名称 unique：是否唯一。默认值不唯一 nullable：是否允许为空。默认值允许。 insertable：是否允许插入。默认值允许。 updatable：是否允许更新。默认值允许。 columnDefinition：列的定义信息。 对象导航查询查询一个对象的同时，通过此对象查询他的关联对象案例：客户和联系人从一方查询多方默认：使用延迟加载（）从多方查询一方默认：使用立即加载 1234567/** * 在客户对象的@OneToMany注解中添加fetch属性 * FetchType.EAGER ：立即加载 * FetchType.LAZY ：延迟加载 */ @OneToMany(mappedBy=&quot;customer&quot;,fetch=FetchType.EAGER) private Set&lt;LinkMan&gt; linkMans = new HashSet&lt;&gt;(0); 123456789/** * 在联系人对象的@ManyToOne注解中添加fetch属性 * FetchType.EAGER ：立即加载 * FetchType.LAZY ：延迟加载 */ @ManyToOne(targetEntity=Customer.class,fetch=FetchType.EAGER) @JoinColumn(name=&quot;cst_lkm_id&quot;,referencedColumnName=&quot;cust_id&quot;) private Customer customer;]]></content>
      <categories>
        <category>SpringData</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringDataJPA]]></title>
    <url>%2F2019%2F04%2F03%2FSpringDataJPA%2F</url>
    <content type="text"><![CDATA[springDataJpa的概述Spring Data JPA 是 Spring 基于 ORM 框架、JPA 规范的基础上封装的一套JPA应用框架，可使开发者用极简的代码即可实现对数据库的访问和操作。它提供了包括增删改查等在内的常用功能，且易于扩展！学习并使用 Spring Data JPA 可以极大提高开发效率！ Spring Data JPA 让我们解脱了DAO层的操作，基本上所有CRUD都可以依赖于它来实现,在实际的工作工程中，推荐使用Spring Data JPA + ORM（如：hibernate）完成操作，这样在切换不同的ORM框架时提供了极大的方便，同时也使数据库层操作更加简单，方便解耦 SpringData Jpa 极大简化了数据库访问层代码。 如何简化的呢？ 使用了SpringDataJpa，我们的dao层中只需要写接口，就自动具有了增删改查、分页查询等方法。 Spring Data JPA的快速入门Spring Data JPA完成客户的基本CRUD操作 搭建Spring Data JPA的开发环境使用Spring Data JPA，需要整合Spring与Spring Data JPA，并且需要提供JPA的服务提供者hibernate，所以需要导入spring相关坐标，hibernate坐标，数据库驱动坐标等pom文件配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142&lt;properties&gt; &lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;hibernate.version&gt;5.0.7.Final&lt;/hibernate.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;c3p0.version&gt;0.9.1.2&lt;/c3p0.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- junit单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring beg --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring end --&gt; &lt;!-- hibernate beg --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.2.1.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- hibernate end --&gt; &lt;!-- c3p0 beg --&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;$&#123;c3p0.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- c3p0 end --&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.9.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- el beg 使用spring data jpa 必须引入 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.el&lt;/groupId&gt; &lt;artifactId&gt;javax.el-api&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.web&lt;/groupId&gt; &lt;artifactId&gt;javax.el&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- el end --&gt; &lt;/dependencies&gt; 整合Spring Data JPA与Spring文件名为 ：applicationContext.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:jdbc=&quot;http://www.springframework.org/schema/jdbc&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:jpa=&quot;http://www.springframework.org/schema/data/jpa&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd&quot;&gt; &lt;!--Spring和 Spring Date jpa 的配置--&gt; &lt;!--创建entityManagerFactory对象交给Spring容器管理--&gt; &lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt; &lt;!--配置的扫描的包（实体类所在的包）--&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.jpa.pojo&quot;&gt;&lt;/property&gt; &lt;!--JPA的是实现厂家--&gt; &lt;property name=&quot;persistenceProvider&quot;&gt; &lt;bean class=&quot;org.hibernate.jpa.HibernatePersistenceProvider&quot;&gt;&lt;/bean&gt; &lt;/property&gt; &lt;!--JPA的供应商的适配器--&gt; &lt;property name=&quot;jpaVendorAdapter&quot;&gt; &lt;bean class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;&gt; &lt;!--配置是否自动创建数据库表--&gt; &lt;property name=&quot;generateDdl&quot; value=&quot;false&quot; /&gt; &lt;!--指定数据库类型--&gt; &lt;property name=&quot;database&quot; value=&quot;MYSQL&quot; /&gt; &lt;!--数据库方言--&gt; &lt;property name=&quot;databasePlatform&quot; value=&quot;org.hibernate.dialect.MySQLDialect&quot; /&gt; &lt;property name=&quot;showSql&quot; value=&quot;true&quot; /&gt; &lt;/bean&gt; &lt;/property&gt; &lt;!--JPA的方言 ： 高级特性--&gt; &lt;property name=&quot;jpaDialect&quot;&gt; &lt;bean class=&quot;org.springframework.orm.jpa.vendor.HibernateJpaDialect&quot;&gt;&lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--创建数据库连接池--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;rcd520.&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql:///jpa&quot;&gt;&lt;/property&gt; &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--整合SpringDataJPA--&gt; &lt;jpa:repositories base-package=&quot;com.jpa.dao&quot; transaction-manager-ref=&quot;transactionManager&quot; entity-manager-factory-ref=&quot;entityManagerFactory&quot;&gt;&lt;/jpa:repositories&gt; &lt;!--配置事务管理器--&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.jpa.JpaTransactionManager&quot;&gt; &lt;property name=&quot;entityManagerFactory&quot; ref=&quot;entityManagerFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--声明式事务--&gt; &lt;!--配置包扫描--&gt; &lt;context:component-scan base-package=&quot;com.jpa&quot;/&gt;&lt;/beans&gt; 编写实体类配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import javax.persistence.*;/** * 客户实体类 * 配置映射关系 * 1.实体类和表的映射关系 * @Entity 声明这是一个实体类 * @Table 配置实体类和表的映射关系 * name: 配置数据库表的名称 * 2.实体类中属性和表中字段的映射关系 * * */@Entity@Table(name = &quot;cst_customer&quot;)public class Customer &#123; /** * @Id： 声明主键的配置 * @GeneratedValue: 配置主键生成策略 * strategy * GenerationType.IDENTITY： 自增 * * 底层数据库必须支持自动增长 * GenerationType.SEQUENCE : 序列 oracle * * 底层数据库必须支持序列 * GenerationType.TABLE : jpa提供的一种机制 通过一张数据库表的形式帮助我们完成主键自增 * GenerationType.AUTO : 有程序自动的帮助我们选择主键生成策略 * @Column:配置属性和字段的映射关系 * name: 数据库表中字段的名称 * */ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;cust_id&quot;) private Long custId; //客户主键 @Column(name = &quot;cust_name&quot;) private String custName; //客户名称 @Column(name = &quot;cust_source&quot;) private String custSource; //客户来源 @Column(name = &quot;cust_industry&quot;) private String custIndustry; //客户所属行业 @Column(name = &quot;cust_level&quot;) private String custLevel; //客户级别 @Column(name = &quot;cust_address&quot;) private String custAddress; //客户地址 @Column(name = &quot;cust_phone&quot;) private String custPhone; //客户的联系方式 @Override public String toString() &#123; return &quot;Customer&#123;&quot; + &quot;custId=&quot; + custId + &quot;, custName=&apos;&quot; + custName + &apos;\&apos;&apos; + &quot;, custSource=&apos;&quot; + custSource + &apos;\&apos;&apos; + &quot;, custIndustry=&apos;&quot; + custIndustry + &apos;\&apos;&apos; + &quot;, custLevel=&apos;&quot; + custLevel + &apos;\&apos;&apos; + &quot;, custAddress=&apos;&quot; + custAddress + &apos;\&apos;&apos; + &quot;, custPhone=&apos;&quot; + custPhone + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125; public Long getCustId() &#123; return custId; &#125; public void setCustId(Long custId) &#123; this.custId = custId; &#125; public String getCustName() &#123; return custName; &#125; public void setCustName(String custName) &#123; this.custName = custName; &#125; public String getCustSource() &#123; return custSource; &#125; public void setCustSource(String custSource) &#123; this.custSource = custSource; &#125; public String getCustIndustry() &#123; return custIndustry; &#125; public void setCustIndustry(String custIndustry) &#123; this.custIndustry = custIndustry; &#125; public String getCustLevel() &#123; return custLevel; &#125; public void setCustLevel(String custLevel) &#123; this.custLevel = custLevel; &#125; public String getCustAddress() &#123; return custAddress; &#125; public void setCustAddress(String custAddress) &#123; this.custAddress = custAddress; &#125; public String getCustPhone() &#123; return custPhone; &#125; public void setCustPhone(String custPhone) &#123; this.custPhone = custPhone; &#125;&#125; 编写一个符合springDataJpa的dao层接口只需要编写dao层接口，不需要编写dao层接口的实现类dao层接口规范符合SpringDateJPA接口规范 JpaRepository&lt;操作的实体类类型，实体类中主键属性类型&gt;, 封装了基本的CRUD的操作 JpaSpecificationExecutor&lt;操作的实体类类型&gt; 封装了复杂查询 12public interface CustomerDao extends JpaRepository&lt;Customer,Long&gt; ,JpaSpecificationExecutor&lt;Customer&gt;&#123;&#125; 以下是简单的CRUD方法 save(customer):保存或者更新（依据：传递的实体类对象中，是否包含id属性） delete（id） ：根据id删除 findAll() : 查询全部 count(): 统计查询 exists(id): 根据ID查询是否存在 返回boolean值 findOne(id) : 立即加载 等同于 em.find()getOne(id) : 延迟加载 等同于 em.getReference()运行getOne()方法需要添加 @Transactional :保证getOne()正常运行 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class CustomerDaoTest &#123; @Autowired private CustomerDao customerDao; /** * 根据ID查询 */ @Test public void findOne()&#123; Customer customer = customerDao.findOne(1L); System.out.println(customer); &#125; /** * save:保存或者更新 * 根据传递的对象是否存在主键ID * 如果没有ID主键属性 ：保存 * 存在ID主键属性 ：根据ID主键查询数据， 更新数据 */ @Test public void testSave()&#123; Customer customer = new Customer(); customer.setCustName(&quot;程序员&quot;); customer.setCustLevel(&quot;VIP&quot;); customer.setCustIndustry(&quot;搬砖&quot;); customerDao.save(customer); &#125; @Test public void testUpdate()&#123; Customer customer = new Customer(); customer.setCustId(2L); customer.setCustName(&quot;程序员&quot;); customer.setCustLevel(&quot;VIP&quot;); customer.setCustIndustry(&quot;不再搬砖&quot;); customerDao.save(customer); &#125; /** * 删除 * */ @Test public void testDelete()&#123; customerDao.delete(2L); &#125; /** * 查询所有 */ @Test public void testFindAll()&#123; List&lt;Customer&gt; all = customerDao.findAll(); for (Customer customer : all) &#123; System.out.println(customer); &#125; &#125; /** * 统计查询 ：查询客户的总数量 */ @Test public void testCount()&#123; long count = customerDao.count(); //查询全部的用户数量 System.out.println(count); &#125; /** * 测试：判断ID为4的客户是否存在 * 可以查询一下id为4的客户 * 如果值为空 代表不存在 如果不为空 代表存在 * 判断数据库ID为4的客户的数量 * 如果大于0 代表存在 如果等于0 代表不存在 */ @Test public void testExie()&#123; boolean exists = customerDao.exists(2L); System.out.println(exists); &#125; /** * 根据ID从数据库查询 * @Transactional :保证getOne()正常运行 * findOne() : 立即加载 等同于 em.find() * getOne() : 延迟加载 等同于 em.getReference() */ @Test @Transactional public void testGetOne()&#123; Customer customer = customerDao.getOne(1L); System.out.println(customer); &#125; 复杂查询jpql的查询方式jpql ： jpa query language （jpq查询语言）特点：语法或关键字和sql语句类似 查询的是类和类中的属性需要将JPQL语句配置到接口方法上1.特有的查询：需要在dao接口上配置方法2.在新添加的方法上，使用注解的形式配置jpql查询语句3.注解 ： @Query1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 根据客户名称查询客户 * jpql: from Customer where custName = ? * 配置jpql语句 使用@Query注解 */ @Query(value = &quot;from Customer where custName = ?&quot;) public Customer findJpql(String custName); /** * 根据酷虎名称和客户Id查询客户 * jpql: from Customer where custName = ? and custId = ? * * 对于多个占位符 参数 * 赋值的时候默认的情况下 占位符的位置需要和方法参数中的位置保持一致 * * 可以指定占位符的位置 * ？ 索引的方式 指定次占位的取值来源 * 例如： * @Query(value = &quot;from Customer where custName = ?2 and custId = ?1 &quot;) * public Customer findCustNameAndId(Long id,String name); * */ @Query(value = &quot;from Customer where custName = ? and custId = ?&quot;) public Customer findCustNameAndId(String name,Long id); /** * 使用JPQL王城更新操作 * 根据id更新 客户的名称 * jpql: update Customer set custName = ? where custId = ? * @Query：代表的是进行查询 * 声明此方法是用来更新 需要使用 * @Modifying 注解 * 表示此方法是用来更新 */ @Query(value = &quot;update Customer set custName = ?2 where custId = ?1 &quot;) @Modifying() public void updateCustomer(long custId,String custName);``` 测试代码： @Autowired private CustomerDao customerDao; @Test public void testFindJpql()&#123; Customer jpql = customerDao.findJpql(&quot;小胖&quot;); System.out.println(jpql); &#125; @Test public void testFindCustNameAndId()&#123; Customer customer = customerDao.findCustNameAndId(&quot;小胖&quot;, 1L); System.out.println(customer); &#125; 在使用JPQL执行更新操作时 需要添加事务 @Transactional 并且 JPQL默认执行事务回滚 需要使用 @Rollback :是否开启自动回滚 (value = false) 关闭事务回滚 默认 等于 true @Test @Transactional @Rollback(value = false) public void testUpdateCustomer()&#123; customerDao.updateCustomer(2L,&quot;小胖子&quot;); &#125; sql语句的查询1.特有的查询：需要在dao接口上配置方法2.在新添加的方法上，使用注解的形式配置sql查询语句3.注解 ： @Queryvalue ：jpql语句 | sql语句nativeQuery ：false（使用jpql查询） | true（使用本地查询：sql查询）是否使用本地查询12345678910111213141516171819202122232425 /** * 使用sql的形式进行查询 * 查询全部用户 * select * from cust_customer * */// @Query(value = &quot;select * from cst_customer&quot; ,nativeQuery = true) @Query(value = &quot;select * from cst_customer where cust_name like ?1 &quot; ,nativeQuery = true) public List&lt;Customer &gt; findSql(String name);测试： //测试sql方式查询@Testpublic void testFindSql()&#123; List&lt;Customer&gt; sql = customerDao.findSql(&quot;小胖&quot;); for (Customer customer : sql) &#123; System.out.println(customer); &#125;&#125;``` 方法名称规则查询方法名的查询findBy : 查询对象中的属性名称 （首字母大写） 查询条件再springdatajpa的运行阶段会根据方法名称进行解析 findBy from xxx(实体类)属性名称 wherefindBy + 属性名称 （根据属性名称进行完成匹配的查询）findBy + 属性名称 + “查询方式（Like | isnull ）”多条件查询findBy + 属性名 + “查询方式” + 多个条件的连接符（and | or） + 属性名 + “查询方式”1234public Customer findByCustName(String name);public List&lt;Customer&gt; findByCustNameLike(String name);//使用客户名称模糊匹配和客户所属行业精准匹配的查询public Customer findByCustNameLikeAndCustIndustry(String name,String industry); 测试： //以方法名称规则查询 @Test public void testFindByCustName(){ Customer customer = customerDao.findByCustName(&quot;小胖&quot;); System.out.println(customer); } //以方法名称规则查询 @Test public void testFindByCustNameLike(){ List&lt;Customer&gt; customers = customerDao.findByCustNameLike(&quot;小胖%&quot;); for (Customer customer : customers) { System.out.println(customer); } } //以方法名称规则查询 @Test public void testFindByCustNameLikeAndCustIndustry(){ Customer customer = customerDao.findByCustNameLikeAndCustIndustry(&quot;小胖%&quot;,&quot;IT&quot;); System.out.println(customer); }]]></content>
      <categories>
        <category>SpringData</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPQL的简单使用]]></title>
    <url>%2F2019%2F04%2F02%2FJPQL%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[JPA中的复杂查询 JPQL全称Java Persistence Query Language 基于首次在EJB2.0中引入的EJB查询语言(EJB QL),Java持久化查询语言(JPQL)是一种可移植的查询语言，旨在以面向对象表达式语言的表达式，将SQL语法和简单查询语义绑定在一起·使用这种语言编写的查询是可移植的，可以被编译成所有主流数据库服务器上的SQL。 其特征与原生SQL语句类似，并且完全面向对象，通过类名和属性访问，而不是表名和表的属性。 sql: 查询的是表和表中的字段jpql: 查询的是实体类和类中的属性 jpql和sql语句的语法相似 查询全部12345678910111213141516171819202122@Test public void testFindAll()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); String jpql = &quot;from com.jap.pojo.Customer&quot;; Query query = em.createQuery(jpql); List resultList = query.getResultList(); for(Object obj:resultList)&#123; System.out.println(obj); &#125; tx.commit(); em.close(); &#125; 排序12345678910111213141516171819202122@Test public void testOrders()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); String jpql = &quot;from com.jap.pojo.Customer order by custId desc &quot;; Query query = em.createQuery(jpql); List resultList = query.getResultList(); for(Object obj:resultList)&#123; System.out.println(obj); &#125; tx.commit(); em.close(); &#125; 聚合函数1234567891011121314151617181920@Test public void testCount()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); String jpql = &quot;select count(custId) from com.jap.pojo.Customer&quot;; Query query = em.createQuery(jpql); Object result = query.getSingleResult(); System.out.println(result); tx.commit(); em.close(); &#125; 分页查询1234567891011121314151617181920212223@Test public void testLimit()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); String jpql = &quot;from com.jap.pojo.Customer&quot;; Query query = em.createQuery(jpql); query.setFirstResult(0); query.setMaxResults(2); List result = query.getResultList(); System.out.println(result); tx.commit(); em.close(); &#125; 条件查询1234567891011121314151617181920212223@Test public void testCondition()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); String jpql = &quot;from com.jap.pojo.Customer where custName like ? &quot;; Query query = em.createQuery(jpql); query.setParameter(1,&quot;I%&quot;); List result = query.getResultList(); System.out.println(result); tx.commit(); em.close(); &#125;]]></content>
      <categories>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPA的入门案例]]></title>
    <url>%2F2019%2F04%2F02%2FJPA%E7%9A%84%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[由于JPA是sun公司制定的API规范，所以我们不需要导入额外的JPA相关的jar包，只需要导入JPA的提供商的jar包。我们选择Hibernate作为JPA的提供商，所以需要导入Hibernate的相关jar包。 导入jar包123456789101112131415161718192021222324252627282930313233343536373839404142&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.hibernate.version&gt;5.0.7.Final&lt;/project.hibernate.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- hibernate对jpa的支持包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;$&#123;project.hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- c3p0 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-c3p0&lt;/artifactId&gt; &lt;version&gt;$&#123;project.hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql and MariaDB --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 实体类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/** * 客户实体类 * 配置映射关系 * 1.实体类和表的映射关系 * @Entity 声明这是一个实体类 * @Table 配置实体类和表的映射关系 * name: 配置数据库表的名称 * 2.实体类中属性和表中字段的映射关系 * * */@Entity@Table(name = &quot;cst_customer&quot;)public class Customer &#123; /** * @Id： 声明主键的配置 * @GeneratedValue: 配置主键生成策略 * strategy * GenerationType.IDENTITY： 自增 * * 底层数据库必须支持自动增长 * GenerationType.SEQUENCE : 序列 oracle * * 底层数据库必须支持序列 * GenerationType.TABLE : jpa提供的一种机制 通过一张数据库表的形式帮助我们完成主键自增 * GenerationType.AUTO : 有程序自动的帮助我们选择主键生成策略 * @Column:配置属性和字段的映射关系 * name: 数据库表中字段的名称 * */ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = &quot;cust_id&quot;) private Long custId; //客户主键 @Column(name = &quot;cust_name&quot;) private String custName; //客户名称 @Column(name = &quot;cust_source&quot;) private String custSource; //客户来源 @Column(name = &quot;cust_industry&quot;) private String custIndustry; //客户所属行业 @Column(name = &quot;cust_level&quot;) private String custLevel; //客户级别 @Column(name = &quot;cust_address&quot;) private String custAddress; //客户地址 @Column(name = &quot;cust_phone&quot;) private String custPhone; //客户的联系方式 @Override public String toString() &#123; return &quot;Customer&#123;&quot; + &quot;custId=&quot; + custId + &quot;, custName=&apos;&quot; + custName + &apos;\&apos;&apos; + &quot;, custSource=&apos;&quot; + custSource + &apos;\&apos;&apos; + &quot;, custIndustry=&apos;&quot; + custIndustry + &apos;\&apos;&apos; + &quot;, custLevel=&apos;&quot; + custLevel + &apos;\&apos;&apos; + &quot;, custAddress=&apos;&quot; + custAddress + &apos;\&apos;&apos; + &quot;, custPhone=&apos;&quot; + custPhone + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125; public Long getCustId() &#123; return custId; &#125; public void setCustId(Long custId) &#123; this.custId = custId; &#125; public String getCustName() &#123; return custName; &#125; public void setCustName(String custName) &#123; this.custName = custName; &#125; public String getCustSource() &#123; return custSource; &#125; public void setCustSource(String custSource) &#123; this.custSource = custSource; &#125; public String getCustIndustry() &#123; return custIndustry; &#125; public void setCustIndustry(String custIndustry) &#123; this.custIndustry = custIndustry; &#125; public String getCustLevel() &#123; return custLevel; &#125; public void setCustLevel(String custLevel) &#123; this.custLevel = custLevel; &#125; public String getCustAddress() &#123; return custAddress; &#125; public void setCustAddress(String custAddress) &#123; this.custAddress = custAddress; &#125; public String getCustPhone() &#123; return custPhone; &#125; public void setCustPhone(String custPhone) &#123; this.custPhone = custPhone; &#125;&#125; 创建一个文件 persistence.xml 填写配置12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;persistence xmlns=&quot;http://java.sun.com/xml/ns/persistence&quot; version=&quot;2.0&quot;&gt; &lt;!--需要配置 persistence-unit 节点 持久化单元格： name:持久化单元格名称 transaction-type:事务管理方式 JTA:分布式事务管理 RESOURCE_LOCAL:本地事务管理 --&gt; &lt;persistence-unit name=&quot;myJpa&quot; transaction-type=&quot;RESOURCE_LOCAL&quot;&gt; &lt;!--jpa的实现方式--&gt; &lt;provider&gt;org.hibernate.jpa.HibernatePersistenceProvider&lt;/provider&gt; &lt;!--数据库信息 用户名： javax.persistence.jdbc.user 密码： javax.persistence.jdbc.password 地址： javax.persistence.jdbc.url 数据库驱动： javax.persistence.jdbc.mysql --&gt; &lt;properties&gt; &lt;property name=&quot;javax.persistence.jdbc.user&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;javax.persistence.jdbc.password&quot; value=&quot;rcd520.&quot; /&gt; &lt;property name=&quot;javax.persistence.jdbc.url&quot; value=&quot;jdbc:mysql:///jpa&quot; /&gt; &lt;property name=&quot;javax.persistence.jdbc.mysql&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;!--可选配置 : 配置jpa实现方的配置信息 显示sql: false | true 自动创建数据库表： create: 程序运行时创建数据库表（如果有表 先删除再创建表） update: 程序运行时创建表（如果有表 不会创建表） none: 不会创建表 --&gt; &lt;property name=&quot;hibernate.show_sql&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;hibernate.hbm2ddl.auto&quot; value=&quot;update&quot; /&gt; &lt;/properties&gt; &lt;/persistence-unit&gt;&lt;/persistence&gt; 创建一个JPA的工具类 1234567891011121314151617181920212223/** * 解决实体管理工厂的浪费资源的耗时问题 * 通过静态代码块 当程序第一次访问此工具类时 创建一个公共的实体管理器工厂对象 * */public class JpaUtils &#123; private static EntityManagerFactory factory; static &#123; //加载配置文件 factory = Persistence.createEntityManagerFactory(&quot;myJpa&quot;); &#125; /** * 获取EntityManage对象 */ public static EntityManager getEntityManager()&#123; return factory.createEntityManager(); &#125;&#125; 在JPA 的查询方法中 保存：persist(Object o) 查询：find(Customer.class, 1L)/getReference(Customer.class, 1L) 根据id进行查询 删除：remove(object o) 更新：merge(Object o) 最后测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124public class JpaTest &#123; /** * 测试JPA的保存 * * JPA的操作步骤 * 加载配置文件创建工厂对象 * 通过实体类管理类工厂获取实体类管理器 * 获取事务对象 开启事务 * 完成增删改查操作 * 提交事务 * 释放资源 */ @Test public void testSave() &#123; //加载配置文件创建工厂对象 //EntityManagerFactory factory = Persistence.createEntityManagerFactory(&quot;myJpa&quot;); // 通过实体类管理类工厂获取实体类管理器// EntityManager em = factory.createEntityManager(); EntityManager em = JpaUtils.getEntityManager();// 获取事务对象 开启事务 EntityTransaction tx = em.getTransaction(); tx.begin(); //开启事务// 完成增删改查操作 Customer customer = new Customer(); customer.setCustName(&quot;小胖&quot;); customer.setCustIndustry(&quot;血池&quot;); //保存 em.persist(customer); //提交事务 tx.commit(); //释放资源 em.close(); &#125; /** * find() 立即加载 */ @Test public void testFind()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); Customer customer = em.find(Customer.class, 1L); System.out.println(customer); tx.commit(); em.close(); &#125; /** * getReference() 延迟加载 或者时 懒加载 */ @Test public void testReference()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); Customer customer = em.getReference(Customer.class, 1L); System.out.println(customer); tx.commit(); em.close(); &#125; /** * 删除 */ @Test public void testRemove()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); Customer customer = em.find(Customer.class, 1L); em.remove(customer); tx.commit(); em.close(); &#125; /** * 更新 * 使用 merge()方法 * */ @Test public void testUpdate()&#123; EntityManager em = JpaUtils.getEntityManager(); EntityTransaction tx = em.getTransaction(); tx.begin(); Customer customer = em.find(Customer.class, 1L); customer.setCustIndustry(&quot;IT&quot;); em.merge(customer); tx.commit(); em.close(); &#125;&#125;]]></content>
      <categories>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORM思想]]></title>
    <url>%2F2019%2F04%2F02%2FORM%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[简单了解ORM思想ORM（Object-Relational Mapping） 表示对象关系映射。在面向对象的软件开发中，通过ORM，就可以把对象映射到关系型数据库中。只要有一套程序能够做到建立对象与数据库的关联，操作对象就可以直接操作数据库数据，就可以说这套程序实现了ORM对象关系映射 **主要目的** ：操作实体类就相当于操作数据库表，只需要对象打点调方法就可以实现数据库操作 建立两个映射关系： 实体类和表的与映射关系 实体类中属性与表中字段的映射关系 不再重点关注：sql语句 就能实现操作 实现了ORM思想的框架 ： mybatis,hibarnate,JPA 为什么使用ORM当实现一个应用程序时（不使用O/R Mapping），我们可能会写特别多数据访问层的代码，从数据库保存数据、修改数据、删除数据，而这些代码都是重复的。而使用ORM则会大大减少重复性代码。对象关系映射（Object Relational Mapping，简称ORM），主要实现程序对象到关系数据库数据的映射 JPA概述JPA的全称是Java Persistence API， 即Java 持久化API，是SUN公司推出的一套基于ORM的规范，内部是由一系列的接口和抽象类构成。 JPA通过JDK 5.0注解描述对象－关系表的映射关系，并将运行期的实体对象持久化到数据库中 hibernate概述Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 JPA的优势 标准化 容器级特性的支持 简单方便 查询能力 高级特性 JPA与hibernate的关系JPA规范本质上就是一种ORM规范，注意不是ORM框架——因为JPA并未提供ORM实现，它只是制订了一些规范，提供了一些编程的API接口，但具体实现则由服务厂商来提供实现 JPA和Hibernate的关系就像JDBC和JDBC驱动的关系，JPA是规范，Hibernate除了作为ORM框架之外，它也是一种JPA实现。JPA怎么取代Hibernate呢？JDBC规范可以驱动底层数据库吗？答案是否定的，也就是说，如果使用JPA规范进行数据库操作，底层需要hibernate作为其实现类完成数据持久化工作。]]></content>
      <categories>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[方法引用]]></title>
    <url>%2F2019%2F04%2F02%2F%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在使用Lambda表达式的时候，我们实际上传递进去的代码就是一种解决方案：拿什么参数做什么操作。那么考虑 一种情况：如果我们在Lambda中所指定的操作方案，已经有地方存在相同方案，那是否还有必要再写重复逻辑？ 方法引用符双冒号 :: 为引用运算符，而它所在的表达式被称为方法引用。如果Lambda要表达的函数方案已经存在于某个方 法的实现中，那么则可以通过双冒号来引用该方法作为Lambda的替代者。 System.out 对象中有一个重载的 println(String) 方法恰好就是我们所需要的。那么对于 printString 方法的函数式接口参数，对比下面两种写法，完全等效： - Lambda表达式写法： s -&gt; System.out.println(s); - 方法引用写法： System.out::println 第一种语义是指：拿到参数之后经Lambda之手，继而传递给 System.out.println 方法去处理。 第二种等效写法的语义是指：直接让 System.out 中的 println 方法来取代Lambda。两种写法的执行效果完全一 样，而第二种方法引用的写法复用了已有方案，更加简洁。 注:Lambda 中 传递的参数 一定是方法引用中 的那个方法可以接收的类型,否则会抛出异常 推导与省略如果使用Lambda，那么根据“可推导就是可省略”的原则，无需指定参数类型，也无需指定的重载形式——它们都 将被自动推导。而如果使用方法引用，也是同样可以根据上下文进行推导。 函数式接口是Lambda的基础，而方法引用是Lambda的孪生兄弟。下面这段代码将会调用 println 方法的不同重载形式，将函数式接口改为int类型的参数：1234@FunctionalInterface public interface PrintableInteger &#123; void print(int str); &#125; 由于上下文变了之后可以自动推导出唯一对应的匹配重载，所以方法引用没有任何变化： 123456789public class Demo03PrintOverload &#123; private static void printInteger(PrintableInteger data) &#123; data.print(1024); &#125; public static void main(String[] args) &#123; printInteger(System.out::println); &#125; &#125; 这次方法引用将会自动匹配到 println(int) 的重载形式。 通过对象名引用成员方法这是常见的一种用法，与上例相同。如果一个类中已经存在了一个成员方法12345public class MethodRefObject &#123; public void printUpperCase(String str) &#123; System.out.println(str.toUpperCase()); &#125; &#125; 函数式接口仍然定义为：1234@FunctionalInterface public interface Printable &#123; void print(String str); &#125; 那么当需要使用这个 printUpperCase 成员方法来替代 Printable 接口的Lambda的时候，已经具有了 MethodRefObject 类的对象实例，则可以通过对象名引用成员方法，代码为：123456789public class Demo04MethodRef &#123; private static void printString(Printable lambda) &#123; lambda.print(&quot;Hello&quot;); &#125; public static void main(String[] args) &#123; MethodRefObject obj = new MethodRefObject(); printString(obj::printUpperCase); &#125; &#125; 通过类名称引用静态方法由于在 java.lang.Math 类中已经存在了静态方法 abs ，所以当我们需要通过Lambda来调用该方法时，有两种写 法。首先是函数式接口：1234@FunctionalInterface public interface Calcable &#123; int calc(int num); &#125; 第一种写法是使用Lambda表达式：12345678public class Demo05Lambda &#123; private static void method(int num, Calcable lambda) &#123; System.out.println(lambda.calc(num)); &#125; public static void main(String[] args) &#123; method(‐10, n ‐&gt; Math.abs(n)); &#125; &#125; 但是使用方法引用的更好写法是：12345678public class Demo06MethodRef &#123; private static void method(int num, Calcable lambda) &#123; System.out.println(lambda.calc(num)); &#125; public static void main(String[] args) &#123; method(‐10, Math::abs); &#125; &#125; 在这个例子中，下面两种写法是等效的： - Lambda表达式： n -&gt; Math.abs(n) - 方法引用： Math::abs 通过super引用成员方法如果存在继承关系，当Lambda中需要出现super调用时，也可以使用方法引用进行替代。首先是函数式接口1234@FunctionalInterface public interface Greetable &#123; void greet(); &#125; 然后是父类 Human 的内容：12345public class Human &#123; public void sayHello() &#123; System.out.println(&quot;Hello!&quot;); &#125;&#125; 最后是子类 Man 的内容，其中使用了Lambda的写法：123456789101112131415161718192021public class Man extends Human &#123; @Override public void sayHello() &#123; System.out.println(&quot;大家好,我是Man!&quot;); &#125; //定义方法method,参数传递Greetable接口 public void method(Greetable g)&#123; g.greet(); &#125; public void show()&#123; //调用method方法,使用Lambda表达式 method(()‐&gt;&#123; //创建Human对象,调用sayHello方法 new Human().sayHello(); &#125;); //简化Lambda method(()‐&gt;new Human().sayHello()); //使用super关键字代替父类对象 method(()‐&gt;super.sayHello()); &#125; &#125; 但是如果使用方法引用来调用父类中的 sayHello 方法会更好，例如另一个子类 Woman 12345678910111213public class Man extends Human &#123; @Override public void sayHello() &#123; System.out.println(&quot;大家好,我是Man!&quot;); &#125; //定义方法method,参数传递Greetable接口 public void method(Greetable g)&#123; g.greet(); &#125; public void show()&#123; method(super::sayHello); &#125; &#125; 在这个例子中，下面两种写法是等效的： Lambda表达式： () -&gt; super.sayHello() 方法引用： super::sayHello 通过this引用成员方法this代表当前对象，如果需要引用的方法就是当前类中的成员方法，那么可以使用“this::成员方法”的格式来使用方 法引用。首先是简单的函数式接口：1234@FunctionalInterface public interface Richable &#123; void buy(); &#125; 下面是一个丈夫 Husband 类：12345678public class Husband &#123; private void marry(Richable lambda) &#123; lambda.buy(); &#125; public void beHappy() &#123; marry(() ‐&gt; System.out.println(&quot;买套房子&quot;)); &#125; &#125; 开心方法 beHappy 调用了结婚方法 marry ，后者的参数为函数式接口 Richable ，所以需要一个Lambda表达式。 但是如果这个Lambda表达式的内容已经在本类当中存在了，则可以对 Husband 丈夫类进行修改： 1234567891011public class Husband &#123; private void buyHouse() &#123; System.out.println(&quot;买套房子&quot;); &#125; private void marry(Richable lambda) &#123; lambda.buy(); &#125; public void beHappy() &#123; marry(() ‐&gt; this.buyHouse()); &#125; &#125; 如果希望取消掉Lambda表达式，用方法引用进行替换，则更好的写法为： 1234567891011public class Husband &#123; private void buyHouse() &#123; System.out.println(&quot;买套房子&quot;); &#125; private void marry(Richable lambda) &#123; lambda.buy(); &#125; public void beHappy() &#123; marry(this::buyHouse); &#125; &#125; 在这个例子中，下面两种写法是等效的： Lambda表达式： () -&gt; this.buyHouse() 方法引用： this::buyHouse 类的构造器引用由于构造器的名称与类名完全一样，并不固定。所以构造器引用使用 类名称::new 的格式表示。首先是一个简单 的 Person 类123456789101112public class Person &#123; private String name; public Person(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 然后是用来创建 Person 对象的函数式接口 123public interface PersonBuilder &#123; Person buildPerson(String name); &#125; 要使用这个函数式接口，可以通过Lambda表达式：12345678public class Demo09Lambda &#123; public static void printName(String name, PersonBuilder builder) &#123; System.out.println(builder.buildPerson(name).getName()); &#125; public static void main(String[] args) &#123; printName(&quot;赵丽颖&quot;, name ‐&gt; new Person(name)); &#125; &#125; 但是通过构造器引用，有更好的写法：12345678public class Demo10ConstructorRef &#123; public static void printName(String name, PersonBuilder builder) &#123; System.out.println(builder.buildPerson(name).getName()); &#125; public static void main(String[] args) &#123; printName(&quot;赵丽颖&quot;, Person::new); &#125; &#125; 数组的构造器引用数组也是 Object 的子类对象，所以同样具有构造器，只是语法稍有不同。如果对应到Lambda的使用场景中时， 需要一个函数式接口：1234@FunctionalInterface public interface ArrayBuilder&#123; int[] buildArray(int length); &#125; 在应用该接口的时候，可以通过Lambda表达式：12345678public class Demo11ArrayInitRef &#123; private static int[] initArray(int length, ArrayBuilder builder) &#123; return builder.buildArray(length); &#125; public static void main(String[] args) &#123; int[] array = initArray(10, length ‐&gt; new int[length]); &#125; &#125; 但是更好的写法是使用数组的构造器引用：12345678public class Demo12ArrayInitRef &#123; private static int[] initArray(int length, ArrayBuilder builder) &#123; return builder.buildArray(length); &#125; public static void main(String[] args) &#123; int[] array = initArray(10, int[]::new); &#125; &#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stream]]></title>
    <url>%2F2019%2F04%2F02%2FStream%E6%B5%81%2F</url>
    <content type="text"><![CDATA[说到Stream便容易想到I/O Stream，而实际上，谁规定“流”就一定是“IO流”呢？在Java 8中，得益于Lambda所带 来的函数式编程，引入了一个全新的Stream概念，用于解决已有集合类库既有的弊端。 流式思想概述Stream（流）是一个来自数据源的元素队列元素是特定类型的对象，形成一个队列。 Java中的Stream并不会存储元素，而是按需计算。 数据源 流的来源。 可以是集合，数组 等。 和以前的Collection操作不同， Stream操作还有两个基础的特征： Pipelining: 中间操作都会返回流对象本身。 这样多个操作可以串联成一个管道， 如同流式风格（ﬂuent style）。 这样做可以对操作进行优化， 比如延迟执行(laziness)和短路( short-circuiting)。 内部迭代： 以前对集合遍历都是通过Iterator或者增强for的方式, 显式的在集合外部进行迭代， 这叫做外部迭 代。 Stream提供了内部迭代的方式，流可以直接调用遍历方法。当使用一个流的时候，通常包括三个基本步骤：获取一个数据源（source）→ 数据转换→执行操作获取想要的结 果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以 像链条一样排列，变成一个管道。 获取流java.util.stream.Stream 是Java 8新加入的常用的流接口。（这并不是一个函数式接口。）获取一个流非常简单，有以下几种常用的方式： - 所有的 Collection 集合都可以通过 stream 默认方法获取流； - Stream 接口的静态方法 of 可以获取数组对应的流。 123456789101112131415161718192021222324252627public class Demo1 &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;张无忌&quot;); list.add(&quot;周芷若&quot;); list.add(&quot;赵敏&quot;); list.add(&quot;张强&quot;); list.add(&quot;张三丰&quot;); /*for(String name : list) &#123; System.out.println(name); &#125;*/ list.stream().filter((s) -&gt; s.startsWith(&quot;张&quot;)).filter((s) -&gt; s.length()==3).forEach((s) -&gt; System.out.println(s)); //获取键值对(键与值的映射关系 entrySet) Map&lt;String ,String &gt; map = new HashMap&lt;&gt;(); Set&lt;Map.Entry&lt;String, String&gt;&gt; entries = map.entrySet(); Stream&lt;Map.Entry&lt;String, String&gt;&gt; stream = entries.stream(); //将数组转换成Stream流 Integer[] arr = &#123;1,23,4,5,6,2&#125;; Stream&lt;Integer&gt; arr1 = Stream.of(arr); &#125;&#125; 常用方法流模型的操作很丰富，这里介绍一些常用的API。这些方法可以被分成两种：延迟方法：返回值类型仍然是 Stream 接口自身类型的方法，因此支持链式调用。（除了终结方法外，其余方 法均为延迟方法。）终结方法：返回值类型不再是 Stream 接口自身类型的方法，因此不再支持类似 StringBuilder 那样的链式调 用。本小节中，终结方法包括 count 和 forEach 方法 逐一处理 forEach虽然方法名字叫 forEach ，但是与for循环中的“for-each”昵称不同。1void forEach(Consumer&lt;? super T&gt; action); 该方法接收一个 Consumer 接口函数，会将每一个流元素交给该函数进行处理 复习Consumer接口12java.util.function.Consumer&lt;T&gt;接口是一个消费型接口。 Consumer接口中包含抽象方法void accept(T t)，意为消费一个指定泛型的数据。 基本使用12345678import java.util.stream.Stream; public class Demo12StreamForEach &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; stream = Stream.of(&quot;张无忌&quot;, &quot;张三丰&quot;, &quot;周芷若&quot;); stream.forEach(name‐&gt; System.out.println(name)); &#125; &#125; 过滤 filter可以通过 filter 方法将一个流转换成另一个子集流。方法签名：1Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate); 该接口接收一个 Predicate 函数式接口参数（可以是一个Lambda或方法引用）作为筛选条件 复习Perdicate此前我们已经学习过 java.util.stream.Predicate 函数式接口，其中唯一的抽象方法为： 1boolean test(T t); 该方法将会产生一个boolean值结果，代表指定的条件是否满足。如果结果为true，那么Stream流的 filter 方法 将会留用元素；如果结果为false，那么 filter 方法将会舍弃元素。 基本使用Stream流中的 filter 方法基本使用的代码如：1234567import java.util.stream.Stream; public class Demo07StreamFilter &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; original = Stream.of(&quot;张无忌&quot;, &quot;张三丰&quot;, &quot;周芷若&quot;); Stream&lt;String&gt; result = original.filter(s ‐&gt; s.startsWith(&quot;张&quot;)); &#125; &#125; 在这里通过Lambda表达式来指定了筛选的条件：必须姓张。 映射：map如果需要将流中的元素映射到另一个流中，可以使用 map 方法。方法签名：1&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper); 该接口需要一个 Function 函数式接口参数，可以将当前流中的T类型数据转换为另一种R类型的流。 复习Function接口此前我们已经学习过 java.util.stream.Function 函数式接口，其中唯一的抽象方法为：1R apply(T t); 这可以将一种T类型转换成为R类型，而这种转换的动作，就称为“映射”。 基本使用Stream流中的 map 方法基本使用的代码如：12345678import java.util.stream.Stream; public class Demo08StreamMap &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; original = Stream.of(&quot;10&quot;, &quot;12&quot;, &quot;18&quot;); Stream&lt;Integer&gt; result = original.map(str‐&gt;Integer.parseInt(str)); &#125; &#125; 这段代码中， map 方法的参数通过方法引用，将字符串类型转换成为了int类型（并自动装箱为 Integer 类对 象）。 统计个数：count正如旧集合 Collection 当中的 size 方法一样，流提供 count 方法来数一数其中的元素个数：1long count(); 该方法返回一个long值代表元素个数（不再像旧集合那样是int值）。 基本使用1234567891011import java.util.stream.Stream; public class Demo09StreamCount &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; original = Stream.of(&quot;张无忌&quot;, &quot;张三丰&quot;, &quot;周芷若&quot;); Stream&lt;String&gt; result = original.filter(s ‐&gt; s.startsWith(&quot;张&quot;)); System.out.println(result.count()); // 2 &#125; &#125; 抓取前几个：limitlimit 方法可以对流进行截取，只取用前n个。方法签名：1Stream&lt;T&gt; limit(long maxSize); 参数是一个long型，如果集合当前长度大于参数则进行截取；否则不进行操作。 基本使用：12345678910import java.util.stream.Stream; public class Demo10StreamLimit &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; original = Stream.of(&quot;张无忌&quot;, &quot;张三丰&quot;, &quot;周芷若&quot;); Stream&lt;String&gt; result = original.limit(2); System.out.println(result.count()); // 2 &#125; &#125; 跳过前几个：skip如果希望跳过前几个元素，可以使用 skip 方法获取一个截取之后的新流：1Stream&lt;T&gt; skip(long n); 如果流的当前长度大于n，则跳过前n个；否则将会得到一个长度为0的空流。 基本使用：12345678910import java.util.stream.Stream; public class Demo11StreamSkip &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; original = Stream.of(&quot;张无忌&quot;, &quot;张三丰&quot;, &quot;周芷若&quot;); Stream&lt;String&gt; result = original.skip(2); System.out.println(result.count()); // 1 &#125; &#125; 组合：concat如果有两个流，希望合并成为一个流，那么可以使用 Stream 接口的静态方法 concat1static &lt;T&gt; Stream&lt;T&gt; concat(Stream&lt;? extends T&gt; a, Stream&lt;? extends T&gt; b) 这是一个静态方法，与 java.lang.String 当中的 concat 方法是不同的 该方法的基本使用代码如 12345678import java.util.stream.Stream; public class Demo12StreamConcat &#123; public static void main(String[] args) &#123; Stream&lt;String&gt; streamA = Stream.of(&quot;张无忌&quot;); Stream&lt;String&gt; streamB = Stream.of(&quot;张翠山&quot;); Stream&lt;String&gt; result = Stream.concat(streamA, streamB); &#125; &#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数式接口]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[函数式接口在Java中是指：有且仅有一个抽象方法的接口。函数式接口，即适用于函数式编程场景的接口。而Java中的函数式编程体现就是Lambda，所以函数式接口就是可 以适用于Lambda使用的接口。只有确保接口中有且仅有一个抽象方法，Java中的Lambda才能顺利地进行推导 备注：“语法糖”是指使用更加方便，但是原理不变的代码语法。例如在遍历集合时使用的for-each语法，其实 底层的实现原理仍然是迭代器，这便是“语法糖”。从应用层面来讲，Java中的Lambda可以被当做是匿名内部 类的“语法糖”，但是二者在原理上是不同的。 只要确保接口中有且仅有一个抽象方法即可：1234 修饰符 interface 接口名称 &#123; public abstract 返回值类型 方法名称(可选参数信息); // 其他非抽象方法内容&#125; 由于接口当中抽象方法的 public abstract 是可以省略的，所以定义一个函数式接口很简单： @FunctionalInterface注解与 @Override 注解的作用类似，Java 8中专门为函数式接口引入了一个新的注解： @FunctionalInterface 。该注 解可用于一个接口的定义上： 一旦使用该注解来定义接口，编译器将会强制检查该接口是否确实有且仅有一个抽象方法，否则将会报错。需要注 意的是，即使不使用该注解，只要满足函数式接口的定义，这仍然是一个函数式接口，使用起来都一样。 自定义函数式接口对于刚刚定义好的 MyFunctionalInterface 函数式接口，典型使用场景就是作为方法的参数： 123456789101112public class Demo09FunctionalInterface &#123; // 使用自定义的函数式接口作为方法参数 private static void doSomething(MyFunctionalInterface inter) &#123; inter.myMethod(); // 调用自定义的函数式接口方法 &#125; public static void main(String[] args) &#123; // 调用使用函数式接口的方法 doSomething(() ‐&gt; System.out.println(&quot;Lambda执行啦！&quot;)); &#125; &#125; 常用的函数式接口Supplier接口Supplier 接口被称之为生产型接口 指定接口的泛型式什么类型 那么接口中的get方法就会生产什么类型的数据 练习一：123456789101112131415161718192021222324import java.util.function.Supplier;public class Demo1Supplier &#123; //定义一个方法 方法的参数传递Supplier&lt;T&gt;接口 泛型执行String get方法就会返回一个String类型 public static String getString(Supplier&lt;String&gt; sup)&#123; return sup.get(); &#125; public static void main(String[] args) &#123; /*String s = getString(() -&gt; &#123; return &quot;胡歌&quot;; &#125;); System.out.println(s);*/ String s = getString(() -&gt; &quot;黄飞鸿&quot;); System.out.println(s); &#125;&#125; 练习二： 12345678910111213141516171819202122232425262728public class Demo2Supplier &#123; //定义一个方法 用于获取int类型数组中元素的最大值 参数传递Supplier接口 泛型使用Integer public static int getMax(Supplier&lt;Integer&gt; sup)&#123; return sup.get(); &#125; public static void main(String[] args) &#123; //定义一个int类型数组 int[] arr = &#123;100,2,312,43,-52,12,43,-2&#125;; //调用getMax方法 ，方法的参数Supplier是一个函数式接口 所以可以传递Lambda表达式 int maxValue = getMax(() -&gt; &#123; //获取数组的最大值 ，并返回 //定义一个变量 int max = arr[0]; for (int i : arr) &#123; if (i &gt; max) &#123; max = i; &#125; &#125; return max; &#125;); System.out.println(&quot;最大元素是&quot;+maxValue); &#125;&#125; Consumer接口Consumer 接口被称之为消费型接口 指定接口的泛型式什么类型 那么接口中的accept方法就会消费什么类型的数据 练习一：123456789101112131415161718192021222324252627public class Demo1Consumer &#123; //方法的参数传递一个字符串的姓名 //方法参数的传递Consumer接口 泛型使用String //可以使用Consumer接口消费字符串的姓名 public static void method(String name, Consumer&lt;String&gt; con) &#123; con.accept(name); &#125; public static void main(String[] args) &#123; method(&quot;小胖子&quot;,(String name) -&gt; &#123; System.out.println(name); //使用reverse()方法对字符串进行反转 String eman = new StringBuilder(name).reverse().toString(); System.out.println(eman); &#125;); method(&quot;康师傅&quot;,(String name) -&gt; System.out.println(new StringBuilder(name).reverse().toString())); &#125;&#125; 练习二：123456789101112131415161718192021222324/** * Consumer接口的默认方法andThen * 作用：需要两个Consumer接口 可以把两个Consumer接口组合到一起 在对数据进行消费 */public class Demo2Consumer &#123; //定义一个方法 方法的参数传递一个字符串喝两个Consumer接口 Consumer接口的泛型使用字符串 public static void method(String name , Consumer&lt;String&gt; con1,Consumer&lt;String&gt; con2)&#123; // con1.accept(name); // con2.accept(name); con1.andThen(con2).accept(name); &#125; public static void main(String[] args) &#123; method(&quot;hello&quot;, (name) -&gt; &#123; System.out.println(name.toUpperCase()); &#125;, (name) -&gt; &#123; System.out.println(name.toLowerCase()); &#125;); &#125;&#125; Predicate接口Predicate接口 是对结果进行判断的接口123456789101112131415public class Demo1Predicate &#123; //使用Predicate的text()方法对字符串进行判断 并把结果返回 public static boolean checking(String s, Predicate&lt;String&gt; pre)&#123; return pre.test(s); &#125; public static void main(String[] args) &#123; boolean b = checking(&quot;asdda&quot;, (str) -&gt; str.length() &gt; 5); System.out.println(b); &#125;&#125; 其中 and() or() negate() 方法的简单使用 123456789101112public static boolean checking(String s , Predicate&lt;String&gt; pre1,Predicate&lt;String&gt; pre2)&#123; return pre1.and(pre2).test(s); //等价于 return pre1.test(s) &amp;&amp; pre2.test(2); &#125;public static boolean checking(String s , Predicate&lt;String&gt; pre1, Predicate&lt;String&gt; pre2)&#123; return pre1.or(pre2).test(s); //等价于 return pre1.test(s) || pre2.test(2); &#125; public static boolean checking(String s , Predicate&lt;String&gt; pre)&#123; return pre.negate().test(s); //等价于 return !pre1.test(s); &#125; 综合练习1234567891011121314151617181920212223public class Demo5Test &#123; public static List&lt;String&gt; checking(String[] arr , Predicate&lt;String&gt; pre1,Predicate&lt;String&gt; pre2)&#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (String s : arr) &#123; boolean b = pre1.and(pre2).test(s); if(b)&#123; list.add(s); &#125; &#125; return list; &#125; public static void main(String[] args) &#123; String[] arr = &#123;&quot;马云,男&quot;,&quot;马化腾,男&quot;,&quot;董明珠,女&quot;&#125;; List&lt;String&gt; list = checking(arr, (s) -&gt; s.split(&quot;,&quot;)[0].length() &gt; 2, (s) -&gt; s.split(&quot;,&quot;)[1].contains(&quot;女&quot;)); System.out.println(list); &#125;&#125; Function接口Function接口有两个泛型 输入什么类型转换成指定类型 练习一：123456789101112131415161718public class Demo1Function &#123; /** * 方法参数传递 一个Function接口 泛型使用&lt;String ,Integer&gt; * 使用Function接口传递中的方法apply，把支付穿争行 转化为Integer类型整数 * */ public static void change(String str, Function&lt;String ,Integer&gt; fun)&#123; Integer apply = fun.apply(str); System.out.println(apply); &#125; public static void main(String[] args) &#123; change(&quot;13&quot;,(s) -&gt; Integer.parseInt(s)); &#125;&#125; 练习二：123456789101112131415161718192021public class Demo2Function &#123; /** * * 使用Function函数式接口 andThen()方法 * * 参数传一个字符串类型的整数 * 参数在传递两个function 接口 * 一个泛型接口Function&lt;String,Integer&gt; * 一个泛型接口Function&lt;Integer,String&gt; * */ public static void change(String str, Function&lt;String ,Integer&gt; fun1 ,Function&lt;Integer,String &gt; fun2)&#123; String s = fun1.andThen(fun2).apply(str); System.out.println(s); &#125; public static void main(String[] args) &#123; change(&quot;123&quot;,(s) -&gt; Integer.parseInt(s)+10,(i)-&gt; i+&quot;&quot;); &#125;&#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda表达式]]></title>
    <url>%2F2019%2F04%2F01%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[函数式编程思想概述在数学中，函数就是有输入量、输出量的一套计算方案，也就是“拿什么东西做什么事情”。相对而言，面向对象过分强调“必须通过对象的形式来做事情”，而函数式思想则尽量忽略面向对象的复杂语法——强调做什么，而不是以什么形式做。 面向对象的思想: 做一件事情,找一个能解决这个事情的对象,调用对象的方法,完成事情. 函数式编程思想: 只要能获取到结果,谁去做的,怎么做的都不重要,重视的是结果,不重视过程 冗余的Runnable代码传统写法当需要启动一个线程去完成任务时，通常会通过java.lang.Runnable接口来定义任务内容，并使用java.lang.Thread类来启动该线程。代码如下： 12345678910111213public class Demo01Runnable &#123; public static void main(String[] args) &#123; // 匿名内部类 Runnable task = new Runnable() &#123; @Override public void run() &#123; // 覆盖重写抽象方法 System.out.println(&quot;多线程任务执行！&quot;); &#125; &#125;; new Thread(task).start(); // 启动线程 &#125;&#125; 本着“一切皆对象”的思想，这种做法是无可厚非的：首先创建一个Runnable接口的匿名内部类对象来指定任务内容，再将其交给一个线程来启动。 代码分析 对于Runnable的匿名内部类用法，可以分析出几点内容： Thread类需要Runnable接口作为参数，其中的抽象run方法是用来指定线程任务内容的核心； 为了指定run的方法体，不得不需要Runnable接口的实现类； 为了省去定义一个RunnableImpl实现类的麻烦，不得不使用匿名内部类； 必须覆盖重写抽象run方法，所以方法名称、方法参数、方法返回值不得不再写一遍，且不能写错； 而实际上，似乎只有方法体才是关键所在。 编程思想转换做什么，而不是怎么做 我们真的希望创建一个匿名内部类对象吗？不。我们只是为了做这件事情而不得不创建一个对象。我们真正希望做的事情是：将run方法体内的代码传递给Thread类知晓。 传递一段代码——这才是我们真正的目的。而创建对象只是受限于面向对象语法而不得不采取的一种手段方式。那，有没有更加简单的办法？如果我们将关注点从“怎么做”回归到“做什么”的本质上，就会发现只要能够更好地达到目的，过程与形式其实并不重要。 体验Lambda的更优写法借助Java 8的全新语法，上述Runnable接口的匿名内部类写法可以通过更简单的Lambda表达式达到等效： 12345public class Demo02LambdaRunnable &#123; public static void main(String[] args) &#123; new Thread(() -&gt; System.out.println(&quot;多线程任务执行！&quot;)).start(); // 启动线程 &#125;&#125; 这段代码和刚才的执行效果是完全一样的，可以在1.8或更高的编译级别下通过。从代码的语义中可以看出：我们启动了一个线程，而线程任务的内容以一种更加简洁的形式被指定。 不再有“不得不创建接口对象”的束缚，不再有“抽象方法覆盖重写”的负担，就是这么简单！ Lambda标准格式Lambda省去面向对象的条条框框，格式由3个部分组成： 一些参数 一个箭头 一段代码 Lambda表达式的标准格式为： (参数类型 参数名称) -&gt; { 代码语句 } 格式说明： 小括号内的语法与传统方法参数列表一致：无参数则留空；多个参数则用逗号分隔。 -&gt;是新引入的语法格式，代表指向动作。 大括号内的语法与传统方法体要求基本一致。 练习：使用Lambda标准格式（无参无返回）给定一个厨子Cook接口，内含唯一的抽象方法makeFood，且无参数、无返回值。如下： 123public interface Cook &#123; void makeFood();&#125; 在下面的代码中，请使用Lambda的标准格式调用invokeCook方法，打印输出“吃饭啦！”字样： 123456789public class Demo05InvokeCook &#123; public static void main(String[] args) &#123; // TODO 请在此使用Lambda【标准格式】调用invokeCook方法 &#125; private static void invokeCook(Cook cook) &#123; cook.makeFood(); &#125;&#125; 解答:12345public static void main(String[] args) &#123; invokeCook(() -&gt; &#123; System.out.println(&quot;吃饭啦！&quot;); &#125;);&#125; 备注：小括号代表Cook接口makeFood抽象方法的参数为空，大括号代表makeFood的方法体。 Lambda的参数和返回值 需求: 使用数组存储多个Person对象 对数组中的Person对象使用Arrays的sort方法通过年龄进行升序排序 下面举例演示java.util.Comparator接口的使用场景代码，其中的抽象方法定义为： public abstract int compare(T o1, T o2); 当需要对一个对象数组进行排序时，Arrays.sort方法需要一个Comparator接口实例来指定排序的规则。假设有一个Person类，含有String name和int age两个成员变量： 123456public class Person &#123; private String name; private int age; // 省略构造器、toString方法与Getter Setter &#125; 传统写法如果使用传统的代码对Person[]数组进行排序，写法如下：1234567891011121314151617181920212223242526import java.util.Arrays;import java.util.Comparator;public class Demo06Comparator &#123; public static void main(String[] args) &#123; // 本来年龄乱序的对象数组 Person[] array = &#123; new Person(&quot;古力娜扎&quot;, 19), new Person(&quot;迪丽热巴&quot;, 18), new Person(&quot;马尔扎哈&quot;, 20) &#125;; // 匿名内部类 Comparator&lt;Person&gt; comp = new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; return o1.getAge() - o2.getAge(); &#125; &#125;; Arrays.sort(array, comp); // 第二个参数为排序规则，即Comparator接口实例 for (Person person : array) &#123; System.out.println(person); &#125; &#125;&#125; 这种做法在面向对象的思想中，似乎也是“理所当然”的。其中Comparator接口的实例（使用了匿名内部类）代表了“按照年龄从小到大”的排序规则。 下面我们来搞清楚上述代码真正要做什么事情。 为了排序，Arrays.sort方法需要排序规则，即Comparator接口的实例，抽象方法compare是关键； 为了指定compare的方法体，不得不需要Comparator接口的实现类； 为了省去定义一个ComparatorImpl实现类的麻烦，不得不使用匿名内部类； 必须覆盖重写抽象compare方法，所以方法名称、方法参数、方法返回值不得不再写一遍，且不能写错； 实际上，只有参数和方法体才是关键。 Lambda写法12345678910111213141516171819import java.util.Arrays;public class Demo07ComparatorLambda &#123; public static void main(String[] args) &#123; Person[] array = &#123; new Person(&quot;古力娜扎&quot;, 19), new Person(&quot;迪丽热巴&quot;, 18), new Person(&quot;马尔扎哈&quot;, 20) &#125;; Arrays.sort(array, (Person a, Person b) -&gt; &#123; return a.getAge() - b.getAge(); &#125;); for (Person person : array) &#123; System.out.println(person); &#125; &#125;&#125; 使用Lambda标准格式（有参有返回）给定一个计算器Calculator接口，内含抽象方法calc可以将两个int数字相加得到和值： 123public interface Calculator &#123; int calc(int a, int b);&#125; 在下面的代码中，请使用Lambda的标准格式调用invokeCalc方法，完成120和130的相加计算：12345678910public class Demo08InvokeCalc &#123; public static void main(String[] args) &#123; // TODO 请在此使用Lambda【标准格式】调用invokeCalc方法来计算120+130的结果ß &#125; private static void invokeCalc(int a, int b, Calculator calculator) &#123; int result = calculator.calc(a, b); System.out.println(&quot;结果是：&quot; + result); &#125;&#125; 解答12345public static void main(String[] args) &#123; invokeCalc(120, 130, (int a, int b) -&gt; &#123; return a + b; &#125;);&#125; 备注：小括号代表Calculator接口calc抽象方法的参数，大括号代表calc的方法体。 Lambda省略格式可推导即可省略Lambda强调的是“做什么”而不是“怎么做”，所以凡是可以根据上下文推导得知的信息，都可以省略。例如上例还可以使用Lambda的省略写法： 123public static void main(String[] args) &#123; invokeCalc(120, 130, (a, b) -&gt; a + b);&#125; 省略规则 在Lambda标准格式的基础上，使用省略写法的规则为： 小括号内参数的类型可以省略； 如果小括号内有且仅有一个参，则小括号可以省略； 如果大括号内有且仅有一个语句，则无论是否有返回值，都可以省略大括号、return关键字及语句分号。 Lambda的使用前提Lambda的语法非常简洁，完全没有面向对象复杂的束缚。但是使用时有几个问题需要特别注意： 使用Lambda必须具有接口，且要求接口中有且仅有一个抽象方法。无论是JDK内置的Runnable、Comparator接口还是自定义的接口，只有当接口中的抽象方法存在且唯一时，才可以使用Lambda。 使用Lambda必须具有上下文推断。也就是方法的参数或局部变量类型必须为Lambda对应的接口类型，才能使用Lambda作为该接口的实例。 备注：有且仅有一个抽象方法的接口，称为“函数式接口”。]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2019%2F04%2F01%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程池思想概述我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题： 如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池。 线程池概念线程池：其实就是一个容纳多个线程的容器，其中的线程可以反复使用，省去了频繁创建线程对象的操作，无需反复创建线程而消耗过多资源 合理利用线程池能够带来三个好处： 降低资源消耗。减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。 线程池的使用Java里面线程池的顶级接口是java.util.concurrent.Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是java.util.concurrent.ExecutorService。 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在java.util.concurrent.Executors线程工厂类里面提供了一些静态工厂，生成一些常用的线程池。官方建议使用Executors工程类来创建线程池对象。 Executors类中有个创建线程池的方法如下： public static ExecutorService newFixedThreadPool(int nThreads)：返回线程池对象。(创建的是有界线程池,也就是池中的线程个数可以指定最大数量) 获取到了一个线程池ExecutorService 对象，那么怎么使用呢，在这里定义了一个使用线程池对象的方法如下： public Future&lt;?&gt; submit(Runnable task):获取线程池中的某一个线程对象，并执行 Future接口：用来记录线程任务执行完毕后产生的结果。线程池创建与使用。 使用线程池中线程对象的步骤： 创建线程池对象。 创建Runnable接口子类对象。(task) 提交Runnable接口子类对象。(take task) 关闭线程池(一般不做)。 Runnable实现类代码：1234567891011121314public class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;我要一个教练&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;教练来了： &quot; + Thread.currentThread().getName()); System.out.println(&quot;教我游泳,交完后，教练回到了游泳池&quot;); &#125;&#125; 线程池测试类: 1234567891011121314151617181920212223public class ThreadPoolDemo &#123; public static void main(String[] args) &#123; // 创建线程池对象 ExecutorService service = Executors.newFixedThreadPool(2);//包含2个线程对象 // 创建Runnable实例对象 MyRunnable r = new MyRunnable(); //自己创建线程对象的方式 // Thread t = new Thread(r); // t.start(); ---&gt; 调用MyRunnable中的run() // 从线程池中获取线程对象,然后调用MyRunnable中的run() service.submit(r); // 再获取个线程对象，调用MyRunnable中的run() service.submit(r); service.submit(r); // 注意：submit方法调用结束后，程序并不终止，是因为线程池控制了线程的关闭。 // 将使用完的线程又归还到了线程池中 // 关闭线程池 //service.shutdown(); &#125;&#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[等待唤醒机制]]></title>
    <url>%2F2019%2F04%2F01%2F%E7%AD%89%E5%BE%85%E5%94%A4%E9%86%92%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[线程间通信概念：多个线程在处理同一个资源，但是处理的动作（线程的任务）却不相同。 比如：线程A用来生成包子的，线程B用来吃包子的，包子可以理解为同一资源，线程A与线程B处理的动作，一个是生产，一个是消费，那么线程A与线程B之间就存在线程通信问题。 为什么要处理线程间通信：多个线程并发执行时, 在默认情况下CPU是随机切换线程的，当我们需要多个线程来共同完成一件任务，并且我们希望他们有规律的执行, 那么多线程之间需要一些协调通信，以此来帮我们达到多线程共同操作一份数据。 如何保证线程间通信有效利用资源：多个线程在处理同一个资源，并且任务不同时，需要线程通信来帮助解决线程之间对同一个变量的使用或操作。 就是多个线程在操作同一份数据时， 避免对同一共享变量的争夺。也就是我们需要通过一定的手段使各个线程能有效的利用资源。而这种手段即—— 等待唤醒机制。 什么是等待唤醒机制这是多个线程间的一种协作机制。谈到线程我们经常想到的是线程间的竞争（race），比如去争夺锁，但这并不是故事的全部，线程间也会有协作机制。就好比在公司里你和你的同事们，你们可能存在在晋升时的竞争，但更多时候你们更多是一起合作以完成某些任务。 就是在一个线程进行了规定操作后，就进入等待状态（wait()）， 等待其他线程执行完他们的指定代码过后 再将其唤醒（notify()）;在有多个线程进行等待时， 如果需要，可以使用 notifyAll()来唤醒所有的等待线程。 wait/notify 就是线程间的一种协作机制。 等待唤醒中的方法 等待唤醒机制就是用于解决线程间通信的问题的，使用到的3个方法的含义如下： wait：线程不再活动，不再参与调度，进入 wait set 中，因此不会浪费 CPU 资源，也不会去竞争锁了，这时的线程状态即是 WAITING。它还要等着别的线程执行一个特别的动作，也即是“通知（notify）”在这个对象上等待的线程从wait set 中释放出来，重新进入到调度队列（ready queue）中 notify：则选取所通知对象的 wait set 中的一个线程释放；例如，餐馆有空位置后，等候就餐最久的顾客最先入座。 notifyAll：则释放所通知对象的 wait set 上的全部线程。 注意：哪怕只通知了一个等待的线程，被通知线程也不能立即恢复执行，因为它当初中断的地方是在同步块内，而此刻它已经不持有锁，所以她需要再次尝试去获取锁（很可能面临其它线程的竞争），成功后才能在当初调用 wait 方法之后的地方恢复执行。总结如下：如果能获取锁，线程就从 WAITING 状态变成 RUNNABLE 状态；否则，从 wait set 出来，又进入 entry set，线程就从 WAITING 状态又变成 BLOCKED 状态 调用wait和notify方法需要注意的细节 wait方法与notify方法必须要由同一个锁对象调用。因为：对应的锁对象可以通过notify唤醒使用同一个锁对象调用的wait方法后的线程。 wait方法与notify方法是属于Object类的方法的。因为：锁对象可以是任意对象，而任意对象的所属类都是继承了Object类的。 wait方法与notify方法必须要在同步代码块或者是同步函数中使用。因为：必须要通过锁对象调用这2个方法。 生产者与消费者问题等待唤醒机制其实就是经典的“生产者与消费者”的问题。 就拿生产包子消费包子来说等待唤醒机制如何有效利用资源： 包子铺线程生产包子，吃货线程消费包子。当包子没有时（包子状态为false），吃货线程等待，包子铺线程生产包子（即包子状态为true），并通知吃货线程（解除吃货的等待状态）,因为已经有包子了，那么包子铺线程进入等待状态。接下来，吃货线程能否进一步执行则取决于锁的获取情况。如果吃货获取到锁，那么就执行吃包子动作，包子吃完（包子状态为false），并通知包子铺线程（解除包子铺的等待状态）,吃货线程进入等待。包子铺线程能否进一步执行则取决于锁的获取情况。 包子资源类: 12345public class BaoZi &#123; String pier ; String xianer ; boolean flag = false ;//包子资源 是否存在 包子资源状态&#125; 吃货线程类:1234567891011121314151617181920212223242526public class ChiHuo extends Thread&#123; private BaoZi bz; public ChiHuo(String name,BaoZi bz)&#123; super(name); this.bz = bz; &#125; @Override public void run() &#123; while(true)&#123; synchronized (bz)&#123; if(bz.flag == false)&#123;//没包子 try &#123; bz.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;吃货正在吃&quot;+bz.pier+bz.xianer+&quot;包子&quot;); bz.flag = false; bz.notify(); &#125; &#125; &#125;&#125; 包子铺线程类: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class BaoZiPu extends Thread &#123; private BaoZi bz; public BaoZiPu(String name,BaoZi bz)&#123; super(name); this.bz = bz; &#125; @Override public void run() &#123; int count = 0; //造包子 while(true)&#123; //同步 synchronized (bz)&#123; if(bz.flag == true)&#123;//包子资源 存在 try &#123; bz.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 没有包子 造包子 System.out.println(&quot;包子铺开始做包子&quot;); if(count%2 == 0)&#123; // 冰皮 五仁 bz.pier = &quot;冰皮&quot;; bz.xianer = &quot;五仁&quot;; &#125;else&#123; // 薄皮 牛肉大葱 bz.pier = &quot;薄皮&quot;; bz.xianer = &quot;牛肉大葱&quot;; &#125; count++; bz.flag=true; System.out.println(&quot;包子造好了：&quot;+bz.pier+bz.xianer); System.out.println(&quot;吃货来吃吧&quot;); //唤醒等待线程 （吃货） bz.notify(); &#125; &#125; &#125;&#125; 测试类: 12345678910111213public class Demo &#123; public static void main(String[] args) &#123; //等待唤醒案例 BaoZi bz = new BaoZi(); ChiHuo ch = new ChiHuo(&quot;吃货&quot;,bz); BaoZiPu bzp = new BaoZiPu(&quot;包子铺&quot;,bz); ch.start(); bzp.start(); &#125;&#125; 执行效果: 12345678910111213包子铺开始做包子包子造好了：冰皮五仁吃货来吃吧吃货正在吃冰皮五仁包子包子铺开始做包子包子造好了：薄皮牛肉大葱吃货来吃吧吃货正在吃薄皮牛肉大葱包子包子铺开始做包子包子造好了：冰皮五仁吃货来吃吧吃货正在吃冰皮五仁包子]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全]]></title>
    <url>%2F2019%2F04%2F01%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[如果有多个线程在同时运行，而这些线程可能会同时运行这段代码。程序每次运行结果和单线程运行的结果是一样 的，而且其他的变量的值也和预期的是一样的，就是线程安全的。我们通过一个案例，演示线程的安全问题：电影院要卖票，我们模拟电影院的卖票过程。假设要播放的电影是 “葫芦娃大战奥特曼”，本次电影的座位共100个 (本场电影只能卖100张票)。 我们来模拟电影院的售票窗口，实现多个窗口同时卖 “葫芦娃大战奥特曼”这场电影票(多个窗口一起卖这100张票) 需要窗口，采用线程对象来模拟；需要票，Runnable接口子类来模拟 123456789101112131415161718192021222324252627 public class Ticket implements Runnable &#123; private int ticket = 100; /* *执行卖票操作 */ @Override public void run() &#123; //每个窗口卖票的操作 //窗口 永远开启 while (true) &#123; if (ticket &gt; 0) &#123; //有票 可以卖 //出票操作 //使用sleep模拟一下出票时间 try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; // TODO Auto‐generated catch block e.printStackTrace(); &#125; //获取当前线程对象的名字 String name = Thread.currentThread().getName(); System.out.println(name + &quot;正在卖:&quot; + ticket‐‐); &#125; &#125; &#125;&#125; 测试类：123456789101112131415public class Demo &#123; public static void main(String[] args) &#123; //创建线程任务对象 Ticket ticket = new Ticket(); //创建三个窗口对象 Thread t1 = new Thread(ticket, &quot;窗口1&quot;); Thread t2 = new Thread(ticket, &quot;窗口2&quot;); Thread t3 = new Thread(ticket, &quot;窗口3&quot;); //同时卖票 t1.start(); t2.start(); t3.start(); &#125; &#125; 线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写 操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步， 否则的话就可能影响线程安全。 线程同步当我们使用多个线程访问同一资源的时候，且多个线程中对资源有写的操作，就容易出现线程安全问题。要解决上述多线程并发访问一个资源的安全性问题:也就是解决重复票与不存在票问题，Java中提供了同步机制 (synchronized)来解决。 为了保证每个线程都能正常执行原子操作,Java引入了线程同步机制。那么怎么去使用呢？有三种方式完成同步操作： 同步代码块。 同步方法。 锁机制。 同步代码块同步代码块： synchronized 关键字可以用于方法中的某个区块中，表示只对这个区块的资源实行互斥访问。格式: 123synchronized(同步锁)&#123; 需要同步操作的代码&#125; 同步锁:对象的同步锁只是一个概念,可以想象为在对象上标记了一个锁. 1. 锁对象 可以是任意类型。 2. 多个线程对象 要使用同一把锁。 注意:在任何时候,最多允许一个线程拥有同步锁,谁拿到锁就进入代码块,其他的线程只能在外等着使用同步代码块解决代码123456789101112131415161718192021222324252627282930public class Ticket implements Runnable&#123; private int ticket = 100; /* * 执行卖票操作 */ @Override public void run() &#123; //每个窗口卖票的操作 //窗口 永远开启 while(true)&#123; synchronized (this) &#123; if(ticket&gt;0)&#123; //有票 可以卖 //出票操作 //使用sleep模拟一下出票时间 try &#123; Thread.sleep(50); &#125; catch (InterruptedException e) &#123; // TODO Auto‐generated catch block e.printStackTrace(); &#125; //获取当前线程对象的名字 String name = Thread.currentThread().getName(); System.out.println(name+&quot;正在卖:&quot;+ticket‐‐); &#125; &#125; &#125; &#125;&#125; 当使用了同步代码块后，线程的安全问题，解决了 同步方法同步方法:使用synchronized修饰的方法,就叫做同步方法,保证A线程执行该方法的时候,其他线程只能在方法外 等着 格式：123public synchronized void run() &#123;&#125; 同步锁是谁?对于非static方法,同步锁就是this。对于static方法,我们使用当前方法所在类的字节码对象(类名.class)。 Lock锁java.util.concurrent.locks.Lock 机制提供了比synchronized代码块和synchronized方法更广泛的锁定操作, 同步代码块/同步方法具有的功能Lock都有,除此之外更强大,更体现面向对象。Lock锁也称同步锁，加锁与释放锁方法化了，如下： - public void lock() :加同步锁。 - public void unlock() :释放同步锁。 public class Ticket implements Runnable{ private int ticket = 100; Lock l = new ReentrantLock(); @Override public void run() { while (true){ //判断票是否存在 l.lock(); try { if(tickt&gt;0){ System.out.println(Thread.currentThread().getName()+&quot;正在买第&quot;+tickt+&quot;张票&quot;); tickt--; } } catch (Exception e) { e.printStackTrace(); }finally { l.unlock(); } } } }]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2F2019%2F04%2F01%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[我们在之前，学习的程序在没有跳转语句的前提下，都是由上至下依次执行，那现在想要设计一个程序，边打游戏边听歌，怎么设计？ 要解决上述问题,咱们得使用多进程或者多线程来解决. 并发与并行 并发：指两个或多个事件在同一个时间段内发生。 并行：指两个或多个事件在同一时刻发生（同时发生）。 在操作系统中，安装了多个程序，并发指的是在一段时间内宏观上有多个程序同时运行，这在单 CPU 系统中，每一时刻只能有一道程序执行，即微观上这些程序是分时的交替运行，只不过是给人的感觉是同时运行，那是因为分时交替运行的时间是非常短的。 而在多个 CPU 系统中，则这些可以并发执行的程序便可以分配到多个处理器上（CPU），实现多任务并行执行，即利用每个处理器来处理一个可以并发执行的程序，这样多个程序便可以同时执行。目前电脑市场上说的多核 CPU，便是多核处理器，核 越多，并行处理的程序越多，能大大的提高电脑运行的效率。 注意：单核处理器的计算机肯定是不能并行的处理多个任务的，只能是多个任务在单个CPU上并发运行。同理,线程也是一样的，从宏观角度上理解线程是并行运行的，但是从微观角度上分析却是串行运行的，即一个线程一个线程的去运行，当系统只有一个CPU时，线程会以某种顺序执行多个线程，我们把这种情况称之为线程调度。 线程与进程进程：是指一个内存中运行的应用程序，每个进程都有一个独立的内存空间，一个应用程序可以同时运行多个进程；进程也是程序的一次执行过程，是系统运行程序的基本单位；系统运行一个程序即是一个进程从创建、运行到消亡的过程。线程：线程是进程中的一个执行单元，负责当前进程中程序的执行，一个进程中至少有一个线程。一个进程中是可以有多个线程的，这个应用程序也可以称之为多线程程序。 简而言之：一个程序运行后至少有一个进程，一个进程中可以包含多个线程 线程调度: 分时调度所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间。 抢占式调度优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个(线程随机性)，Java使用的为抢占式调度。 设置线程的优先级 抢占式调度详解 大部分操作系统都支持多进程并发运行，现在的操作系统几乎都支持同时运行多个程序。比如：现在我们上课一边使用编辑器，一边使用录屏软件，同时还开着画图板，dos窗口等软件。此时，这些程序是在同时运行，”感觉这些软件好像在同一时刻运行着“。 实际上，CPU(中央处理器)使用抢占式调度模式在多个线程间进行着高速的切换。对于CPU的一个核而言，某个时刻，只能执行一个线程，而 CPU的在多个线程间切换速度相对我们的感觉要快，看上去就是在同一时刻运行。 其实，多线程程序并不能提高程序的运行速度，但能够提高程序运行效率，让CPU的使用率更高。 创建线程类一Java使用java.lang.Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。每个线程的作用是完成一定的任务，实际上就是执行一段程序流即一段顺序执行的代码。Java使用线程执行体来代表这段程序流。Java中通过继承Thread类来创建并启动多线程的步骤如下： 定义Thread类的子类，并重写该类的run()方法，该run()方法的方法体就代表了线程需要完成的任务,因此把run()方法称为线程执行体。 创建Thread子类的实例，即创建了线程对象 调用线程对象的start()方法来启动该线程 自定义线程类 1234567891011121314151617public class MyThread extends Thread &#123;//定义指定线程名称的构造方法 public MyThread(String name) &#123; //调用父类的String参数的构造方法，指定线程的名称 super(name); &#125; /** * 重写run方法，完成该线程执行的逻辑 */ @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(getName()+&quot;：正在执行！&quot;+i); &#125; &#125;&#125; 测试类123456789101112public class Demo01 &#123; public static void main(String[] args) &#123; //创建自定义线程对象 MyThread mt = new MyThread(&quot;新的线程！&quot;); //开启新线程 mt.start(); //在主方法中执行for循环 for (int i = 0; i &lt; 10; i++) &#123; System.out.println(&quot;main线程！&quot;+i); &#125; &#125;&#125; 程序启动运行main时候，java虚拟机启动一个进程，主线程main在main()调用时候被创建。随着调用mt的对象的 start方法，另外一个新的线程也启动了，这样，整个应用就在多线程下运行。通过这张图我们可以很清晰的看到多线程的执行流程，那么为什么可以完成并发执行呢？我们再来讲一讲原理。多线程执行时，到底在内存中是如何运行的呢？以上个程序为例，进行图解说明：多线程执行时，在栈内存中，其实每一个执行线程都有一片自己所属的栈内存空间。进行方法的压栈和弹栈。 当执行线程的任务结束了，线程自动在栈内存中释放了。但是当所有的执行线程都结束了，那么进程就结束了 Thread类java.lang.Thread 类， API中该类中定义了有关线程的一些方法，具体如下： public Thread() :分配一个新的线程对象。 public Thread(String name) :分配一个指定名字的新的线程对象。public Thread(Runnable target) :分配一个带有指定目标新的线程对象。public Thread(Runnable target,String name) :分配一个带有指定目标新的线程对象并指定名字。常用方法：public String getName() :获取当前线程名称。public void start() :导致此线程开始执行; Java虚拟机调用此线程的run方法。public void run() :此线程要执行的任务在此处定义代码。public static void sleep(long millis) :使当前正在执行的线程以指定的毫秒数暂停（暂时停止执行）。public static Thread currentThread() :返回对当前正在执行的线程对象的引用。翻阅API后得知创建线程的方式总共有两种，一种是继承Thread类方式，一种是实现Runnable接口方式，方式一已经完成，接下来讲解方式二实现的方式。 创建线程方式二采用 java.lang.Runnable 也是非常常见的一种，我们只需要重写run方法即可。步骤如下： 定义Runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。 2. 创建Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正 的线程对象。 3. 调用线程对象的start()方法来启动线程。12345678910111213141516171819202122232425 public class MyRunnable implements Runnable&#123; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; System.out.println(Thread.currentThread().getName()+&quot; &quot;+i); &#125; &#125; &#125;public class Demo &#123; public static void main(String[] args) &#123; //创建自定义类对象 线程任务对象 MyRunnable mr = new MyRunnable(); //创建线程对象 Thread t = new Thread(mr, &quot;小强&quot;); t.start(); for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;旺财 &quot; + i); &#125; &#125; 通过实现Runnable接口，使得该类有了多线程类的特征。run()方法是多线程程序的一个执行目标。所有的多线程 代码都在run方法里面。Thread类实际上也是实现了Runnable接口的类。 在启动的多线程的时候，需要先通过Thread类的构造方法Thread(Runnable target) 构造出对象，然后调用Thread 对象的start()方法来运行多线程代码。实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是继承Thread类还是实现 Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的，熟悉Thread类的API是进行多线程 编程的基础。 tips:Runnable对象仅仅作为Thread对象的target，Runnable实现类里包含的run()方法仅作为线程执行体。 而实际的线程对象依然是Thread实例，只是该Thread线程负责执行其target的run()方法。 Thread和Runnable的区别如果一个类继承Thread，则不适合资源共享。但是如果实现了Runable接口的话，则很容易的实现资源共享总结：实现Runnable接口比继承Thread类所具有的优势： 适合多个相同的程序代码的线程去共享同一个资源。 可以避免java中的单继承的局限性。 增加程序的健壮性，实现解耦操作，代码可以被多个线程共享，代码和线程独立。 线程池只能放入实现Runable或Callable类线程，不能直接放入继承Thread的类 扩充：在java中，每次程序运行至少启动2个线程。一个是main线程，一个是垃圾收集线程。因为每当使用 java命令执行一个类的时候，实际上都会启动一个JVM，每一个JVM其实在就是在操作系统中启动了一个进程。 匿名内部类方式实现线程的创建使用线程的内匿名内部类方式，可以方便的实现每个线程执行不同的线程任务操作。使用匿名内部类的方式实现Runnable接口，重新Runnable接口中的run方法 123456789101112131415161718192021222324 public class NoNameInnerClassThread &#123; public static void main(String[] args) &#123; // new Runnable()&#123; // public void run()&#123; // for (int i = 0; i &lt; 20; i++) &#123; // System.out.println(&quot;张宇:&quot;+i); // &#125; // &#125; // &#125;; //‐‐‐这个整体 相当于new MyRunnable() Runnable r = new Runnable()&#123; public void run()&#123; for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;张宇:&quot;+i); &#125; &#125; &#125;; new Thread(r).start(); for (int i = 0; i &lt; 20; i++) &#123; System.out.println(&quot;费玉清:&quot;+i); &#125; &#125; &#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义异常]]></title>
    <url>%2F2019%2F04%2F01%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[为什么需要自定义异常类: 我们说了Java中不同的异常类,分别表示着某一种具体的异常情况,那么在开发中总是有些异常情况是SUN没有定义好的,此时我们根据自己业务的异常情况来定义异常类。例如年龄负数问题,考试成绩负数问题等等。 在上述代码中，发现这些异常都是JDK内部定义好的，但是实际开发中也会出现很多异常,这些异常很可能在JDK中没有定义过,例如年龄负数问题,考试成绩负数问题.那么能不能自己定义异常呢？ 什么是自定义异常类: 在开发中根据自己业务的异常情况来定义异常类. 自定义一个业务逻辑异常: RegisterException。一个注册异常类。 异常类如何定义: 自定义一个编译期异常: 自定义类 并继承于java.lang.Exception。 自定义一个运行时期的异常类:自定义类 并继承于java.lang.RuntimeException。 自定义异常的练习要求：我们模拟注册操作，如果用户名已存在，则抛出异常并提示：亲，该用户名已经被注册。 首先定义一个登陆异常类RegisterException：1234567891011121314151617// 业务逻辑异常public class RegisterException extends Exception &#123; /** * 空参构造 */ public RegisterException() &#123; &#125; /** * * @param message 表示异常提示 */ public RegisterException(String message) &#123; super(message); &#125;&#125; 模拟登陆操作，使用数组模拟数据库中存储的数据，并提供当前注册账号是否存在方法用于判断。 12345678910111213141516171819202122232425262728public class Demo &#123; // 模拟数据库中已存在账号 private static String[] names = &#123;&quot;bill&quot;,&quot;hill&quot;,&quot;jill&quot;&#125;; public static void main(String[] args) &#123; //调用方法 try&#123; // 可能出现异常的代码 checkUsername(&quot;nill&quot;); System.out.println(&quot;注册成功&quot;);//如果没有异常就是注册成功 &#125;catch(RegisterException e)&#123; //处理异常 e.printStackTrace(); &#125; &#125; //判断当前注册账号是否存在 //因为是编译期异常，又想调用者去处理 所以声明该异常 public static boolean checkUsername(String uname) throws LoginException&#123; for (String name : names) &#123; if(name.equals(uname))&#123;//如果名字在这里面 就抛出登陆异常 throw new RegisterException(&quot;亲&quot;+name+&quot;已经被注册了！&quot;); &#125; &#125; return true; &#125;&#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常的处理]]></title>
    <url>%2F2019%2F04%2F01%2F%E5%BC%82%E5%B8%B8%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[Java异常处理的五个关键字：try、catch、finally、throw、throws 抛出异常throw在编写程序时，我们必须要考虑程序出现问题的情况。比如，在定义方法时，方法需要接受参数。那么，当调用方法使用接受到的参数时，首先需要先对参数数据进行合法的判断，数据若不合法，就应该告诉调用者，传递合法的数据进来。这时需要使用抛出异常的方式来告诉调用者。 在java中，提供了一个throw关键字，它用来抛出一个指定的异常对象。那么，抛出一个异常具体如何操作呢？ 创建一个异常对象。封装一些提示信息(信息可以自己编写)。 需要将这个异常对象告知给调用者。怎么告知呢？怎么将这个异常对象传递到调用者处呢？通过关键字throw就可以完成。throw 异常对象。throw用在方法内，用来抛出一个异常对象，将这个异常对象传递到调用者处，并结束当前方法的执行。 使用格式： throw new 异常类名(参数); 例如： throw new NullPointerException(“要访问的arr数组不存在”); throw new ArrayIndexOutOfBoundsException(“该索引在数组中不存在，已超出范围”); 学习完抛出异常的格式后，我们通过下面程序演示下throw的使用。12345678910111213141516171819202122232425262728public class ThrowDemo &#123; public static void main(String[] args) &#123; //创建一个数组 int[] arr = &#123;2,4,52,2&#125;; //根据索引找对应的元素 int index = 4; int element = getElement(arr, index); System.out.println(element); System.out.println(&quot;over&quot;); &#125; /* * 根据 索引找到数组中对应的元素 */ public static int getElement(int[] arr,int index)&#123; //判断 索引是否越界 if(index&lt;0 || index&gt;arr.length-1)&#123; /* 判断条件如果满足，当执行完throw抛出异常对象后，方法已经无法继续运算。 这时就会结束当前方法的执行，并将异常告知给调用者。这时就需要通过异常来解决。 */ throw new ArrayIndexOutOfBoundsException(&quot;哥们，角标越界了~~~&quot;); &#125; int element = arr[index]; return element; &#125;&#125; 注意：如果产生了问题，我们就会throw将问题描述类即异常进行抛出，也就是将问题返回给该方法的调用者。 那么对于调用者来说，该怎么处理呢？一种是进行捕获处理，另一种就是继续讲问题声明出去，使用throws声明处理。 Objects非空判断还记得我们学习过一个类Objects吗，曾经提到过它由一些静态的实用方法组成，这些方法是null-save（空指针安全的）或null-tolerant（容忍空指针的），那么在它的源码中，对对象为null的值进行了抛出异常操作。 public static T requireNonNull(T obj):查看指定引用对象不是null。 查看源码发现这里对为null的进行了抛出异常操作：12345678910111213public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj; //简化写法 Objects.requireNonNull(parse); //或者 Objects.requireNonNull(parse,&quot;进行合法性判断&quot;); &#125; 声明异常throws声明异常：将问题标识出来，报告给调用者。如果方法内通过throw抛出了编译时异常，而没有捕获处理（稍后讲解该方式），那么必须通过throws进行声明，让调用者去处理。 关键字throws运用于方法声明之上,用于表示当前方法不处理异常,而是提醒该方法的调用者来处理异常(抛出异常). 声明异常格式： 修饰符 返回值类型 方法名(参数) throws 异常类名1,异常类名2…{ } 声明异常的代码演示：12345678910111213public class ThrowsDemo &#123; public static void main(String[] args) throws FileNotFoundException &#123; read(&quot;a.txt&quot;); &#125; // 如果定义功能时有问题发生需要报告给调用者。可以通过在方法上使用throws关键字进行声明 public static void read(String path) throws FileNotFoundException &#123; if (!path.equals(&quot;a.txt&quot;)) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException(&quot;文件不存在&quot;); &#125; &#125;&#125; throws用于进行异常类的声明，若该方法可能有多种异常情况产生，那么在throws后面可以写多个异常类，用逗号隔开。 12345678910111213141516public class ThrowsDemo2 &#123; public static void main(String[] args) throws IOException &#123; read(&quot;a.txt&quot;); &#125; public static void read(String path)throws FileNotFoundException, IOException &#123; if (!path.equals(&quot;a.txt&quot;)) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException(&quot;文件不存在&quot;); &#125; if (!path.equals(&quot;b.txt&quot;)) &#123; throw new IOException(); &#125; &#125;&#125; 捕获异常try…catch如果异常出现的话,会立刻终止程序,所以我们得处理异常: 该方法不处理,而是声明抛出,由该方法的调用者来处理(throws)。 在方法中使用try-catch的语句块来处理异常。 try-catch的方式就是捕获异常。 捕获异常：Java中对异常有针对性的语句进行捕获，可以对出现的异常进行指定方式的处理。 捕获异常语法如下：123456try&#123; 编写可能会出现异常的代码&#125;catch(异常类型 e)&#123; 处理异常的代码 //记录日志/打印异常信息/继续抛出异常&#125; try：该代码块中编写可能产生异常的代码。 catch：用来进行某种异常的捕获，实现对捕获到的异常进行处理。 注意:try和catch都不能单独使用,必须连用。 演示如下： 123456789101112131415161718192021public class TryCatchDemo &#123; public static void main(String[] args) &#123; try &#123;// 当产生异常时，必须有处理方式。要么捕获，要么声明。 read(&quot;b.txt&quot;); &#125; catch (FileNotFoundException e) &#123;// 括号中需要定义什么呢？ //try中抛出的是什么异常，在括号中就定义什么异常类型 System.out.println(e); &#125; System.out.println(&quot;over&quot;); &#125; /* * * 我们 当前的这个方法中 有异常 有编译期异常 */ public static void read(String path) throws FileNotFoundException &#123; if (!path.equals(&quot;a.txt&quot;)) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException(&quot;文件不存在&quot;); &#125; &#125;&#125; 如何获取异常信息： Throwable类中定义了一些查看方法: public String getMessage():获取异常的描述信息,原因(提示给用户的时候,就提示错误原因。 public String toString():获取异常的类型和异常描述信息(不用)。 public void printStackTrace():打印异常的跟踪栈信息并输出到控制台。 包含了异常的类型,异常的原因,还包括异常出现的位置,在开发和调试阶段,都得使用printStackTrace。 finally 代码块finally：有一些特定的代码无论异常是否发生，都需要执行。另外，因为异常会引发程序跳转，导致有些语句执行不到。而finally就是解决这个问题的，在finally代码块中存放的代码都是一定会被执行的。 什么时候的代码必须最终执行？ 当我们在try语句块中打开了一些物理资源(磁盘文件/网络连接/数据库连接等),我们都得在使用完之后,最终关闭打开的资源。 finally的语法: try…catch….finally:自身需要处理异常,最终还得关闭资源。 注意:finally不能单独使用。比如在我们之后学习的IO流中，当打开了一个关联文件的资源，最后程序不管结果如何，都需要把这个资源关闭掉。 finally代码参考如下： 123456789101112131415161718192021222324public class TryCatchDemo4 &#123; public static void main(String[] args) &#123; try &#123; read(&quot;a.txt&quot;); &#125; catch (FileNotFoundException e) &#123; //抓取到的是编译期异常 抛出去的是运行期 throw new RuntimeException(e); &#125; finally &#123; System.out.println(&quot;不管程序怎样，这里都将会被执行。&quot;); &#125; System.out.println(&quot;over&quot;); &#125; /* * * 我们 当前的这个方法中 有异常 有编译期异常 */ public static void read(String path) throws FileNotFoundException &#123; if (!path.equals(&quot;a.txt&quot;)) &#123;//如果不是 a.txt这个文件 // 我假设 如果不是 a.txt 认为 该文件不存在 是一个错误 也就是异常 throw throw new FileNotFoundException(&quot;文件不存在&quot;); &#125; &#125;&#125; 当只有在try或者catch中调用退出JVM的相关方法,此时finally才不会执行,否则finally永远会执行。 异常注意事项多个异常使用捕获又该如何处理呢？ 多个异常分别处理。 多个异常一次捕获，多次处理。 多个异常一次捕获一次处理。 一般我们是使用一次捕获多次处理方式，格式如下：12345678910try&#123; 编写可能会出现异常的代码&#125;catch(异常类型A e)&#123; 当try中出现A类型异常,就用该catch来捕获. 处理异常的代码 //记录日志/打印异常信息/继续抛出异常&#125;catch(异常类型B e)&#123; 当try中出现B类型异常,就用该catch来捕获. 处理异常的代码 //记录日志/打印异常信息/继续抛出异常&#125; 注意:这种异常处理方式，要求多个catch中的异常不能相同，并且若catch中的多个异常之间有子父类异常的关系，那么子类异常要求在上面的catch处理，父类异常在下面的catch处理。 运行时异常被抛出可以不处理。即不捕获也不声明抛出。 如果finally有return语句,永远返回finally中的结果,避免该情况. 如果父类抛出了多个异常,子类重写父类方法时,抛出和父类相同的异常或者是父类异常的子类或者不抛出异常。 父类方法没有抛出异常，子类重写父类该方法时也不可抛出异常。此时子类产生该异常，只能捕获处理，不能声明抛出]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常]]></title>
    <url>%2F2019%2F04%2F01%2F%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[异常概念异常，就是不正常的意思。在生活中:医生说,你的身体某个部位有异常,该部位和正常相比有点不同,该部位的功能将受影响.在程序中的意思就是：异常 ：指的是程序在执行过程中，出现的非正常的情况，最终会导致JVM的非正常停止。在Java等面向对象的编程语言中，异常本身是一个类，产生异常就是创建异常对象并抛出了一个异常对象。Java处理异常的方式是中断处理。 异常指的并不是语法错误,语法错了,编译不通过,不会产生字节码文件,根本不能运行. 异常体系异常机制其实是帮助我们找到程序中的问题，异常的根类是java.lang.Throwable，其下有两个子类：java.lang.Error与java.lang.Exception，平常所说的异常指java.lang.Exception。 Throwable体系： Error:严重错误Error，无法通过处理的错误，只能事先避免，好比绝症。 Exception:表示异常，异常产生后程序员可以通过代码的方式纠正，使程序继续运行，是必须要处理的。好比感冒、阑尾炎。 Throwable中的常用方法： public void printStackTrace():打印异常的详细信息。包含了异常的类型,异常的原因,还包括异常出现的位置,在开发和调试阶段,都得使用printStackTrace。 public String getMessage():获取发生异常的原因。提示给用户的时候,就提示错误原因。 public String toString():获取异常的类型和异常描述信息(不用)。 出现异常,不要紧张,把异常的简单类名,拷贝到API中去查。 异常分类我们平常说的异常就是指Exception，因为这类异常一旦出现，我们就要对代码进行更正，修复程序。 异常(Exception)的分类:根据在编译时期还是运行时期去检查异常? 编译时期异常:checked异常。在编译时期,就会检查,如果没有处理异常,则编译失败。(如日期格式化异常) 运行时期异常:runtime异常。在运行时期,检查异常.在编译时期,运行异常不会编译器检测(不报错)。(如数学异常) 异常的产生过程解析先运行下面的程序，程序会产生一个数组索引越界异常ArrayIndexOfBoundsException。我们通过图解来解析下异常产生的过程。1234567public class ArrayTools &#123; // 对给定的数组通过给定的角标获取元素。 public static int getElement(int[] arr, int index) &#123; int element = arr[index]; return element; &#125;&#125; 12345678public class ExceptionDemo &#123; public static void main(String[] args) &#123; int[] arr = &#123; 34, 12, 67 &#125;; intnum = ArrayTools.getElement(arr, 4) System.out.println(&quot;num=&quot; + num); System.out.println(&quot;over&quot;); &#125;&#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pegehelper-分页助手]]></title>
    <url>%2F2019%2F03%2F29%2Fpegehelper-%E5%88%86%E9%A1%B5%E5%8A%A9%E6%89%8B%2F</url>
    <content type="text"><![CDATA[分页助手 POM配置12345678&lt;!-- 分页助手 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;4.1.6&lt;/version&gt;&lt;/dependency&gt; 这次直接是在项目的入口类application.java中直接设置PageHelper插件即可 123456789101112//配置mybatis的分页插件pageHelper @Bean public PageHelper pageHelper()&#123; PageHelper pageHelper = new PageHelper(); Properties properties = new Properties(); properties.setProperty(&quot;offsetAsPageNum&quot;,&quot;true&quot;); properties.setProperty(&quot;rowBoundsWithCount&quot;,&quot;true&quot;); properties.setProperty(&quot;reasonable&quot;,&quot;true&quot;); properties.setProperty(&quot;dialect&quot;,&quot;mysql&quot;); //配置mysql数据库的方言 pageHelper.setProperties(properties); return pageHelper; &#125; 在springBoot项目中 POM配置 12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; 使用用法12345678910111213141516171819202122// 先创建一个实体工具类 来保存分页数据@Datapublic class PageResult&lt;T&gt; &#123; private Long total; //总条数 private Integer totalPage;//总页数 private List&lt;T&gt; items; //当前分页数据 public PageResult() &#123; &#125; public PageResult(Long total, List&lt;T&gt; items) &#123; this.total = total; this.items = items; &#125; public PageResult(Long total, Integer totalPage, List&lt;T&gt; items) &#123; this.total = total; this.totalPage = totalPage; this.items = items; &#125;&#125; 使用一个案例方法讲述分页用法 123456789101112131415161718192021222324252627282930313233343536373839@Autowired private BrandMapper brandMapper; page 当前页 rows 每页大小 sortBy 排序字段 desc 是否降序 key 搜索条件 public PageResult&lt;Brand&gt; QueryBrandByPage(Integer page, Integer rows, String sortBy, Boolean desc, String key) &#123; //分页 通过分页插件 PageHelper.startPage(page,rows); //过滤 Example example = new Example(Brand.class); if(StringUtils.isNotBlank(key))&#123; //过滤条件 example.createCriteria().orLike(&quot;name&quot;,&quot;%&quot;+key+&quot;%&quot;).orEqualTo(&quot;letter&quot;,key.toUpperCase()); &#125; //排序 if(StringUtils.isNoneBlank(sortBy))&#123; String orederByClauce = sortBy+(desc ? &quot; DESC&quot;:&quot; ASC&quot; ); example.setOrderByClause(orederByClauce); &#125; //查询 List&lt;Brand&gt; brands = brandMapper.selectByExample(example); if(CollectionUtils.isEmpty(brands))&#123; throw new LyException(ExceptionEnums.BRAND_NOT_FOUND); &#125; //解析分页结果 PageInfo&lt;Brand&gt; info = new PageInfo&lt;&gt;(brands); return new PageResult&lt;&gt;(info.getTotal(),brands); &#125; 这就使分页助手 pegehelper 的简单使用]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异步查询工具axios]]></title>
    <url>%2F2019%2F03%2F29%2F%E5%BC%82%E6%AD%A5%E6%9F%A5%E8%AF%A2%E5%B7%A5%E5%85%B7axios%2F</url>
    <content type="text"><![CDATA[异步查询数据，自然是通过ajax查询，大家首先想起的肯定是jQuery。但jQuery与MVVM的思想不吻合，而且ajax只是jQuery的一小部分。因此不可能为了发起ajax请求而去引用这么大的一个库 Vue官方推荐的ajax请求框架叫做：axios axios小入门先导入axios的js文件 axios的Get请求语法12345678910111213141516axios.get(&quot;/item/category/list?pid=0&quot;) // 请求路径和请求参数拼接 .then(function(resp)&#123; // 成功回调函数 &#125;) .catch(function()&#123; // 失败回调函数 &#125;)// 参数较多时，可以通过params来传递参数axios.get(&quot;/item/category/list&quot;, &#123; params:&#123; pid:0 &#125; &#125;) .then(function(resp)&#123;&#125;)// 成功时的回调 .catch(function(error)&#123;&#125;)// 失败时的回调 axios的POST请求语法123456axios.post(&quot;/user&quot;,&#123; name:&quot;Jack&quot;, age:21 &#125;) .then(function(resp)&#123;&#125;) .catch(function(error)&#123;&#125;) 注意，POST请求传参，不需要像GET请求那样定义一个对象，在对象的params参数中传参。post()方法的第二个参数对象，就是将来要传递的参数 PUT和DELETE请求与POST请求类似 可以设置axios的基础请求路径 和请求时间12axios.defaults.baseURL = config.api; // 设置axios的基础请求路径axios.defaults.timeout = 2000; // 设置axios的请求时间]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cors解决跨域]]></title>
    <url>%2F2019%2F03%2F29%2Fcors%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[什么是corsCORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。 它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。 CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。 浏览器端：目前，所有浏览器都支持该功能（IE10以下不行）。整个CORS通信过程，都是浏览器自动完成，不需要用户参与。 服务端：CORS通信与AJAX没有任何差别，因此你不需要改变以前的业务逻辑。只不过，浏览器会在请求中携带一些头信息，我们需要以此判断是否运行其跨域，然后在响应头中加入一些信息即可。这一般通过过滤器完成即可。 浏览器会将ajax请求分为两类，其处理方案略有差异：简单请求、特殊请求。 简单请求只要同时满足以下两大条件，就属于简单请求。： （1) 请求方法是以下三种方法之一： HEAD GET POST （2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain Access-Control-Allow-Origin：可接受的域，是一个具体域名或者*，代表任意 Access-Control-Allow-Credentials：是否允许携带cookie，默认情况下，cors不会携带cookie，除非这个值是true 注意： 如果跨域请求要想操作cookie，需要满足3个条件： 服务的响应头中需要携带Access-Control-Allow-Credentials并且为true。 浏览器发起ajax需要指定withCredentials 为true 响应头中的Access-Control-Allow-Origin一定不能为*，必须是指定的域名 Access-Control-Allow-Methods：允许访问的方式 Access-Control-Allow-Headers：允许携带的头 Access-Control-Max-Age：本次许可的有效时长，单位是秒，过期之前的ajax请求就无需再次进行预检了 如果浏览器得到上述响应，则认定为可以跨域，后续就跟简单请求的处理是一样的了。 实现 浏览器端都有浏览器自动完成，我们无需操心 服务端可以通过拦截器统一实现，不必每次都去进行跨域判定的编写。 事实上，SpringMVC已经帮我们写好了CORS的跨域过滤器：CorsFilter ,内部已经实现了刚才所讲的判定逻辑，我们直接用就好了 在网关服务中编写一个配置类12345678910111213141516171819202122232425262728293031323334353637import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;@Configurationpublic class GlobalCorsConfig &#123; @Bean public CorsFilter corsFilter() &#123; //1.添加CORS配置信息 CorsConfiguration config = new CorsConfiguration(); //1) 允许的域,不要写*，否则cookie就无法使用了 config.addAllowedOrigin(&quot;http://manage.leyou.com&quot;); //2) 是否发送Cookie信息 config.setAllowCredentials(true); //3) 允许的请求方式 config.addAllowedMethod(&quot;OPTIONS&quot;); config.addAllowedMethod(&quot;HEAD&quot;); config.addAllowedMethod(&quot;GET&quot;); config.addAllowedMethod(&quot;PUT&quot;); config.addAllowedMethod(&quot;POST&quot;); config.addAllowedMethod(&quot;DELETE&quot;); config.addAllowedMethod(&quot;PATCH&quot;); // 4）允许的头信息 config.addAllowedHeader(&quot;*&quot;); // 5 有效时长 config.setMaxAge(3600L); //2.添加映射路径，我们拦截一切请求 UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration(&quot;/**&quot;, config); //3.返回新的CorsFilter. return new CorsFilter(configSource); &#125;&#125; 然后重新启动测试]]></content>
      <categories>
        <category>跨域</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot之全局异常处理2]]></title>
    <url>%2F2019%2F03%2F29%2FSpringBoot%E4%B9%8B%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%862%2F</url>
    <content type="text"><![CDATA[全局处理异常步骤第一步12345678910111213141516//创建一个枚举类@Getter@NoArgsConstructorpublic enum ExceptionMuns &#123; MY_ERROR(404,&quot;找不到&quot;), ; private Integer status; private String mseeage; ExceptionMuns(Integer status, String mseeage) &#123; this.status = status; this.mseeage = mseeage; &#125;&#125; 第二步123456789101112131415@Datapublic class ExceptionResult &#123; private Integer code; private String message; private Long timestamp; public ExceptionResult(ExceptionMuns e) &#123; this.code = e.getStatus(); this.message = e.getMseeage(); this.timestamp = System.currentTimeMillis(); &#125;&#125; 第三步123456789@Getter@AllArgsConstructor@NoArgsConstructorpublic class MyException extends RuntimeException &#123; private ExceptionMuns exceptionMuns;&#125; 第四步123456789101112131415161718/***全局异常拦截**/@ControllerAdvice //拦截所有加了controler注解的类public class ExceptionAdtive &#123; /** * 遵循Result风格 */ @ExceptionHandler(MyException.class) public ResponseEntity&lt;ExceptionResult&gt; ExceptionAdtive(MyException e)&#123; return ResponseEntity.status(e.getExceptionMuns().getStatus()) .body(new ExceptionResult(e.getExceptionMuns())); &#125; &#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud之Zuul网关]]></title>
    <url>%2F2019%2F03%2F07%2FSpringCloud%E4%B9%8BZuul%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[使用Spring Cloud实现微服务的架构基本成型，大致是这样的: 我们使用Spring Cloud Netflix中的Eureka实现了服务注册中心以及服务注册与发现；而服务间通过Ribbon或Feign实现服务的消费以及均衡负载；通过Spring Cloud Config实现了应用多环境的外部化配置以及版本管理。为了使得服务集群更为健壮，使用Hystrix的融断机制来避免在微服务架构中个别服务出现异常时引起的故障蔓延。 在该架构中，我们的服务集群包含：内部服务Service A和Service B，他们都会注册与订阅服务至Eureka Server，而Open Service是一个对外的服务，通过均衡负载公开至服务调用方。我们把焦点聚集在对外服务这块，直接暴露我们的服务地址，这样的实现是否合理，或者是否有更好的实现方式呢？ 先来说说这样架构需要做的一些事儿以及存在的不足： 首先，破坏了服务无状态特点。 为了保证对外服务的安全性，我们需要实现对服务访问的权限控制，而开放服务的权限控制机制将会贯穿并污染整个开放服务的业务逻辑，这会带来的最直接问题是，破坏了服务集群中REST API无状态的特点。 从具体开发和测试的角度来说，在工作中除了要考虑实际的业务逻辑之外，还需要额外考虑对接口访问的控制处理。 其次，无法直接复用既有接口。 当我们需要对一个即有的集群内访问接口，实现外部服务访问时，我们不得不通过在原有接口上增加校验逻辑，或增加一个代理调用来实现权限控制，无法直接复用原有的接口。 面对类似上面的问题，我们要如何解决呢？答案是：服务网关！ 为了解决上面这些问题，我们需要将权限控制这样的东西从我们的服务单元中抽离出去，而最适合这些逻辑的地方就是处于对外访问最前端的地方，我们需要一个更强大一些的均衡负载器的 服务网关。 服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。 Zuul加入后的架构 不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都会经过Zuul这个网关，然后再由网关来实现 鉴权、动态路由等等操作。Zuul就是我们服务的统一入口。 编写启动类通过@EnableZuulProxy注解开启Zuul的功能：12345678@SpringBootApplication@EnableZuulProxy // 开启Zuul的网关功能public class ZuulDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulDemoApplication.class, args); &#125;&#125; 编写配置12345server: port: 10010 #服务端口spring: application: name: api-gateway #指定服务名 映射规则：12345zuul: routes: user-service: # 这里是路由id，随意写 path: /user-service/** # 这里是映射路径 url: http://127.0.0.1:8081 # 映射路径对应的实际url地址 我们将符合path 规则的一切请求，都代理到 url参数指定的地址 本例中，我们将 /user-service/**开头的请求，代理到http://127.0.0.1:8081 启动测试：访问的路径中需要加上配置规则的映射路径 面向服务的路由在刚才的路由规则中，我们把路径对应的服务地址写死了！如果同一服务有多个实例的话，这样做显然就不合理了。 我们应该根据服务的名称，去Eureka注册中心查找 服务对应的所有实例列表，然后进行动态路由才对！ 添加Eureka客户端依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 开启Eureka客户端发现功能123456789@SpringBootApplication@EnableZuulProxy // 开启Zuul的网关功能@EnableDiscoveryClientpublic class ZuulDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulDemoApplication.class, args); &#125;&#125; 添加Eureka配置，获取服务信息12345678eureka: client: registry-fetch-interval-seconds: 5 # 获取服务列表的周期：5s service-url: defaultZone: http://127.0.0.1:10086/eureka instance: prefer-ip-address: true ip-address: 127.0.0.1 修改映射配置，通过服务名称获取因为已经有了Eureka客户端，我们可以从Eureka获取服务的地址信息，因此映射时无需指定IP地址，而是通过服务名称来访问，而且Zuul已经集成了Ribbon的负载均衡功能。 12345zuul: routes: user-service: # 这里是路由id，随意写 path: /user-service/** # 这里是映射路径 serviceId: user-service # 指定服务名称 再次启动，这次Zuul进行代理时，会利用Ribbon进行负载均衡访问： 默认的路由规则在使用Zuul的过程中，上面讲述的规则已经大大的简化了配置项。但是当服务较多时，配置也是比较繁琐的。因此Zuul就指定了默认的路由规则： 默认情况下，一切服务的映射路径就是服务名本身。 例如服务名为：user-service，则默认的映射路径就是：/user-service/** 也就是说，刚才的映射规则我们完全不配置也是OK的，不信就试试看。 路由前缀配置示例：123456zuul: prefix: /api # 添加路由前缀 routes: user-service: # 这里是路由id，随意写 path: /user-service/** # 这里是映射路径 service-id: user-service # 指定服务名称 我们通过zuul.prefix=/api来指定了路由的前缀，这样在发起请求时，路径就要以/api开头。 路径/api/user-service/user/1将会被代理到/user-service/user/1 ZuulFilterZuul作为网关的其中一个重要功能，就是实现请求的鉴权。而这个动作我们往往是通过Zuul提供的过滤器来实现的。ZuulFilter是过滤器的顶级父类。在这里我们看一下其中定义的4个最重要的方法： 12345678910public abstract ZuulFilter implements IZuulFilter&#123; abstract public String filterType(); abstract public int filterOrder(); boolean shouldFilter();// 来自IZuulFilter Object run() throws ZuulException;// IZuulFilter&#125; shouldFilter：返回一个Boolean值，判断该过滤器是否需要执行。返回true执行，返回false不执行。 run：过滤器的具体业务逻辑。 filterType：返回字符串，代表过滤器的类型。包含以下4种： pre：请求在被路由之前执行 routing：在路由请求时调用 post：在routing和errror过滤器之后调用 error：处理请求时发生错误调用 filterOrder：通过返回的int值来定义过滤器的执行顺序，数字越小优先级越高。 过滤器执行生命周期 正常流程： 请求到达首先会经过pre类型过滤器，而后到达routing类型，进行路由，请求就到达真正的服务提供者，执行请求，返回结果后，会到达post过滤器。而后返回响应。 异常流程： 整个过程中，pre或者routing过滤器出现异常，都会直接进入error过滤器，再error处理完毕后，会将请求交给POST过滤器，最后返回给用户。 如果是error过滤器自己出现异常，最终也会进入POST过滤器，而后返回。 如果是POST过滤器出现异常，会跳转到error过滤器，但是与pre和routing不同的时，请求不会再到达POST过滤器了。 场景非常多： 请求鉴权：一般放在pre类型，如果发现没有访问权限，直接就拦截了 异常处理：一般会在error类型和post类型过滤器中结合来处理。 服务调用时长统计：pre和post结合使用。 自定义过滤器接下来我们来自定义一个过滤器，模拟一个登录的校验。基本逻辑：如果请求中有access-token参数，则认为请求有效，放行 定义过滤器类1234567891011121314151617181920212223242526272829303132@Componentpublic class LoginFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FilterConstants.PRE_DECORATION_FILTER_ORDER -1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; //获取请求的参数 RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); //判断是否存在 String parameter = request.getParameter(&quot;access-token&quot;); if(StringUtils.isBlank(parameter))&#123; //不存在，未登录，则拦截 ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(HttpStatus.FORBIDDEN.value()); &#125; return null; &#125;&#125; 测试 没有token参数时，访问失败： 添加token参数后：访问成功 负载均衡和熔断Zuul中默认就已经集成了Ribbon负载均衡和Hystix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议我们手动进行配置： 123456789101112131415zuul: retryable: trueribbon: ConnectTimeout: 250 # 连接超时时间(ms) ReadTimeout: 2000 # 通信超时时间(ms) OkToRetryOnAllOperations: true # 是否对所有操作重试 MaxAutoRetriesNextServer: 2 # 同一服务不同实例的重试次数 MaxAutoRetries: 1 # 同一实例的重试次数hystrix: command: default: execution: isolation: thread: timeoutInMillisecond: 6000 # 熔断超时时长：6000ms ribbon的超时时长，真实值是（read+connect）*2,必须小于hystrix熔断超时时长 最终配置 1234567891011121314151617181920212223242526272829303132server: port: 10010spring: application: name: api-gatewayeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eurekazuul: prefix: /api # 添加路由前缀 routes: item-service: /item/** upload-service: path: /upload/** serviceId: upload-service strip-prefix: false add-host-header: true # API网关在进行请求路由转发前为请求设置Host头信息 sensitive-headers: # 默认情况下，敏感的头信息无法经过API网关进行传递，我们可以通过如下配置使之可以传递hystrix: command: default: execution: isolation: thread: timeoutInMillisecond: 50000 # 熔断超时时长：10000msribbon: ConnectTimeout: 5000 # 连接超时时间(ms) ReadTimeout: 5000 # 通信超时时间(ms) MaxAutoRetriesNextServer: 0 # 同一服务不同实例的重试次数 MaxAutoRetries: 0 # 同一实例的重试次数]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud之Feign远程调用]]></title>
    <url>%2F2019%2F03%2F07%2FSpringCloud%E4%B9%8BFeign%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[我们使用过Ribbon的负载均衡功能，大大简化了远程调用时的代码：12String baseUrl = &quot;http://user-service/user/&quot;;User user = this.restTemplate.getForObject(baseUrl + id, User.class) Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。 快速入门 导入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; Feign的客户端123456@FeignClient(&quot;user-service&quot;)public interface UserFeignClient &#123; @GetMapping(&quot;/user/&#123;id&#125;&quot;) User queryUserById(@PathVariable(&quot;id&quot;) Long id);&#125; 首先这是一个接口，Feign会通过动态代理，帮我们生成实现类。这点跟mybatis的mapper很像 @FeignClient，声明这是一个Feign客户端，类似@Mapper注解。同时通过value属性指定服务名称 接口中的定义方法，完全采用SpringMVC的注解，Feign会根据注解帮我们生成URL，并访问获取结果 改造原来的调用逻辑，不再调用UserDao： 123456789101112131415@Servicepublic class UserService &#123; @Autowired private UserFeignClient userFeignClient; public List&lt;User&gt; queryUserByIds(List&lt;Long&gt; ids) &#123; List&lt;User&gt; users = new ArrayList&lt;&gt;(); ids.forEach(id -&gt; &#123; // 我们测试多次查询， users.add(this.userFeignClient.queryUserById(id)); &#125;); return users; &#125;&#125; 开启Feign功能我们在启动类上，添加注解，开启Feign功能 123456789@SpringBootApplication@EnableDiscoveryClient@EnableHystrix@EnableFeignClients // 开启Feign功能public class UserConsumerDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserConsumerDemoApplication.class, args); &#125;&#125; 你会发现RestTemplate的注册被我删除了。Feign中已经自动集成了Ribbon负载均衡，因此我们不需要自己定义RestTemplate了 启动测试, 访问接口： 负载均衡Feign中本身已经集成了Ribbon依赖和自动配置：因此我们不需要额外引入依赖，也不需要再注册RestTemplate对象。 另外，我们可以像上节课中讲的那样去配置Ribbon，可以通过ribbon.xx来进行全局配置。也可以通过服务名.ribbon.xx来对指定服务配置：1234567user-service: ribbon: ConnectTimeout: 250 # 连接超时时间(ms) ReadTimeout: 1000 # 通信超时时间(ms) OkToRetryOnAllOperations: true # 是否对所有操作重试 MaxAutoRetriesNextServer: 1 # 同一服务不同实例的重试次数 MaxAutoRetries: 1 # 同一实例的重试次数 Hystix支持 Feign默认也有对Hystix的集成： 只不过，默认情况下是关闭的。我们需要通过下面的参数来开启：123feign: hystrix: enabled: true # 开启Feign的熔断功能 但是，Feign中的Fallback配置不像Ribbon中那样简单了。 首先，我们要定义一个类，实现刚才编写的UserFeignClient，作为 fallback的处理类12345678910@Componentpublic class UserFeignClientFallback implements UserFeignClient &#123; @Override public User queryUserById(Long id) &#123; User user = new User(); user.setId(id); user.setName(&quot;用户查询出现异常！&quot;); return user; &#125;&#125; 然后在UserFeignClient中，指定刚才编写的实现类 123456@FeignClient(value = &quot;user-service&quot;, fallback = UserFeignClientFallback.class)public interface UserFeignClient &#123; @GetMapping(&quot;/user/&#123;id&#125;&quot;) User queryUserById(@PathVariable(&quot;id&quot;) Long id);&#125; 重启测试： 我们关闭user-service服务，然后在页面访问：]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud之Hystix熔断]]></title>
    <url>%2F2019%2F03%2F07%2FSpringCloud%E4%B9%8BHystix%E7%86%94%E6%96%AD%2F</url>
    <content type="text"><![CDATA[Hystix，即熔断器。主页：https://github.com/Netflix/Hystrix/ Hystix是Netflix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败 熔断器的工作机制：正常工作的情况下，客户端请求调用服务API接口：当有服务出现异常时，直接进行失败回滚，服务降级处理：当服务繁忙时，如果服务出现异常，不是粗暴的直接报错，而是返回一个友好的提示，虽然拒绝了用户的访问，但是会返回一个结果。 这就好比去买鱼，平常超市买鱼会额外赠送杀鱼的服务。等到逢年过节，超时繁忙时，可能就不提供杀鱼服务了，这就是服务的降级。 系统特别繁忙时，一些次要服务暂时中断，优先保证主要服务的畅通，一切资源优先让给主要服务来使用，在双十一、618时，京东天猫都会采用这样的策略。 引入依赖首先入Hystix依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 开启熔断在启动类上添加@EnableCircuitBreaker 或者只添加@SpringCloudApplication改造消费者 我们改造user-consumer，添加一个用来访问的user服务的DAO，并且声明一个失败时的回滚处理函数：1234567891011121314151617181920212223242526@Componentpublic class UserDao &#123; @Autowired private RestTemplate restTemplate; private static final Logger logger = LoggerFactory.getLogger(UserDao.class); @HystrixCommand(fallbackMethod = &quot;queryUserByIdFallback&quot;) public User queryUserById(Long id)&#123; long begin = System.currentTimeMillis(); String url = &quot;http://user-service/user/&quot; + id; User user = this.restTemplate.getForObject(url, User.class); long end = System.currentTimeMillis(); // 记录访问用时： logger.info(&quot;访问用时：&#123;&#125;&quot;, end - begin); return user; &#125; public User queryUserByIdFallback(Long id)&#123; User user = new User(); user.setId(id); user.setName(&quot;用户信息查询出现异常！&quot;); return user; &#125;&#125; @HystrixCommand(fallbackMethod=”queryUserByIdFallback”)`：声明一个失败回滚处理函数queryUserByIdFallback，当queryUserById执行超时（默认是1000毫秒），就会执行fallback函数，返回错误提示。 为了方便查看熔断的触发时机，我们记录请求访问时间。 也可以将@DefaultProperties(defaultFallback = “queryByIdFallback”) 配置在类上声明该类方法的默认就会执行fallback函数，返回错误提示 在原来的业务逻辑中调用这个DAO： 123456789101112131415@Servicepublic class UserService &#123; @Autowired private UserDao userDao; public List&lt;User&gt; queryUserByIds(List&lt;Long&gt; ids) &#123; List&lt;User&gt; users = new ArrayList&lt;&gt;(); ids.forEach(id -&gt; &#123; // 我们测试多次查询， users.add(this.userDao.queryUserById(id)); &#125;); return users; &#125;&#125; 改造服务提供者改造服务提供者，随机休眠一段时间，以触发熔断： 123456789101112@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper; public User queryById(Long id) throws InterruptedException &#123; // 为了演示超时现象，我们在这里然线程休眠,时间随机 0~2000毫秒 Thread.sleep(new Random().nextInt(2000)); return this.userMapper.selectByPrimaryKey(id); &#125;&#125; 启动测试 然后运行并查看日志： 根据id进行访问 优化虽然熔断实现了，但是我们的重试机制似乎没有生效，是这样吗？ 其实这里是因为我们的Ribbon超时时间设置的是1000ms: 而Hystix的超时时间默认也是1000ms，因此重试机制没有被触发，而是先触发了熔断。 所以，Ribbon的超时时间一定要小于Hystix的超时时间。 我们可以通过hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds来设置Hystrix超时时间。 1234567hystrix: command: default: execution: isolation: thread: timeoutInMillisecond: 6000 # 设置hystrix的超时时间为6000ms 123456789默认的熔断出发要求比较高，休眠时间窗比较短 为了方便测试可以通过配置修改熔断策略circuitBreaker.requestVolumeThreshold=10circuitBreaker.sleepWindowInMilliseconds=10000circuitBreaker.errorThresholdPercentage=50解读：requestVolumeThreshold：出发熔断的最小请求次数 默认为20sleepWindowInMilliseconds：休眠时长 默认是5000毫秒errorThresholdPercentage：触发熔断的失败请求最小占比 默认是50%]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud之负载均衡Robbin]]></title>
    <url>%2F2019%2F03%2F07%2FSpringCloud%E4%B9%8B%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1Robbin%2F</url>
    <content type="text"><![CDATA[在Eureka中已经帮我们集成了负载均衡组件：Ribbon，简单修改代码即可使用。 接下来，我们就来使用Ribbon实现负载均衡。 启动两个服务实例首先我们启动两个user-service实例，一个8081，一个8082。 开启负载均衡因为Eureka中已经集成了Ribbon，所以我们无需引入新的依赖。直接修改代码：在RestTemplate的配置方法上添加@LoadBalanced注解：12345@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate(new OkHttp3ClientHttpRequestFactory());&#125; 修改调用方式，不再手动获取ip和端口，而是直接通过服务名称调用： 1234567891011121314151617181920212223242526@Servicepublic class UserService &#123; @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; public List&lt;User&gt; queryUserByIds(List&lt;Long&gt; ids) &#123; List&lt;User&gt; users = new ArrayList&lt;&gt;(); // 地址直接写服务名称即可 String baseUrl = &quot;http://user-service/user/&quot;; ids.forEach(id -&gt; &#123; // 我们测试多次查询， users.add(this.restTemplate.getForObject(baseUrl + id, User.class)); // 每次间隔500毫秒 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); return users; &#125;&#125; 访问页面，查看结果：完美 负载均衡策略默认是使用轮询 SpringBoot也帮我们提供了修改负载均衡规则的配置入口：在配置文件中添加123user-service: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 再次测试，发现结果变成了随机 重试机制Eureka的服务治理强调了CAP原则中的AP，即可用性和可靠性。它与Zookeeper这一类强调CP（一致性，可靠性）的服务治理框架最大的区别在于：Eureka为了实现更高的服务可用性，牺牲了一定的一致性，极端情况下它宁愿接收故障实例也不愿丢掉健康实例，正如我们上面所说的自我保护机制。 关闭一个user-service实例:因为服务剔除的延迟，consumer并不会立即得到最新的服务列表，此时再次访问你会得到错误提示：但是此时，8081服务其实是正常的。 因此Spring Cloud 整合了Spring Retry 来增强RestTemplate的重试能力，当一次服务调用失败后，不会立即抛出一次，而是再次重试另一个服务。只需要简单配置即可实现Ribbon的重试：12345678910111213spring: cloud: loadbalancer: retry: enabled: true # 开启Spring Cloud的重试功能user-service: ribbon: ConnectTimeout: 250 # Ribbon的连接超时时间 ReadTimeout: 1000 # Ribbon的数据读取超时时间 OkToRetryOnAllOperations: true # 是否对所有操作都进行重试 MaxAutoRetriesNextServer: 1 # 切换实例的重试次数 MaxAutoRetries: 1 # 对当前实例的重试次数 根据如上配置，当访问到某个服务超时后，它会再次尝试访问下一个服务实例，如果不行就再换一个实例，如果不行，则返回失败。切换次数取决于MaxAutoRetriesNextServer参数的值 引入spring-retry依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt; 我们重启user-consumer-demo，测试，发现即使user-service2宕机，也能通过另一台服务实例获取到结果！]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud之Eureka注册中心]]></title>
    <url>%2F2019%2F03%2F07%2FSpringCloud%E4%B9%8BEureka%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[原理图Eureka：就是服务注册中心（可以是一个集群），对外暴露自己的地址提供者：启动后向Eureka注册自己信息（地址，提供什么服务）消费者：向Eureka订阅服务，Eureka会将对应服务的所有提供者地址列表发送给消费者，并且定期更新心跳(续约)：提供者定期通过http方式向Eureka刷新自己的状态 pom.xml文件12345678910111213141516171819202122&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; &lt;!-- Eureka服务端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringCloud依赖，一定要放到dependencyManagement中，起到管理版本的作用即可 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 根据需要导入依赖即可 编写启动类：123456789@SpringBootApplication@EnableEurekaServer // 声明这个应用是一个EurekaServerpublic class EurekaDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaDemoApplication.class, args); &#125;&#125; 编写配置：以yml文件的方式配置1234567891011server: port: 10086 # 端口spring: application: name: eureka-server # 应用名称，会在Eureka中显示eureka: client: register-with-eureka: false # 是否注册自己的信息到EurekaServer，默认是true fetch-registry: false # 是否拉取其它服务的信息，默认是true service-url: # EurekaServer的地址，现在是自己的地址，如果是集群，需要加上其它Server的地址。 defaultZone: http://127.0.0.1:10086/eureka 启动服务，并访问：http://127.0.0.1:10086/eureka 将user-service注册到Eureka注册服务，就是在服务上添加Eureka的客户端依赖，客户端代码会自动把服务注册到EurekaServer中。先添加SpringCloud依赖：然后是Eureka客户端：12345&lt;!-- Eureka客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 在启动类上开启Eureka客户端功能通过添加@EnableDiscoveryClient来开启Eureka客户端功能 1234567@SpringBootApplication@EnableDiscoveryClient // 开启EurekaClient功能public class UserServiceDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserServiceDemoApplication.class, args); &#125;&#125; 编写配置123456789101112131415161718192021server: port: 8081spring: datasource: url: jdbc:mysql://localhost:3306/mydb01 username: root password: 123 hikari: maximum-pool-size: 20 minimum-idle: 10 application: name: user-service # 应用名称mybatis: type-aliases-package: com.leyou.userservice.pojoeureka: client: service-url: # EurekaServer地址 defaultZone: http://127.0.0.1:10086/eureka instance: prefer-ip-address: true # 当调用getHostname获取实例的hostname时，返回ip而不是host名称 ip-address: 127.0.0.1 # 指定自己的ip信息，不指定的话会自己寻找 注意：这里我们添加了spring.application.name属性来指定应用名称，将来会作为应用的id使用。不用指定register-with-eureka和fetch-registry，因为默认是true 重启项目，访问Eureka监控页面查看，看见有 user-service 大写的名称就说明服务注册成功了消费者从Eureka获取服务 方法与消费者类似，只需要在项目中添加EurekaClient依赖，就可以通过服务名称来获取信息了！、先添加SpringCloud依赖：然后是Eureka客户端：和之前的依赖是一样的在启动类开启Eureka客户端修改配置： 123456789101112server: port: 8080spring: application: name: consumer # 应用名称eureka: client: service-url: # EurekaServer地址 defaultZone: http://127.0.0.1:10086/eureka instance: prefer-ip-address: true # 当其它服务获取地址时提供ip而不是hostname ip-address: 127.0.0.1 # 指定自己的ip信息，不指定的话会自己寻找 修改代码，用DiscoveryClient类的方法，根据服务名称，获取服务实例：123456789101112131415161718192021222324@Servicepublic class UserService &#123; @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient;// Eureka客户端，可以获取到服务实例信息 public List&lt;User&gt; queryUserByIds(List&lt;Long&gt; ids) &#123; List&lt;User&gt; users = new ArrayList&lt;&gt;(); // String baseUrl = &quot;http://localhost:8081/user/&quot;; // 根据服务名称，获取服务实例 List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;user-service&quot;); // 因为只有一个UserService,因此我们直接get(0)获取 ServiceInstance instance = instances.get(0); // 获取ip和端口信息 String baseUrl = &quot;http://&quot;+instance.getHost() + &quot;:&quot; + instance.getPort()+&quot;/user/&quot;; users.add(this.restTemplate.getForObject(baseUrl + id, User.class)); return users; &#125;&#125; 最后根据你的路径访问，查看数据 Eureka详解基础架构Eureka架构中的三个核心角色： 服务注册中心Eureka的服务端应用，提供服务注册和发现功能，就是刚刚我们建立的eureka-demo 服务提供者提供服务的应用，可以是SpringBoot应用，也可以是其它任意技术实现，只要对外提供的是Rest风格服务即可。本例中就是我们实现的user-service-demo 服务消费者消费应用从注册中心获取服务列表，从而得知每个服务方的信息，知道去哪里调用服务方。本例中就是我们实现的consumer-demo 高可用的Eureka ServerEureka Server即服务的注册中心，在刚才的案例中，我们只有一个EurekaServer，事实上EurekaServer也可以是一个集群，形成高可用的Eureka中心。 服务同步 多个Eureka Server之间也会互相注册为服务，当服务提供者注册到Eureka Server集群中的某个节点时，该节点会把服务的信息同步给集群中的每个节点，从而实现数据同步。因此，无论客户端访问到Eureka Server集群中的任意一个节点，都可以获取到完整的服务列表信息 动手搭建高可用的EurekaServer 我们假设要搭建两条EurekaServer的集群，端口分别为：10086和10087我们修改原来的EurekaServer配置：123456789server: port: 10086 # 端口spring: application: name: eureka-server # 应用名称，会在Eureka中显示eureka: client: service-url: # 配置其他Eureka服务的地址，而不是自己，比如10087 defaultZone: http://127.0.0.1:10087/eureka 所谓的高可用注册中心，其实就是把EurekaServer自己也作为一个服务进行注册，这样多个EurekaServer之间就能互相发现对方，从而形成集群。因此我们做了以下修改： 删除了register-with-eureka=false和fetch-registry=false两个配置。因为默认值是true，这样就会吧自己注册到注册中心了。 把service-url的值改成了另外一台EurekaServer的地址，而不是自己 另外一台配置恰好相反：123456789server: port: 10087 # 端口spring: application: name: eureka-server # 应用名称，会在Eureka中显示eureka: client: service-url: # 配置其他Eureka服务的地址，而不是自己，比如10087 defaultZone: http://127.0.0.1:10086/eureka 注意：idea中一个应用不能启动两次，我们需要重新配置一个启动器： 然后启动即可。 客户端注册服务到集群 因为EurekaServer不止一个，因此注册服务的时候，service-url参数需要变化：1234eureka: client: service-url: # EurekaServer地址,多个地址以&apos;,&apos;隔开 defaultZone: http://127.0.0.1:10086/eureka,http://127.0.0.1:10087/eureka 服务提供者服务提供者要向EurekaServer注册服务，并且完成服务续约等工作。 服务注册服务提供者在启动时，会检测配置属性中的：eureka.client.register-with-erueka=true参数是否正确，事实上默认就是true。如果值确实为true，则会向EurekaServer发起一个Rest请求，并携带自己的元数据信息，Eureka Server会把这些信息保存到一个双层Map结构中。第一层Map的Key就是服务名称，第二层Map的key是服务的实例id。服务续约在注册服务完成以后，服务提供者会维持一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”。这个我们称为服务的续约（renew）； 有两个重要参数可以修改服务续约的行为： 1234eureka: instance: lease-expiration-duration-in-seconds: 90 lease-renewal-interval-in-seconds: 30 lease-renewal-interval-in-seconds：服务续约(renew)的间隔，默认为30秒 lease-expiration-duration-in-seconds：服务失效时间，默认值90秒 也就是说，默认情况下每个30秒服务会向注册中心发送一次心跳，证明自己还活着。如果超过90秒没有发送心跳，EurekaServer就会认为该服务宕机，会从服务列表中移除，这两个值在生产环境不要修改，默认即可。 但是在开发时，这个值有点太长了，经常我们关掉一个服务，会发现Eureka依然认为服务在活着。所以我们在开发阶段可以适当调小。 服务消费者 获取服务列表当服务消费者启动是，会检测eureka.client.fetch-registry=true参数的值，如果为true，则会从Eureka Server服务的列表只读备份，然后缓存在本地。并且每隔30秒会重新获取并更新数据。我们可以通过下面的参数来修改： 123eureka: client: registry-fetch-interval-seconds: 5 生产环境中，我们不需要修改这个值。 失效剔除和自我保护失效剔除有些时候，我们的服务提供方并不一定会正常下线，可能因为内存溢出、网络故障等原因导致服务无法正常工作。Eureka Server需要将这样的服务剔除出服务列表。因此它会开启一个定时任务，每隔60秒对所有失效的服务（超过90秒未响应）进行剔除。可以通过eureka.server.eviction-interval-timer-in-ms参数对其进行修改，单位是毫秒，生成环境不要修改。 这个会对我们开发带来极大的不变，你对服务重启，隔了60秒Eureka才反应过来。开发阶段可以适当调整，比如10S 自我保护 我们关停一个服务，就会在Eureka面板看到一条警告：这是触发了Eureka的自我保护机制。当一个服务未按时进行心跳续约时，Eureka会统计最近15分钟心跳失败的服务实例的比例是否超过了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务剔除列表并不妥当，因为服务可能没有宕机。Eureka就会把当前实例的注册信息保护起来，不予剔除。生产环境下这很有效，保证了大多数服务依然可用。 但是这给我们的开发带来了麻烦， 因此开发阶段我们都会关闭自我保护模式： 1234eureka: server: enable-self-preservation: false # 关闭自我保护模式（缺省为打开） eviction-interval-timer-in-ms: 1000 # 扫描失效服务的间隔时间（缺省为60*1000ms）]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的RestTemplate]]></title>
    <url>%2F2019%2F03%2F07%2FSpring%E7%9A%84RestTemplate%2F</url>
    <content type="text"><![CDATA[系统之间调用Spring提供了一个RestTemplate模板工具类，对基于Http的客户端进行了封装，并且实现了对象与json的序列化和反序列化，非常方便。RestTemplate并没有限定Http的客户端类型，而是进行了抽象，目前常用的3种都有支持：1.HttpClient2.OkHttp3.JDK原生的URLConnection（默认的）首先在项目中注册一个RestTemplate对象，可以在启动类位置注册：1234567891011121314@SpringBootApplicationpublic class HttpDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HttpDemoApplication.class, args); &#125; @Bean public RestTemplate restTemplate() &#123; // 默认的RestTemplate，底层是走JDK的URLConnection方式。 return new RestTemplate(); &#125;&#125; 在测试类中直接@Autowired注入： 1234567891011121314@RunWith(SpringRunner.class)@SpringBootTest(classes = HttpDemoApplication.class)public class HttpDemoApplicationTests &#123; @Autowired private RestTemplate restTemplate; @Test public void httpGet() &#123; User user = this.restTemplate.getForObject(&quot;http://localhost/hello&quot;, User.class); System.out.println(user); &#125;&#125; 通过RestTemplate的getForObject()方法，传递url地址及实体类的字节码，RestTemplate会自动发起请求，接收响应，并且帮我们对响应结果进行反序列化。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[远程调用方式RPC与http]]></title>
    <url>%2F2019%2F03%2F07%2F%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E6%96%B9%E5%BC%8FRPC%E4%B8%8Ehttp%2F</url>
    <content type="text"><![CDATA[远程调用方式无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？ 常见的远程调用方式有以下几种： RPC：Remote Produce Call远程过程调用，类似的还有RMI。自定义数据格式，基于原生TCP通信，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型 Http：http其实是一种网络传输协议，基于TCP，规定了数据传输的格式。现在客户端浏览器与服务端通信基本都是采用Http协议。也可以用来进行远程服务调用。缺点是消息封装臃肿。现在热门的Rest风格，就可以通过http协议来实现。 RPCRPC，即 Remote Procedure Call（远程过程调用），是一个计算机通信协议。 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。说得通俗一点就是：A计算机提供一个服务，B计算机可以像调用本地服务那样调用A计算机的服务。 通过上面的概念，我们可以知道，实现RPC主要是做到两点： 实现远程调用其他计算机的服务 要实现远程调用，肯定是通过网络传输数据。A程序提供服务，B程序通过网络将请求参数传递给A，A本地执行后得到结果，再将结果返回给B程序。这里需要关注的有两点： 采用何种网络通讯协议？ 现在比较流行的RPC框架，都会采用TCP作为底层传输协议 数据传输的格式怎样？ 两个程序进行通讯，必须约定好数据传输格式。就好比两个人聊天，要用同一种语言，否则无法沟通。所以，我们必须定义好请求和响应的格式。另外，数据在网路中传输需要进行序列化，所以还需要约定统一的序列化的方式。 像调用本地服务一样调用远程服务 如果仅仅是远程调用，还不算是RPC，因为RPC强调的是过程调用，调用的过程对用户而言是应该是透明的，用户不应该关心调用的细节，可以像调用本地服务一样调用远程服务。所以RPC一定要对调用的过程进行封装 RPC调用流程图： HttpHttp协议：超文本传输协议，是一种应用层协议。规定了网络传输的请求格式、响应格式、资源定位和操作的方式等。但是底层采用什么网络传输协议，并没有规定，不过现在都是采用TCP协议作为底层传输协议。说到这里，大家可能觉得，Http与RPC的远程调用非常像，都是按照某种规定好的数据格式进行网络通信，有请求，有响应。没错，在这点来看，两者非常相似，但是还是有一些细微差别。 RPC并没有规定数据传输格式，这个格式可以任意指定，不同的RPC协议，数据格式不一定相同。 Http中还定义了资源定位的路径，RPC中并不需要 最重要的一点：RPC需要满足像调用本地服务一样调用远程服务，也就是对调用过程在API层面进行封装。Http协议没有这样的要求，因此请求、响应等细节需要我们自己去实现. 优点：RPC方式更加透明，对用户更方便。Http方式更灵活，没有规定API和语言，跨语言、跨平台 缺点：RPC方式需要在API层面进行封装，限制了开发的语言环境。 例如我们通过浏览器访问网站，就是通过Http协议。只不过浏览器把请求封装，发起请求以及接收响应，解析响应的事情都帮我们做了。如果是不通过浏览器，那么这些事情都需要自己去完成。 如何选择？既然两种方式都可以实现远程调用，我们该如何选择呢？ 速度来看，RPC要比http更快，虽然底层都是TCP，但是http协议的信息往往比较臃肿，不过可以采用gzip压缩 难度来看，RPC实现较为复杂，http相对比较简单 灵活性来看，http更胜一筹，因为它不关心实现细节，跨平台、跨语言。 因此，两者都有不同的使用场景： 如果对效率要求更高，并且开发过程使用统一的技术栈，那么用RPC还是不错的。 如果需要更加灵活，跨语言、跨平台，显然http更合适 那么我们该怎么选择呢？ 微服务，更加强调的是独立、自治、灵活。而RPC方式的限制较多，因此微服务框架中，一般都会采用基于Http的Rest风格服务。]]></content>
      <categories>
        <category>http&amp;RPC</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统架构演变]]></title>
    <url>%2F2019%2F03%2F07%2F%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8F%98%2F</url>
    <content type="text"><![CDATA[集中式架构当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是影响项目开发的关键存在的问题 1.代码耦合，开发维护困难 2.无法针对不同模块进行针对性优化 3.无法水平扩展 4.单点容错率低，并发能力差 垂直拆分当访问量逐渐增大，单一应用无法满足需求，此时为了应对更高的并发和业务需求，我们根据业务功能对系统进行拆分：优点： 1.系统拆分实现了流量分担，解决了并发问题 2.可以针对不同模块进行优化 3.方便水平扩展，负载均衡，容错率提高缺点： 1.系统间相互独立，会有很多重复开发工作，影响开发效率 分布式服务当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式调用是关键。优点： 将基础服务进行了抽取，系统间相互调用，提高了代码复用和开发效率缺点： 系统间耦合度变高，调用关系错综复杂，难以维护 服务治理（SOA）当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键以前出现了什么问题？ 服务越来越多，需要管理每个服务的地址 调用关系错综复杂，难以理清依赖关系 服务过多，服务状态难以管理，无法根据服务情况动态管理服务治理要做什么？ 服务注册中心，实现服务自动注册和发现，无需人为记录服务地址 服务自动订阅，服务列表自动推送，服务调用透明化，无需关心依赖关系 动态监控服务状态监控报告，人为控制服务状态缺点： 服务间会有依赖关系，一旦某个环节出错会影响较大 服务关系复杂，运维、测试部署困难，不符合DevOps思想 微服务前面说的SOA，英文翻译过来是面向服务。微服务，似乎也是服务，都是对系统进行拆分。因此两者非常容易混淆，但其实却有一些差别：微服务的特点： 单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责 微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。 面向服务：面向服务是说每个服务都要对外暴露服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。 自治：自治是说服务间互相独立，互不干扰 团队独立：每个服务都是一个独立的开发团队，人数不能过多。 技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉 前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动段开发不同接口 数据库分离：每个服务都使用自己的数据源 - - 部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护 微服务结构图]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot配置文件application.properties]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6application-properties%2F</url>
    <content type="text"><![CDATA[下面列出其所有的配置 application.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363# ----------------------------------------# CORE PROPERTIES# ----------------------------------------# SPRING 相关配置 (ConfigFileApplicationListener)spring.config.name= # config file name (default to &apos;application&apos;)spring.config.location= # location of config file# profile相关配置spring.profiles= # comma list of active profiles# 系统配置相关参数 (SpringApplication)spring.main.sources=spring.main.web-environment= # detect by defaultspring.main.show-banner=truespring.main....= # see class for all properties# 日志配置相关参数logging.path=/var/logslogging.file=myapp.loglogging.config=# IDENTITY (ContextIdApplicationContextInitializer)spring.application.name=spring.application.index=# tomcat相关配置参数 (ServerProperties)server.port=8080server.address= # bind to a specific NICserver.session-timeout= # session timeout in secondsserver.context-path= # the context path, defaults to &apos;/&apos;server.servlet-path= # the servlet path, defaults to &apos;/&apos;server.tomcat.access-log-pattern= # log pattern of the access logserver.tomcat.access-log-enabled=false # is access logging enabledserver.tomcat.protocol-header=x-forwarded-proto # ssl forward headersserver.tomcat.remote-ip-header=x-forwarded-forserver.tomcat.basedir=/tmp # base dir (usually not needed, defaults to tmp)server.tomcat.background-processor-delay=30; # in secondsserver.tomcat.max-threads = 0 # number of threads in protocol handlerserver.tomcat.uri-encoding = UTF-8 # character encoding to use for URL decoding# springmvc相关配置参数 (HttpMapperProperties)http.mappers.json-pretty-print=false # pretty print JSONhttp.mappers.json-sort-keys=false # sort keysspring.mvc.locale= # set fixed locale, e.g. en_UKspring.mvc.date-format= # set fixed date format, e.g. dd/MM/yyyyspring.mvc.message-codes-resolver-format= # PREFIX_ERROR_CODE / POSTFIX_ERROR_CODEspring.view.prefix= # MVC view prefixspring.view.suffix= # ... and suffixspring.resources.cache-period= # cache timeouts in headers sent to browserspring.resources.add-mappings=true # if default mappings should be added# thymeleaf相关配置参数 (ThymeleafAutoConfiguration)spring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.suffix=.htmlspring.thymeleaf.mode=HTML5spring.thymeleaf.encoding=UTF-8spring.thymeleaf.content-type=text/html # ;charset=&lt;encoding&gt; is addedspring.thymeleaf.cache=true # set to false for hot refresh# freemark相关配置参数 (FreeMarkerAutoConfiguration)spring.freemarker.allowRequestOverride=falsespring.freemarker.allowSessionOverride=falsespring.freemarker.cache=truespring.freemarker.checkTemplateLocation=truespring.freemarker.contentType=text/htmlspring.freemarker.exposeRequestAttributes=falsespring.freemarker.exposeSessionAttributes=falsespring.freemarker.exposeSpringMacroHelpers=falsespring.freemarker.prefix=spring.freemarker.requestContextAttribute=spring.freemarker.settings.*=spring.freemarker.suffix=.ftlspring.freemarker.templateEncoding=UTF-8spring.freemarker.templateLoaderPath=classpath:/templates/spring.freemarker.viewNames= # whitelist of view names that can be resolved# groovy模板相关配置参数 (GroovyTemplateAutoConfiguration)spring.groovy.template.allowRequestOverride=falsespring.groovy.template.allowSessionOverride=falsespring.groovy.template.cache=truespring.groovy.template.configuration.*= # See Groovy&apos;s TemplateConfigurationspring.groovy.template.contentType=text/htmlspring.groovy.template.prefix=classpath:/templates/spring.groovy.template.suffix=.tplspring.groovy.template.templateEncoding=UTF-8spring.groovy.template.viewNames= # whitelist of view names that can be resolved# velocity模板相关配置参数 (VelocityAutoConfiguration)spring.velocity.allowRequestOverride=falsespring.velocity.allowSessionOverride=falsespring.velocity.cache=truespring.velocity.checkTemplateLocation=truespring.velocity.contentType=text/htmlspring.velocity.dateToolAttribute=spring.velocity.exposeRequestAttributes=falsespring.velocity.exposeSessionAttributes=falsespring.velocity.exposeSpringMacroHelpers=falsespring.velocity.numberToolAttribute=spring.velocity.prefix=spring.velocity.properties.*=spring.velocity.requestContextAttribute=spring.velocity.resourceLoaderPath=classpath:/templates/spring.velocity.suffix=.vmspring.velocity.templateEncoding=UTF-8spring.velocity.viewNames= # whitelist of view names that can be resolved# INTERNATIONALIZATION (MessageSourceAutoConfiguration)spring.messages.basename=messagesspring.messages.cacheSeconds=-1spring.messages.encoding=UTF-8# 安全相关配置参数 (SecurityProperties)security.user.name=user # login usernamesecurity.user.password= # login passwordsecurity.user.role=USER # role assigned to the usersecurity.require-ssl=false # advanced settings ...security.enable-csrf=falsesecurity.basic.enabled=truesecurity.basic.realm=Springsecurity.basic.path= # /**security.headers.xss=falsesecurity.headers.cache=falsesecurity.headers.frame=falsesecurity.headers.contentType=falsesecurity.headers.hsts=all # none / domain / allsecurity.sessions=stateless # always / never / if_required / statelesssecurity.ignored=false# 数据源相关配置参数(DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.name= # name of the data sourcespring.datasource.initialize=true # populate using data.sqlspring.datasource.schema= # a schema (DDL) script resource referencespring.datasource.data= # a data (DML) script resource referencespring.datasource.platform= # the platform to use in the schema resource (schema-$&#123;platform&#125;.sql)spring.datasource.continueOnError=false # continue even if can&apos;t be initializedspring.datasource.separator=; # statement separator in SQL initialization scriptsspring.datasource.driverClassName= # JDBC Settings...spring.datasource.url=spring.datasource.username=spring.datasource.password=spring.datasource.max-active=100 # Advanced configuration...spring.datasource.max-idle=8spring.datasource.min-idle=8spring.datasource.initial-size=10spring.datasource.validation-query=spring.datasource.test-on-borrow=falsespring.datasource.test-on-return=falsespring.datasource.test-while-idle=spring.datasource.time-between-eviction-runs-millis=spring.datasource.min-evictable-idle-time-millis=spring.datasource.max-wait-millis=# mongdb相关配置参数 (MongoProperties)spring.data.mongodb.host= # the db hostspring.data.mongodb.port=27017 # the connection port (defaults to 27107)spring.data.mongodb.uri=mongodb://localhost/test # connection URLspring.data.mongo.repositories.enabled=true # if spring data repository support is enabled# springDataJPA相关配置参数(JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.jpa.properties.*= # properties to set on the JPA connectionspring.jpa.openInView=truespring.jpa.show-sql=truespring.jpa.database-platform=spring.jpa.database=spring.jpa.generate-ddl=false # ignored by Hibernate, might be useful for other vendorsspring.jpa.hibernate.naming-strategy= # naming classnamespring.jpa.hibernate.ddl-auto= # defaults to create-drop for embedded dbsspring.data.jpa.repositories.enabled=true # if spring data repository support is enabled# solr相关配置参数(SolrProperties&#125;)spring.data.solr.host=http://127.0.0.1:8983/solrspring.data.solr.zkHost=spring.data.solr.repositories.enabled=true # if spring data repository support is enabled# elasticsearch相关配置参数(ElasticsearchProperties&#125;)spring.data.elasticsearch.cluster-name= # The cluster name (defaults to elasticsearch)spring.data.elasticsearch.cluster-nodes= # The address(es) of the server node (comma-separated; if not specified starts a client node)spring.data.elasticsearch.local=true # if local mode should be used with client nodesspring.data.elasticsearch.repositories.enabled=true # if spring data repository support is enabled# flyway相关配置参数(FlywayProperties)flyway.locations=classpath:db/migrations # locations of migrations scriptsflyway.schemas= # schemas to updateflyway.initVersion= 1 # version to start migrationflyway.prefix=Vflyway.suffix=.sqlflyway.enabled=trueflyway.url= # JDBC url if you want Flyway to create its own DataSourceflyway.user= # JDBC username if you want Flyway to create its own DataSourceflyway.password= # JDBC password if you want Flyway to create its own DataSource# liquibase相关配置参数(LiquibaseProperties)liquibase.change-log=classpath:/db/changelog/db.changelog-master.yamlliquibase.contexts= # runtime contexts to useliquibase.default-schema= # default database schema to useliquibase.drop-first=falseliquibase.enabled=true# JMXspring.jmx.enabled=true # Expose MBeans from Spring# rabbitmq相关配置参数(RabbitProperties)spring.rabbitmq.host= # connection hostspring.rabbitmq.port= # connection portspring.rabbitmq.addresses= # connection addresses (e.g. myhost:9999,otherhost:1111)spring.rabbitmq.username= # login userspring.rabbitmq.password= # login passwordspring.rabbitmq.virtualhost=spring.rabbitmq.dynamic=# redis相关配置参数(RedisProperties)spring.redis.host=localhost # server hostspring.redis.password= # server passwordspring.redis.port=6379 # connection portspring.redis.pool.max-idle=8 # pool settings ...spring.redis.pool.min-idle=0spring.redis.pool.max-active=8spring.redis.pool.max-wait=-1# activemq相关配置参数(ActiveMQProperties)spring.activemq.broker-url=tcp://localhost:61616 # connection URLspring.activemq.user=spring.activemq.password=spring.activemq.in-memory=true # broker kind to create if no broker-url is specifiedspring.activemq.pooled=false# hornetq相关配置参数(HornetQProperties)spring.hornetq.mode= # connection mode (native, embedded)spring.hornetq.host=localhost # hornetQ host (native mode)spring.hornetq.port=5445 # hornetQ port (native mode)spring.hornetq.embedded.enabled=true # if the embedded server is enabled (needs hornetq-jms-server.jar)spring.hornetq.embedded.serverId= # auto-generated id of the embedded server (integer)spring.hornetq.embedded.persistent=false # message persistencespring.hornetq.embedded.data-directory= # location of data content (when persistence is enabled)spring.hornetq.embedded.queues= # comma separate queues to create on startupspring.hornetq.embedded.topics= # comma separate topics to create on startupspring.hornetq.embedded.cluster-password= # customer password (randomly generated by default)# JMS (JmsProperties)spring.jms.pub-sub-domain= # false for queue (default), true for topic# springbatch相关配置参数(BatchDatabaseInitializer)spring.batch.job.names=job1,job2spring.batch.job.enabled=truespring.batch.initializer.enabled=truespring.batch.schema= # batch schema to load# aop相关配置参数spring.aop.auto=spring.aop.proxy-target-class=# FILE ENCODING (FileEncodingApplicationListener)spring.mandatory-file-encoding=false# SPRING SOCIAL (SocialWebAutoConfiguration)spring.social.auto-connection-views=true # Set to true for default connection views or false if you provide your own# SPRING SOCIAL FACEBOOK (FacebookAutoConfiguration)spring.social.facebook.app-id= # your application&apos;s Facebook App IDspring.social.facebook.app-secret= # your application&apos;s Facebook App Secret# SPRING SOCIAL LINKEDIN (LinkedInAutoConfiguration)spring.social.linkedin.app-id= # your application&apos;s LinkedIn App IDspring.social.linkedin.app-secret= # your application&apos;s LinkedIn App Secret# SPRING SOCIAL TWITTER (TwitterAutoConfiguration)spring.social.twitter.app-id= # your application&apos;s Twitter App IDspring.social.twitter.app-secret= # your application&apos;s Twitter App Secret# SPRING MOBILE SITE PREFERENCE (SitePreferenceAutoConfiguration)spring.mobile.sitepreference.enabled=true # enabled by default# SPRING MOBILE DEVICE VIEWS (DeviceDelegatingViewResolverAutoConfiguration)spring.mobile.devicedelegatingviewresolver.enabled=true # disabled by defaultspring.mobile.devicedelegatingviewresolver.normalPrefix=spring.mobile.devicedelegatingviewresolver.normalSuffix=spring.mobile.devicedelegatingviewresolver.mobilePrefix=mobile/spring.mobile.devicedelegatingviewresolver.mobileSuffix=spring.mobile.devicedelegatingviewresolver.tabletPrefix=tablet/spring.mobile.devicedelegatingviewresolver.tabletSuffix=# ----------------------------------------# ACTUATOR PROPERTIES# ----------------------------------------# MANAGEMENT HTTP SERVER (ManagementServerProperties)management.port= # defaults to &apos;server.port&apos;management.address= # bind to a specific NICmanagement.contextPath= # default to &apos;/&apos;# ENDPOINTS (AbstractEndpoint subclasses)endpoints.autoconfig.id=autoconfigendpoints.autoconfig.sensitive=trueendpoints.autoconfig.enabled=trueendpoints.beans.id=beansendpoints.beans.sensitive=trueendpoints.beans.enabled=trueendpoints.configprops.id=configpropsendpoints.configprops.sensitive=trueendpoints.configprops.enabled=trueendpoints.configprops.keys-to-sanitize=password,secretendpoints.dump.id=dumpendpoints.dump.sensitive=trueendpoints.dump.enabled=trueendpoints.env.id=envendpoints.env.sensitive=trueendpoints.env.enabled=trueendpoints.health.id=healthendpoints.health.sensitive=falseendpoints.health.enabled=trueendpoints.info.id=infoendpoints.info.sensitive=falseendpoints.info.enabled=trueendpoints.metrics.id=metricsendpoints.metrics.sensitive=trueendpoints.metrics.enabled=trueendpoints.shutdown.id=shutdownendpoints.shutdown.sensitive=trueendpoints.shutdown.enabled=falseendpoints.trace.id=traceendpoints.trace.sensitive=trueendpoints.trace.enabled=true# MVC ONLY ENDPOINTSendpoints.jolokia.path=jolokiaendpoints.jolokia.sensitive=trueendpoints.jolokia.enabled=true # when using Jolokiaendpoints.error.path=/error# JMX ENDPOINT (EndpointMBeanExportProperties)endpoints.jmx.enabled=trueendpoints.jmx.domain= # the JMX domain, defaults to &apos;org.springboot&apos;endpoints.jmx.unique-names=falseendpoints.jmx.enabled=trueendpoints.jmx.staticNames=# JOLOKIA (JolokiaProperties)jolokia.config.*= # See Jolokia manual# REMOTE SHELLshell.auth=simple # jaas, key, simple, springshell.command-refresh-interval=-1shell.command-path-pattern= # classpath*:/commands/**, classpath*:/crash/commands/**shell.config-path-patterns= # classpath*:/crash/*shell.disabled-plugins=false # don&apos;t expose pluginsshell.ssh.enabled= # ssh settings ...shell.ssh.keyPath=shell.ssh.port=shell.telnet.enabled= # telnet settings ...shell.telnet.port=shell.auth.jaas.domain= # authentication settings ...shell.auth.key.path=shell.auth.simple.user.name=shell.auth.simple.user.password=shell.auth.spring.roles=# GIT INFOspring.git.properties= # resource ref to generated git info properties file]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot应用启动器]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E5%99%A8%2F</url>
    <content type="text"><![CDATA[spring Boot应用启动器基本的一共有44种，具体如下:1.spring-boot-starter这是Spring Boot的核心启动器，包含了自动配置、日志和YAML。 2.spring-boot-starter-actuator帮助监控和管理应用。 3.spring-boot-starter-amqp通过spring-rabbit来支持AMQP协议（Advanced Message Queuing Protocol）。 4.spring-boot-starter-aop支持面向方面的编程即AOP，包括spring-aop和AspectJ。 5.spring-boot-starter-artemis通过Apache Artemis支持JMS的API（Java Message Service API）。 6.spring-boot-starter-batch支持Spring Batch，包括HSQLDB数据库。 7.spring-boot-starter-cache支持Spring的Cache抽象。 8.spring-boot-starter-cloud-connectors支持Spring Cloud Connectors，简化了在像Cloud Foundry或Heroku这样的云平台上连接服务。 9.spring-boot-starter-data-elasticsearch支持ElasticSearch搜索和分析引擎，包括spring-data-elasticsearch。 10.spring-boot-starter-data-gemfire支持GemFire分布式数据存储，包括spring-data-gemfire。 11.spring-boot-starter-data-jpa支持JPA（Java Persistence API），包括spring-data-jpa、spring-orm、hibernate。 12.spring-boot-starter-data-MongoDB支持MongoDB数据，包括spring-data-mongodb。 13.spring-boot-starter-data-rest通过spring-data-rest-webmvc，支持通过REST暴露Spring Data数据仓库。 14.spring-boot-starter-data-solr支持Apache Solr搜索平台，包括spring-data-solr。 15.spring-boot-starter-freemarker支持FreeMarker模板引擎。 16.spring-boot-starter-groovy-templates支持Groovy模板引擎。 17.spring-boot-starter-hateoas通过spring-hateoas支持基于HATEOAS的RESTful Web服务。 18.spring-boot-starter-hornetq通过HornetQ支持JMS。 19.spring-boot-starter-integration支持通用的spring-integration模块。 20.spring-boot-starter-jdbc支持JDBC数据库。 21.spring-boot-starter-jersey支持Jersey RESTful Web服务框架。 22.spring-boot-starter-jta-atomikos通过Atomikos支持JTA分布式事务处理。 23.spring-boot-starter-jta-bitronix通过Bitronix支持JTA分布式事务处理。 24.spring-boot-starter-mail支持javax.mail模块。 25.spring-boot-starter-mobile支持spring-mobile。 26.spring-boot-starter-mustache支持Mustache模板引擎。 27.spring-boot-starter-Redis支持Redis键值存储数据库，包括spring-redis。 28.spring-boot-starter-security支持spring-security。 29.spring-boot-starter-social-facebook支持spring-social-facebook 30.spring-boot-starter-social-linkedin支持pring-social-linkedin 31.spring-boot-starter-social-twitter支持pring-social-twitter 32.spring-boot-starter-test支持常规的测试依赖，包括JUnit、Hamcrest、Mockito以及spring-test模块。 33.spring-boot-starter-thymeleaf支持Thymeleaf模板引擎，包括与Spring的集成。 34.spring-boot-starter-velocity支持Velocity模板引擎。 35.spring-boot-starter-webS支持全栈式Web开发，包括Tomcat和spring-webmvc。 36.spring-boot-starter-websocket支持WebSocket开发。 37.spring-boot-starter-ws支持Spring Web Services。Spring Boot应用启动器面向生产环境的还有2种，具体如下： 1.spring-boot-starter-actuator增加了面向产品上线相关的功能，比如测量和监控。 2.spring-boot-starter-remote-shell增加了远程ssh shell的支持。最后，Spring Boot应用启动器还有一些替换技术的启动器，具体如下： 1.spring-boot-starter-jetty引入了Jetty HTTP引擎（用于替换Tomcat）。 2.spring-boot-starter-log4j支持Log4J日志框架。 3.spring-boot-starter-logging引入了Spring Boot默认的日志框架Logback。 4.spring-boot-starter-tomcat引入了Spring Boot默认的HTTP引擎Tomcat。 5.spring-boot-starter-undertow引入了Undertow HTTP引擎（用于替换Tomcat）。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot使用AOP统一处理Web请求日志]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E4%BD%BF%E7%94%A8AOP%E7%BB%9F%E4%B8%80%E5%A4%84%E7%90%86Web%E8%AF%B7%E6%B1%82%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[首先添加aop依赖123456&lt;!-- AOP --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 写一个切面类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.gyf.aop;import java.util.Enumeration;import javax.servlet.http.HttpServletRequest;import org.apache.log4j.Logger;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;@Aspect@Componentpublic class WebLogAspect &#123; private Logger logger = Logger.getLogger(getClass()); @Pointcut(&quot;execution(public * com.gyf.controller..*.*(..))&quot;) public void webLog() &#123; &#125; @Before(&quot;webLog()&quot;) public void doBefore(JoinPoint joinPoint) throws Throwable &#123; // 接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // 记录下请求内容 logger.info(&quot;---------------request----------------&quot;); logger.info(&quot;URL : &quot; + request.getRequestURL().toString()); logger.info(&quot;HTTP_METHOD : &quot; + request.getMethod()); logger.info(&quot;IP : &quot; + request.getRemoteAddr()); Enumeration&lt;String&gt; enu = request.getParameterNames(); while (enu.hasMoreElements()) &#123; String name = (String) enu.nextElement(); logger.info(&quot;name:&quot; + name + &quot;value&quot; + request.getParameter(name)); &#125; &#125; @AfterReturning(returning = &quot;ret&quot;, pointcut = &quot;webLog()&quot;) public void doAfterReturning(Object ret) throws Throwable &#123; logger.info(&quot;---------------response----------------&quot;); // 处理完请求，返回内容 logger.info(&quot;RESPONSE : &quot; + ret); &#125;&#125; @Aspect:作用是把当前类标识为一个切面供容器读取Aspect的意思是面向切面编程，一个类前面加上@Aspect说明这个类使用了这个技术，很有可能是在进行声明式事务处理 1.这里的可以把这里public void webLog() {}方法理解成具体pointcut（切入点）的声明，实际对应的切入点是“execution(public * com.cc.springboot.controller…(..))”； 2.@AfterReturning，是在具体业务方法返回后的操作（比如下面IndexController类中的getUserName()方法），所以returning=”ret”对应的是业务方法 的返回值，不是切入点声明的返回值，也就是returning=”ret”的“ret”就是具体的方法(public * com.cc.springboot.controller…(..))的返回值，对应public void afterReturning(ret returnValue) 的方法参数，名称一定要对应，在方法返回后，可以进行一些操作，比如输出返回值或者根据返回值进行一些操作。 然后开启Spring 随便使用一个业务方法 就可以看到控制台打印的日志了]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Log4j]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E6%95%B4%E5%90%88Log4j%2F</url>
    <content type="text"><![CDATA[Spring Boot 配合log4j实现日志输出 导入Log4j属性文件log4j.properties注意，复制时要把每一行后面的空格去除 这里配置的 日志文件地址为 C:/Users/10301/Desktop/test/logs/info/info.log1234567891011121314log4j.rootLogger=INFO,Console,File log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.Target=System.outlog4j.appender.Console.layout = org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=[%p] [%d&#123;yyyy-MM-dd HH\:mm\:ss&#125;][%c - %L]%m%n log4j.appender.File = org.apache.log4j.RollingFileAppender log4j.appender.File.File = C:/Users/10301/Desktop/test/logs/info/info.log log4j.appender.File.MaxFileSize = 10MB log4j.appender.File.Threshold = ALL log4j.appender.File.layout = org.apache.log4j.PatternLayout log4j.appender.File.layout.ConversionPattern =[%p] [%d&#123;yyyy-MM-dd HH\:mm\:ss&#125;][%c - %L]%m%n 配置pom.xml 去除springboot的logging，添加log4j，因为自带的logging不启效果springboot下的Log4j的版本最新1.3.8，如果你的springboot的parent版本过高，那在在添加log4j自己版本 12345678910111213141516171819202122232425262728293031323334353637383940&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;groupId&gt;com.micai&lt;/groupId&gt; &lt;artifactId&gt;micai-springboot-log4j-8&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;micai-springboot-log4j-8&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;!-- Spring Boot 启动父依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.6.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- Spring Boot web依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- Spring Boot log4j依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ##具体打印日志的java类，如下： 123456789101112131415161718192021package com.micai.springboot.web; import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; @RestController //提供实现了REST API，可以服务JSON,XML或者其他。这里是以String的形式渲染出结果。public class HelloWorldController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @RequestMapping(&quot;/&quot;) //提供路由信息，”/“路径的HTTP Request都会被映射到sayHello方法进行处理。 public String sayHello()&#123; logger.info(&quot;hello world&quot;); return &quot;Hello,World!&quot;; &#125; &#125; 启动Spring 就可以在上面的路径的日志文件中看到运行日志]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合MyBatis配置多个数据源]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E6%95%B4%E5%90%88MyBatis%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AA%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"><![CDATA[配置文件中新增两个数据源12345678910spring.datasource.test1.driverClassName=com.mysql.jdbc.Driverspring.datasource.test1.url=jdbc:mysql://localhost:3306/test1?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.test1.username=rootspring.datasource.test1.password=123456spring.datasource.test2.driverClassName=com.mysql.jdbc.Driverspring.datasource.test2.url=jdbc:mysql://localhost:3306/test2?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.test2.username=rootspring.datasource.test2.password=123456 在数据库中创建两个数据库12345678910111213141516use test1;CREATE table user( id int PRIMARY KEY AUTO_INCREMENT, username VARCHAR(50), password VARCHAR(50), email VARCHAR(50), birthday TIMESTAMP);use test2;CREATE table customer( id int PRIMARY KEY AUTO_INCREMENT, name VARCHAR(50), tel VARCHAR(50)); 再src下先创建两个包 com.gyf.test1.mapper ， com.gyf.test2.mapper 编写两个数据源配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//----------text1package com.gyf.datasource;@Configuration//注解到springboot容器中@MapperScan(basePackages=&quot;com.gyf.test1.mapper&quot;,sqlSessionFactoryRef=&quot;test1SqlSessionFactory&quot;)public class DataSource01 &#123; /** * @return 返回test1数据库的数据源 */ @Bean(name=&quot;test1DataSource&quot;) @Primary//主数据源 @ConfigurationProperties(prefix=&quot;spring.datasource.test1&quot;) public DataSource dateSource()&#123; return DataSourceBuilder.create().build(); &#125; /** * @return 返回test1数据库的会话工厂 */ @Bean(name = &quot;test1SqlSessionFactory&quot;) public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;test1DataSource&quot;) DataSource ds) throws Exception&#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(ds); return bean.getObject(); &#125; /** * @return 返回test1数据库的事务 */ @Bean(name = &quot;test1TransactionManager&quot;) @Primary public DataSourceTransactionManager transactionManager(@Qualifier(&quot;test1DataSource&quot;) DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; /** * @return 返回test1数据库的会话模版 */ @Bean(name = &quot;test1SqlSessionTemplate&quot;) public SqlSessionTemplate sqlSessionTemplate( @Qualifier(&quot;test1SqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125;//------------text2package com.gyf.datasource;@Configuration//注解到springboot容器中@MapperScan(basePackages=&quot;com.gyf.test2.mapper&quot;,sqlSessionFactoryRef=&quot;test2SqlSessionFactory&quot;)public class DataSource02 &#123; /** * @return 返回test2数据库的数据源 */ @Bean(name=&quot;test2DataSource&quot;) @ConfigurationProperties(prefix=&quot;spring.datasource.test2&quot;) public DataSource dateSource()&#123; return DataSourceBuilder.create().build(); &#125; /** * @return 返回test2数据库的会话工厂 */ @Bean(name = &quot;test2SqlSessionFactory&quot;) public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;test2DataSource&quot;) DataSource ds) throws Exception&#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(ds); return bean.getObject(); &#125; /** * @return 返回test2数据库的事务 */ @Bean(name = &quot;test2TransactionManager&quot;) public DataSourceTransactionManager transactionManager(@Qualifier(&quot;test2DataSource&quot;) DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource); &#125; /** * @return 返回test2数据库的会话模版 */ @Bean(name = &quot;test2SqlSessionTemplate&quot;) public SqlSessionTemplate sqlSessionTemplate( @Qualifier(&quot;test2SqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 然后编写Mapper里的类和映射SQL的xml文件如果使用的是com.gyf.test1.mapper下的类就是使用的第一个数据源的数据如果使用的是com.gyf.test2.mapper下的类就是使用的第二个数据源的数据 如果你在一个service的方法里同时使用了两个数据源 开启了事务注解 @Transactoinal 并出现了的异常很显然，有多个事务，容器不知道我们要的是哪个事务、如何解决这个错误 下面会给大家讲解 springboot中的多事务管理使用springboot+jta+atomikos 分布式事物管理解决方案 添加jta事务依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jta-atomikos&lt;/artifactId&gt;&lt;/dependency&gt; 修改数据库连接配置数据 123456789101112131415161718192021222324252627# Mysql 1mysql.datasource.test1.url = jdbc:mysql://localhost:3306/test1?useUnicode=true&amp;characterEncoding=utf-8mysql.datasource.test1.username = rootmysql.datasource.test1.password = 123456mysql.datasource.test1.minPoolSize = 3mysql.datasource.test1.maxPoolSize = 25mysql.datasource.test1.maxLifetime = 20000mysql.datasource.test1.borrowConnectionTimeout = 30mysql.datasource.test1.loginTimeout = 30mysql.datasource.test1.maintenanceInterval = 60mysql.datasource.test1.maxIdleTime = 60mysql.datasource.test1.testQuery = select 1# Mysql 2mysql.datasource.test2.url =jdbc:mysql://localhost:3306/test2?useUnicode=true&amp;characterEncoding=utf-8mysql.datasource.test2.username =rootmysql.datasource.test2.password =123456mysql.datasource.test2.minPoolSize = 3mysql.datasource.test2.maxPoolSize = 25mysql.datasource.test2.maxLifetime = 20000mysql.datasource.test2.borrowConnectionTimeout = 30mysql.datasource.test2.loginTimeout = 30mysql.datasource.test2.maintenanceInterval = 60mysql.datasource.test2.maxIdleTime = 60mysql.datasource.test2.testQuery = select 1 添加2个配置模型 模型放在com.gyf.dbconfig包 12345678910111213141516171819202122232425262728293031323334353637@ConfigurationProperties(&quot;mysql.datasource.test1&quot;)public class DBConfig1 &#123; private String url; private String username; private String password; private int minPoolSize; private int maxPoolSize; private int maxLifetime; private int borrowConnectionTimeout; private int loginTimeout; private int maintenanceInterval; private int maxIdleTime; private String testQuery; ...... &#125; @ConfigurationProperties(&quot;mysql.datasource.test2&quot;)public class DBConfig2 &#123; private String url; private String username; private String password; private int minPoolSize; private int maxPoolSize; private int maxLifetime; private int borrowConnectionTimeout; private int loginTimeout; private int maintenanceInterval; private int maxIdleTime; private String testQuery; ...... &#125; 重定两个数据源配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.gyf.datasource;import java.sql.SQLException;import javax.sql.DataSource;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.SqlSessionTemplate;import org.mybatis.spring.annotation.MapperScan;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.autoconfigure.jdbc.DataSourceBuilder;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import com.atomikos.jdbc.AtomikosDataSourceBean;import com.gyf.dbconfig.DBConfig1;import com.mysql.jdbc.jdbc2.optional.MysqlXADataSource;@Configuration//注解到springboot容器中@MapperScan(basePackages=&quot;com.gyf.test1.mapper&quot;,sqlSessionFactoryRef=&quot;test1SqlSessionFactory&quot;)public class DataSource01 &#123; // 配置数据源 @Primary @Bean(name = &quot;test1DataSource&quot;) public DataSource testDataSource(DBConfig1 testConfig) throws SQLException &#123; MysqlXADataSource mysqlXaDataSource = new MysqlXADataSource(); mysqlXaDataSource.setUrl(testConfig.getUrl()); mysqlXaDataSource.setPinGlobalTxToPhysicalConnection(true); mysqlXaDataSource.setPassword(testConfig.getPassword()); mysqlXaDataSource.setUser(testConfig.getUsername()); mysqlXaDataSource.setPinGlobalTxToPhysicalConnection(true); AtomikosDataSourceBean xaDataSource = new AtomikosDataSourceBean(); xaDataSource.setXaDataSource(mysqlXaDataSource); xaDataSource.setUniqueResourceName(&quot;test1DataSource&quot;); xaDataSource.setMinPoolSize(testConfig.getMinPoolSize()); xaDataSource.setMaxPoolSize(testConfig.getMaxPoolSize()); xaDataSource.setMaxLifetime(testConfig.getMaxLifetime()); xaDataSource.setBorrowConnectionTimeout(testConfig.getBorrowConnectionTimeout()); xaDataSource.setLoginTimeout(testConfig.getLoginTimeout()); xaDataSource.setMaintenanceInterval(testConfig.getMaintenanceInterval()); xaDataSource.setMaxIdleTime(testConfig.getMaxIdleTime()); xaDataSource.setTestQuery(testConfig.getTestQuery()); return xaDataSource; &#125; @Bean(name = &quot;test1SqlSessionFactory&quot;) public SqlSessionFactory testSqlSessionFactory(@Qualifier(&quot;test1DataSource&quot;) DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); return bean.getObject(); &#125; @Bean(name = &quot;test1SqlSessionTemplate&quot;) public SqlSessionTemplate testSqlSessionTemplate( @Qualifier(&quot;test1SqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125;-------------------------------------------------------package com.gyf.datasource;import java.sql.SQLException;import javax.sql.DataSource;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.SqlSessionTemplate;import org.mybatis.spring.annotation.MapperScan;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.atomikos.jdbc.AtomikosDataSourceBean;import com.gyf.dbconfig.DBConfig2;import com.mysql.jdbc.jdbc2.optional.MysqlXADataSource;@Configuration//注解到springboot容器中@MapperScan(basePackages=&quot;com.gyf.test2.mapper&quot;,sqlSessionFactoryRef=&quot;test2SqlSessionFactory&quot;)public class DataSource02 &#123; // 配置数据源 @Bean(name = &quot;test2DataSource&quot;) public DataSource testDataSource(DBConfig2 testConfig) throws SQLException &#123; MysqlXADataSource mysqlXaDataSource = new MysqlXADataSource(); mysqlXaDataSource.setUrl(testConfig.getUrl()); mysqlXaDataSource.setPinGlobalTxToPhysicalConnection(true); mysqlXaDataSource.setPassword(testConfig.getPassword()); mysqlXaDataSource.setUser(testConfig.getUsername()); mysqlXaDataSource.setPinGlobalTxToPhysicalConnection(true); AtomikosDataSourceBean xaDataSource = new AtomikosDataSourceBean(); xaDataSource.setXaDataSource(mysqlXaDataSource); xaDataSource.setUniqueResourceName(&quot;test2DataSource&quot;); xaDataSource.setMinPoolSize(testConfig.getMinPoolSize()); xaDataSource.setMaxPoolSize(testConfig.getMaxPoolSize()); xaDataSource.setMaxLifetime(testConfig.getMaxLifetime()); xaDataSource.setBorrowConnectionTimeout(testConfig.getBorrowConnectionTimeout()); xaDataSource.setLoginTimeout(testConfig.getLoginTimeout()); xaDataSource.setMaintenanceInterval(testConfig.getMaintenanceInterval()); xaDataSource.setMaxIdleTime(testConfig.getMaxIdleTime()); xaDataSource.setTestQuery(testConfig.getTestQuery()); return xaDataSource; &#125; @Bean(name = &quot;test2SqlSessionFactory&quot;) public SqlSessionFactory testSqlSessionFactory(@Qualifier(&quot;test2DataSource&quot;) DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); return bean.getObject(); &#125; @Bean(name = &quot;test2SqlSessionTemplate&quot;) public SqlSessionTemplate testSqlSessionTemplate( @Qualifier(&quot;test2SqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125;&#125; 在APP类中添加注解12345678910@SpringBootApplication@EnableConfigurationProperties(value = &#123;DBConfig1.class,DBConfig2.class&#125;)public class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class,args); &#125;&#125; 这样就解决了多个事务管理问题]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合MyBatis]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E6%95%B4%E5%90%88MyBatis%2F</url>
    <content type="text"><![CDATA[什么是 MyBatis ？MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录 如何让将MyBatis与SpringBoot进行整合pom导入 1234567891011121314151617181920212223242526272829303132&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- mybaties --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.properties文件中属性配置 123456#数据库配置spring.datasource.url=jdbc:mysql://localhost:3306/db?characterEncoding=utf-8spring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver Mapper中以xml形式编写SQL语句 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;com.gyf.mapper.UserMapper&quot; &gt; &lt;insert id=&quot;save&quot;&gt; insert into t_user (username,password) VALUES(#&#123;0&#125;,#&#123;1&#125;) &lt;/insert&gt; &lt;select id=&quot;findByUsername&quot; resultType=&quot;com.gyf.model.User&quot; parameterType=&quot;string&quot;&gt; select * from t_user where username = #&#123;username,jdbcType=VARCHAR&#125; &lt;/select&gt;&lt;/mapper&gt; 注意这里需要在pom中添加下面代码 1234567891011&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; Controller这里为了简写直接在Controller层中引入了Mapper在实际中Mapper是在service层中引入的 1234567891011121314151617181920212223package com.gyf.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import com.gyf.mapper.UserMapper;import com.gyf.model.User;@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123; @Autowired private UserMapper userMapper; @ResponseBody @RequestMapping(&quot;/add/&#123;name&#125;&quot;) public int add(String name)&#123; return userMapper.insert(name,&quot;e10adc3949ba59abbe56e057f20f883e&quot;); &#125;&#125; 运行App类 123456789101112131415package com.gyf.app;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.context.annotation.ComponentScan;@SpringBootApplicationpublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125;&#125; 在浏览器地址栏中 输入localhost:8080/user/add/参数 然后再去数据库查看数据是否添加成功]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Freemarker的使用]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E6%95%B4%E5%90%88Freemarker%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[模板引擎 Freemarker它是基于模板文件生成其他文本的通用工具FreeMarker是一款用java语言编写的模版引擎，它虽然不是web应用框架，但它很合适作为web应用框架的一个组件。当你使用上述模板引擎中的时候，它们默认的模板配置路径为：src/main/resources/templates 特点： 轻量级模版引擎，不需要Servlet环境就可以很轻松的嵌入到应用程序中 能生成各种文本，如html，xml，java，等 入门简单，它是用java编写的，很多语法和java相似 Freemarker常用指令 关于freemarker的指令需要知道：1、注释，即&lt;#‐‐和‐‐&gt;，介于其之间的内容会被freemarker忽略2、插值（Interpolation）：即${..}部分,freemarker会用真实的值代替${..}3、FTL指令：和HTML标记类似，名字前加#予以区分，Freemarker会解析标签中的表达式或逻辑。4、文本，仅文本信息，这些不是freemarker的注释、插值、FTL指令的内容会被freemarker忽略解析，直接输出内容 List指令12345678910111213141516&lt;table&gt; &lt;tr&gt; &lt;td&gt;序号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stus as stu&gt; &lt;tr&gt; &lt;td&gt;$&#123;stu_index + 1&#125;&lt;/td&gt; &lt;td&gt;$&#123;stu.name&#125;&lt;/td&gt; &lt;td&gt;$&#123;stu.age&#125;&lt;/td&gt; &lt;td&gt;$&#123;stu.mondy&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt;&lt;/table&gt; 说明：_index：得到循环的下标，使用方法是在stu后边加”_index”，它的值是从0开始 遍历Map数据使用map指令遍历数据模型中的stuMap。1234567891011121314151617181920212223输出stu1的学生信息：&lt;br/&gt;姓名：$&#123;stuMap[&apos;stu1&apos;].name&#125;&lt;br/&gt;年龄：$&#123;stuMap[&apos;stu1&apos;].age&#125;&lt;br/&gt;输出stu1的学生信息：&lt;br/&gt;姓名：$&#123;stuMap.stu1.name&#125;&lt;br/&gt;年龄：$&#123;stuMap.stu1.age&#125;&lt;br/&gt;遍历输出两个学生信息：&lt;br/&gt;&lt;table&gt; &lt;tr&gt; &lt;td&gt;序号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stuMap?keys as k&gt; &lt;tr&gt; &lt;td&gt;$&#123;k_index + 1&#125;&lt;/td&gt; &lt;td&gt;$&#123;stuMap[k].name&#125;&lt;/td&gt; &lt;td&gt;$&#123;stuMap[k].age&#125;&lt;/td&gt; &lt;td &gt;$&#123;stuMap[k].mondy&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt;&lt;/table&gt; 输出：12345678910输出stu1的学生信息：姓名：小明年龄：18输出stu1的学生信息：姓名：小明年龄：18遍历输出两个学生信息：序号 姓名 年龄 钱包1 小红 19 200.12 小明 18 1,000.86 if指令if 指令即判断指令，是常用的FTL指令，freemarker在解析时遇到if会进行判断，条件为真则输出if中间的内容，否则跳过内容不再输出1234567891011121314&lt;table&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;钱包&lt;/td&gt; &lt;/tr&gt; &lt;#list stus as stu&gt; &lt;tr&gt; &lt;td &lt;#if stu.name ==&apos;小明&apos;&gt;style=&quot;background:red;&quot;&lt;/#if&gt;&gt;$&#123;stu.name&#125;&lt;/td&gt; &lt;td&gt;$&#123;stu.age&#125;&lt;/td&gt; &lt;td &gt;$&#123;stu.mondy&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt;&lt;/table&gt; 其它指令 运算符: 算数运算符 FreeMarker表达式中完全支持算术运算,FreeMarker支持的算术运算符包括:+, - , * , / , % 2、逻辑运算符 逻辑运算符有如下几个: 逻辑与:&amp;&amp; 逻辑或:|| 逻辑非:! 逻辑运算符只能作用于布尔值,否则将产生错误 3、比较运算符 表达式中支持的比较运算符有如下几个: 1 =或者==:判断两个值是否相等. 2 !=:判断两个值是否不等. 3 &gt;或者gt:判断左边值是否大于右边值 4 &gt;=或者gte:判断左边值是否大于等于右边值 5 &lt;或者lt:判断左边值是否小于右边值 6 &lt;=或者lte:判断左边值是否小于等于右边值 注意: =和!=可以用于字符串,数值和日期来比较是否相等,但=和!=两边必须是相同类型的值,否则会产生错误,而且FreeMarker是精确比较,”x”,”x “,”X”是不等的.其它的运行符可以作用于数字和日期,但不能作用于字符串,大部分的时候,使用gt等字母运算符代替&gt;会有更好的效果,因为 FreeMarker会把&gt;解释成FTL标签的结束字符,当然,也可以使用括号来避免这种情况,如:&lt;#if (x&gt;y)&gt; 空值处理 判断某变量是否存在使用 “??” 用法为:variable??,如果该变量存在,返回true,否则返回false 为防止stus为空报错可以加上判断如下：12345&lt;#if stus??&gt;&lt;#list stus as stu&gt;......&lt;/#list&gt;&lt;/#if&gt; 缺失变量默认值使用 “!” 使用!要以指定一个默认值，当变量为空时显示默认值${name!’’}表示如果name为空显示空字符串如果是嵌套对象则建议使用（）括起来例： ${(stu.bestFriend.name)!’’}表示，如果stu或bestFriend或name为空默认显示空字符串。 内建函数内建函数语法格式： 变量+?+函数名称和到某个集合的大小 ${集合名?size} 日期格式化 显示年月日: ${today?date}显示时分秒：${today?time}显示日期+时间：${today?datetime} 自定义格式化： ${today?string(“yyyy年MM月”)} 内建函数c map.put(“point”, 102920122);point是数字型，使用${point}会显示这个数字的值，不并每三位使用逗号分隔如果不想显示为每三位分隔的数字，可以使用c函数将数字型转成字符串输出 ${point?c} 将json字符串转成对象其中用到了 assign标签，assign的作用是定义一个变量。 &lt;#assign text=”{‘bank’:’工商银行’,’account’:’10101920201920212’}” /&gt;&lt;#assign data=text?eval /&gt;开户行：${data.bank} 账号：${data.account} Springboot-freemarker工程配置详解pom.xml文件详解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;springboot&lt;/groupId&gt; &lt;artifactId&gt;springboot-freemarker&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springboot-freemarker :: Spring Boot 集成 FreeMarker 案例&lt;/name&gt; &lt;!-- Spring Boot 启动父依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;mybatis-spring-boot&gt;1.2.0&lt;/mybatis-spring-boot&gt; &lt;mysql-connector&gt;5.1.39&lt;/mysql-connector&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Freemarker 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Web 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Test 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Mybatis 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-spring-boot&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySQL 连接驱动依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql-connector&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 我们在pom.xml中增加Spring Boot FreeMarker依赖 配置FreeMarker 在application.properties中加入FreeMarker相关配置:12345678910111213141516171819202122server: port: 8088 # 服务端口spring: application: name: test-freemarker freemarker: cache: false #关闭模板缓存，方便测试 settings: template_update_delay: 0 #检查模板更新延迟时间，设置为0表示立即检查，如果时间大于0会有缓存不方便进行模板测试------------------------------------------------ ## Freemarker 配置 ## 文件配置路径 spring.freemarker.template-loader-path=classpath:/web/ spring.freemarker.cache=false spring.freemarker.charset=UTF-8 spring.freemarker.check-template-location=true spring.freemarker.content-type=text/html spring.freemarker.expose-request-attributes=true spring.freemarker.expose-session-attributes=true spring.freemarker.request-context-attribute=request spring.freemarker.suffix=.ftl 静态化测试的两种方式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 /** * 使用模板文件静态化 */ @Test public void testGenerateHtml()&#123; try &#123; //创建配置类 Configuration configuration = new Configuration(Configuration.getVersion()); //设置模板路径 String classPath = this.getClass().getResource(&quot;/&quot;).getPath(); configuration.setDirectoryForTemplateLoading(new File(classPath+&quot;/templates/&quot;)); //设置字符集 configuration.setDefaultEncoding(&quot;UTF-8&quot;); //加载模板 Template template = configuration.getTemplate(&quot;test1.ftl&quot;); //数据模型 Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;name&quot;,&quot;程序员&quot;); //静态化 String content = FreeMarkerTemplateUtils.processTemplateIntoString(template, map); //静态化内容 System.out.println(content); InputStream inputStream = IOUtils.toInputStream(content); //输出文件 FileOutputStream fileOutputStream = new FileOutputStream(new File(&quot;d:/test1.html&quot;)); IOUtils.copy(inputStream,fileOutputStream); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;/** * 使用模板字符串静态化 * * * 基于模板字符串生成静态化文件 */ @Test public void testGenerateHtmlByString()&#123; try &#123; //创建配置类 Configuration configuration = new Configuration(Configuration.getVersion()); //模板内容，这里测试时使用简单的字符串作为模板 String templateString=&quot;&quot; + &quot;&lt;html&gt;\n&quot; + &quot; &lt;head&gt;&lt;/head&gt;\n&quot; + &quot; &lt;body&gt;\n&quot; + &quot; 名称：$&#123;name&#125;\n&quot; + &quot; &lt;/body&gt;\n&quot; + &quot;&lt;/html&gt;&quot;; //字符串模板加载器 StringTemplateLoader stringTemplateLoader = new StringTemplateLoader(); stringTemplateLoader.putTemplate(&quot;template&quot;,templateString); configuration.setTemplateLoader(stringTemplateLoader); //得到模板 Template template = configuration.getTemplate(&quot;template&quot;,&quot;utf‐8&quot;); //数据模型 Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;name&quot;,&quot;程序员&quot;); //静态化 String content = FreeMarkerTemplateUtils.processTemplateIntoString(template, map); //静态化内容 System.out.println(content); InputStream inputStream = IOUtils.toInputStream(content); //输出文件 FileOutputStream fileOutputStream = new FileOutputStream(new File(&quot;d:/test1.html&quot;)); IOUtils.copy(inputStream, fileOutputStream); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 注意 这里不是走HTTP+JSON模式,使用了@Controller而不是先前的@RestController方法返回值是String类型，和.application.properties配置的Freemarker文件配置路径下的各个*.ftl文件名一致，这样才会准确的把数据渲染到ftl文件里面进行展示用Model类，向Model加入数据，并指定在该数据在Freemarker取值指定的名称。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot全局捕获异常]]></title>
    <url>%2F2019%2F03%2F05%2FSpringBoot%E5%85%A8%E5%B1%80%E6%8D%95%E8%8E%B7%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[@ExceptionHeandler 表示拦截异常@ControllerAdivcecontroller 的一个辅助类，最常用的就是全局异常处理的切面类可以指定扫描范围约定了几种可行的返回值，如果是直接返回model类的话，需要使用@ResponseBody进行JSON转换 案例 在一个自己定义的包中创建一个全局异常类12345678910111213@ControllerAdvice//切面public class GlobalExceptionHandler &#123; @ExceptionHandler(RuntimeException.class)//捕获运行时异常 @ResponseBody public Map&lt;String,Object&gt; exceptionHander()&#123; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(&quot;errorCode&quot;, &quot;101&quot;); map.put(&quot;errorMsg&quot;, &quot;系統错误!&quot;); return map; &#125;&#125; 在某个的映射的方法中添加上 int i =10/0 的算术异常 然后再启动Spring 最后在浏览器地址栏中输入该方法的路径 如果页面显示 12&#123;&quot;errorCode&quot;:&quot;101&quot;,&quot;errorMsg&quot;:&quot;系統错误&quot;&#125; 那么就说明SpringBoot的全局捕获异常设置成功]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云深]]></title>
    <url>%2F2019%2F03%2F04%2F%E4%BA%91%E6%B7%B1%2F</url>
    <content type="text"><![CDATA[${哈哈}$ 云深第一篇文章这是三级列表哦 列表1 列表2 a 字体列表哦 b 字体列表哈 列表3 云深导航 字体是斜线的字体是加粗的 &lt;html&gt;&lt;/html&gt; 这个123456789&lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; 在博客中添加图片 ![云深不知处](图片路径) &lt;/body&gt;&lt;/html&gt; 这里的内容是引用的]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>导航</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F04%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
